{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GKCdyG5jHBA"
      },
      "source": [
        "# Natural Language Processing Assignment\n",
        "### Harshitha M.U. (J076)\n",
        "\n",
        "## Research paper topic generation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIEdFghXjHBP"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8CDCFfpjOrQ",
        "outputId": "0d94ac58-d9d6-43f7-fede-1ced8afa46fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "pBqfcMjLd-Sm",
        "outputId": "d5d807ea-3d28-4e1a-ec8d-82b3c79b7e01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-36d5aa99-26a6-41cc-8b10-baed73f705bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4261</th>\n",
              "      <td>4857</td>\n",
              "      <td>2013</td>\n",
              "      <td>Scalable Influence Estimation in Continuous-Ti...</td>\n",
              "      <td>Oral</td>\n",
              "      <td>4857-scalable-influence-estimation-in-continuo...</td>\n",
              "      <td>If a piece of information is released from a m...</td>\n",
              "      <td>Scalable Influence Estimation in\\nContinuous-T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4262</th>\n",
              "      <td>4858</td>\n",
              "      <td>2013</td>\n",
              "      <td>Adaptive Anonymity via</td>\n",
              "      <td>Spotlight</td>\n",
              "      <td>4858-adaptive-anonymity-via-b-matching.pdf</td>\n",
              "      <td>The adaptive anonymity problem is formalized w...</td>\n",
              "      <td>Adaptive Anonymity via b-Matching\\n\\nKrzysztof...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4263</th>\n",
              "      <td>4859</td>\n",
              "      <td>2013</td>\n",
              "      <td>Exact and Stable Recovery of Pairwise Interact...</td>\n",
              "      <td>Spotlight</td>\n",
              "      <td>4859-exact-and-stable-recovery-of-pairwise-int...</td>\n",
              "      <td>Tensor completion from incomplete observations...</td>\n",
              "      <td>Exact and Stable Recovery of Pairwise Interact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4265</th>\n",
              "      <td>4860</td>\n",
              "      <td>2013</td>\n",
              "      <td>Matrix factorization with binary components</td>\n",
              "      <td>Spotlight</td>\n",
              "      <td>4860-matrix-factorization-with-binary-componen...</td>\n",
              "      <td>Motivated by an application in computational b...</td>\n",
              "      <td>Matrix factorization with Binary Components\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4266</th>\n",
              "      <td>4861</td>\n",
              "      <td>2013</td>\n",
              "      <td>On the Complexity and Approximation of Binary ...</td>\n",
              "      <td>Spotlight</td>\n",
              "      <td>4861-on-the-complexity-and-approximation-of-bi...</td>\n",
              "      <td>Lifted inference algorithms exploit symmetries...</td>\n",
              "      <td>On the Complexity and Approximation of\\nBinary...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6943</th>\n",
              "      <td>7280</td>\n",
              "      <td>2017</td>\n",
              "      <td>On Separability of Loss Functions, and Revisit...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>7280-on-separability-of-loss-functions-and-rev...</td>\n",
              "      <td>We revisit the classical analysis of generativ...</td>\n",
              "      <td>On Separability of Loss Functions, and Revisit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6944</th>\n",
              "      <td>7281</td>\n",
              "      <td>2017</td>\n",
              "      <td>Maxing and Ranking with Few Assumptions</td>\n",
              "      <td>Poster</td>\n",
              "      <td>7281-maxing-and-ranking-with-few-assumptions.pdf</td>\n",
              "      <td>PAC maximum                                   ...</td>\n",
              "      <td>Maxing and Ranking with Few Assumptions\\nMoein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6945</th>\n",
              "      <td>7282</td>\n",
              "      <td>2017</td>\n",
              "      <td>On clustering network-valued data</td>\n",
              "      <td>Poster</td>\n",
              "      <td>7282-on-clustering-network-valued-data.pdf</td>\n",
              "      <td>Community detection, which focuses on clusteri...</td>\n",
              "      <td>On clustering network-valued data\\n\\nSoumendu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6946</th>\n",
              "      <td>7283</td>\n",
              "      <td>2017</td>\n",
              "      <td>A General Framework for Robust Interactive Lea...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>7283-a-general-framework-for-robust-interactiv...</td>\n",
              "      <td>We propose a general framework for interactive...</td>\n",
              "      <td>A General Framework for Robust Interactive\\nLe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6947</th>\n",
              "      <td>7284</td>\n",
              "      <td>2017</td>\n",
              "      <td>Multi-view Matrix Factorization for Linear Dyn...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>7284-multi-view-matrix-factorization-for-linea...</td>\n",
              "      <td>We consider maximum likelihood estimation of l...</td>\n",
              "      <td>Multi-view Matrix Factorization for Linear\\nDy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2422 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36d5aa99-26a6-41cc-8b10-baed73f705bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36d5aa99-26a6-41cc-8b10-baed73f705bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36d5aa99-26a6-41cc-8b10-baed73f705bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id  year                                              title  \\\n",
              "4261  4857  2013  Scalable Influence Estimation in Continuous-Ti...   \n",
              "4262  4858  2013                            Adaptive Anonymity via    \n",
              "4263  4859  2013  Exact and Stable Recovery of Pairwise Interact...   \n",
              "4265  4860  2013        Matrix factorization with binary components   \n",
              "4266  4861  2013  On the Complexity and Approximation of Binary ...   \n",
              "...    ...   ...                                                ...   \n",
              "6943  7280  2017  On Separability of Loss Functions, and Revisit...   \n",
              "6944  7281  2017            Maxing and Ranking with Few Assumptions   \n",
              "6945  7282  2017                  On clustering network-valued data   \n",
              "6946  7283  2017  A General Framework for Robust Interactive Lea...   \n",
              "6947  7284  2017  Multi-view Matrix Factorization for Linear Dyn...   \n",
              "\n",
              "     event_type                                           pdf_name  \\\n",
              "4261       Oral  4857-scalable-influence-estimation-in-continuo...   \n",
              "4262  Spotlight         4858-adaptive-anonymity-via-b-matching.pdf   \n",
              "4263  Spotlight  4859-exact-and-stable-recovery-of-pairwise-int...   \n",
              "4265  Spotlight  4860-matrix-factorization-with-binary-componen...   \n",
              "4266  Spotlight  4861-on-the-complexity-and-approximation-of-bi...   \n",
              "...         ...                                                ...   \n",
              "6943     Poster  7280-on-separability-of-loss-functions-and-rev...   \n",
              "6944     Poster   7281-maxing-and-ranking-with-few-assumptions.pdf   \n",
              "6945     Poster         7282-on-clustering-network-valued-data.pdf   \n",
              "6946     Poster  7283-a-general-framework-for-robust-interactiv...   \n",
              "6947     Poster  7284-multi-view-matrix-factorization-for-linea...   \n",
              "\n",
              "                                               abstract  \\\n",
              "4261  If a piece of information is released from a m...   \n",
              "4262  The adaptive anonymity problem is formalized w...   \n",
              "4263  Tensor completion from incomplete observations...   \n",
              "4265  Motivated by an application in computational b...   \n",
              "4266  Lifted inference algorithms exploit symmetries...   \n",
              "...                                                 ...   \n",
              "6943  We revisit the classical analysis of generativ...   \n",
              "6944  PAC maximum                                   ...   \n",
              "6945  Community detection, which focuses on clusteri...   \n",
              "6946  We propose a general framework for interactive...   \n",
              "6947  We consider maximum likelihood estimation of l...   \n",
              "\n",
              "                                             paper_text  \n",
              "4261  Scalable Influence Estimation in\\nContinuous-T...  \n",
              "4262  Adaptive Anonymity via b-Matching\\n\\nKrzysztof...  \n",
              "4263  Exact and Stable Recovery of Pairwise Interact...  \n",
              "4265  Matrix factorization with Binary Components\\n\\...  \n",
              "4266  On the Complexity and Approximation of\\nBinary...  \n",
              "...                                                 ...  \n",
              "6943  On Separability of Loss Functions, and Revisit...  \n",
              "6944  Maxing and Ranking with Few Assumptions\\nMoein...  \n",
              "6945  On clustering network-valued data\\n\\nSoumendu ...  \n",
              "6946  A General Framework for Robust Interactive\\nLe...  \n",
              "6947  Multi-view Matrix Factorization for Linear\\nDy...  \n",
              "\n",
              "[2422 rows x 7 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/Papers.csv')\n",
        "df = df.dropna()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlrCWcTkfWWm",
        "outputId": "9c0da946-0e23-4c31-c898-69debedea161"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "data = df[['paper_text']]\n",
        "data['index'] = data.index\n",
        "documents = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sskkf-f6geeF",
        "outputId": "8751e37d-d250-4d7a-a460-e2949711e10a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-95286098-63cd-4392-a2f1-03b6ce366a70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4261</th>\n",
              "      <td>Scalable Influence Estimation in\\nContinuous-T...</td>\n",
              "      <td>4261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4262</th>\n",
              "      <td>Adaptive Anonymity via b-Matching\\n\\nKrzysztof...</td>\n",
              "      <td>4262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4263</th>\n",
              "      <td>Exact and Stable Recovery of Pairwise Interact...</td>\n",
              "      <td>4263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4265</th>\n",
              "      <td>Matrix factorization with Binary Components\\n\\...</td>\n",
              "      <td>4265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4266</th>\n",
              "      <td>On the Complexity and Approximation of\\nBinary...</td>\n",
              "      <td>4266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95286098-63cd-4392-a2f1-03b6ce366a70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95286098-63cd-4392-a2f1-03b6ce366a70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95286098-63cd-4392-a2f1-03b6ce366a70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             paper_text  index\n",
              "4261  Scalable Influence Estimation in\\nContinuous-T...   4261\n",
              "4262  Adaptive Anonymity via b-Matching\\n\\nKrzysztof...   4262\n",
              "4263  Exact and Stable Recovery of Pairwise Interact...   4263\n",
              "4265  Matrix factorization with Binary Components\\n\\...   4265\n",
              "4266  On the Complexity and Approximation of\\nBinary...   4266"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXxzT47sjHBe"
      },
      "source": [
        "### Lemmatizing & Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds7lqGt3gnLR",
        "outputId": "311e42e1-a638-456c-e9ba-f35fa1ed1eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCwc76EEhel_"
      },
      "outputs": [],
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSPrbj-4h7Av",
        "outputId": "1f6412a1-a690-4e43-e1a1-1360147b7aa4",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original document: \n",
            "['Non-strongly-convex', 'smooth', 'stochastic\\napproximation', 'with', 'convergence', 'rate', 'O(1/n)\\n\\nEric', 'Moulines\\nLTCI\\nTelecom', 'ParisTech,', 'Paris,', 'France\\neric.moulines@enst.fr\\n\\nFrancis', 'Bach\\nINRIA', '-', 'Sierra', 'Project-team\\nEcole', 'Normale', 'Sup?erieure,', 'Paris,', 'France\\nfrancis.bach@ens.fr\\n\\nAbstract\\nWe', 'consider', 'the', 'stochastic', 'approximation', 'problem', 'where', 'a', 'convex', 'function', 'has\\nto', 'be', 'minimized,', 'given', 'only', 'the', 'knowledge', 'of', 'unbiased', 'estimates', 'of', 'its', 'gradients\\nat', 'certain', 'points,', 'a', 'framework', 'which', 'includes', 'machine', 'learning', 'methods', 'based\\non', 'the', 'minimization', 'of', 'the', 'empirical', 'risk.', 'We', 'focus', 'on', 'problems', 'without', 'strong\\nconvexity,', 'for', 'which', 'all', 'previously\\nknown', 'algorithms', 'achieve', 'a', 'convergence', 'rate\\n?\\nfor', 'function', 'values', 'of', 'O(1/', 'n)', 'after', 'n', 'iterations.', 'We', 'consider', 'and', 'analyze', 'two\\nalgorithms', 'that', 'achieve', 'a', 'rate', 'of', 'O(1/n)', 'for', 'classical', 'supervised', 'learning', 'problems.', 'For', 'least-squares', 'regression,', 'we', 'show', 'that', 'averaged', 'stochastic', 'gradient\\ndescent', 'with', 'constant', 'step-size', 'achieves', 'the', 'desired', 'rate.', 'For', 'logistic', 'regression,\\nthis', 'is', 'achieved', 'by', 'a', 'simple', 'novel', 'stochastic', 'gradient', 'algorithm', 'that', '(a)', 'constructs\\nsuccessive', 'local', 'quadratic', 'approximations', 'of', 'the', 'loss', 'functions,', 'while', '(b)', 'preserving', 'the', 'same', 'running-time', 'complexity', 'as', 'stochastic', 'gradient', 'descent.', 'For', 'these\\nalgorithms,', 'we', 'provide', 'a', 'non-asymptotic', 'analysis', 'of', 'the', 'generalization', 'error', '(in\\nexpectation,', 'and', 'also', 'in', 'high', 'probability', 'for', 'least-squares),', 'and', 'run', 'extensive', 'experiments', 'showing', 'that', 'they', 'often', 'outperform', 'existing', 'approaches.\\n\\n1', 'Introduction\\nLarge-scale', 'machine', 'learning', 'problems', 'are', 'becoming', 'ubiquitous', 'in', 'many', 'areas', 'of', 'science', 'and', 'engineering.', 'Faced', 'with', 'large', 'amounts', 'of', 'data,', 'practitioners', 'typically', 'prefer', 'algorithms', 'that', 'process\\neach', 'observation', 'only', 'once,', 'or', 'a', 'few', 'times.', 'Stochastic', 'approximation', 'algorithms', 'such', 'as', 'stochastic\\ngradient', 'descent', '(SGD)', 'and', 'its', 'variants,', 'although', 'introduced', 'more', 'than', 'sixty', 'years', 'ago', '[1],', 'still\\nremain', 'the', 'most', 'widely', 'used', 'and', 'studied', 'method', 'in', 'this', 'context', '(see,', 'e.g.,', '[2,', '3,', '4,', '5,', '6,', '7]).\\nWe\\nconvex', 'functions', 'f', ',', 'defined', 'on', 'a', 'Euclidean', 'space', 'F', ',', 'given', 'by', 'f', '(?)', '=\\n\\x02', 'consider', 'minimizing\\n\\x03\\nE', '?(y,', 'h?,', 'xi)', ',', 'where', '(x,', 'y)', '?', 'F', '?', 'R', 'denotes', 'the', 'data', 'and', '?', 'denotes', 'a', 'loss', 'function', 'that', 'is', 'convex', 'with', 'respect', 'to', 'the', 'second', 'variable.', 'This', 'includes', 'logistic', 'and', 'least-squares', 'regression.', 'In\\nthe', 'stochastic', 'approximation', 'framework,', 'independent', 'and', 'identically', 'distributed', 'pairs', '(xn', ',', 'yn', ')', 'are\\nobserved', 'sequentially', 'and', 'the', 'predictor', 'defined', 'by', '?', 'is', 'updated', 'after', 'each', 'pair', 'is', 'seen.\\nWe', 'partially', 'understand', 'the', 'properties', 'of', 'f', 'that', 'affect', 'the', 'problem', 'difficulty.', 'Strong', 'convexity', '(i.e.,\\nwhen', 'f', 'is', 'twice', 'differentiable,', 'a', 'uniform', 'strictly', 'positive', 'lower-bound', '?', 'on', 'Hessians', 'of', 'f', ')', 'is', 'a', 'key\\nproperty.', 'Indeed,', 'after', 'n', 'observations', 'and', 'with', 'the', 'proper', 'step-sizes,', 'averaged', 'SGD\\n?', 'achieves', 'the\\nrate', 'of', 'O(1/?n)', 'in', 'the', 'strongly-convex', 'case', '[5,', '4],', 'while', 'it', 'achieves', 'only', 'O(1/', 'n)', 'in', 'the', 'nonstrongly-convex', 'case', '[5],', 'with', 'matching', 'lower-bounds', '[8].\\nThe', 'main', 'issue', 'with', 'strong', 'convexity', 'is', 'that', 'typical', 'machine', 'learning', 'problems', 'are', 'high-dimensional\\nand', 'have', 'correlated', 'variables', 'so', 'that\\n?', 'the', 'strong', 'convexity', 'constant', '?', 'is', 'zero', 'or', 'very', 'close', 'to', 'zero,\\nand', 'in', 'any', 'case', 'smaller', 'than', 'O(1/', 'n).', 'This', 'then', 'makes', 'the', 'non-strongly', 'convex', 'methods', 'better.\\nIn', 'this', 'paper,', 'we', 'aim', 'at', 'obtaining', 'algorithms', 'that', 'may', 'deal', 'with', 'arbitrarily', 'small', 'strong-convexity\\nconstants,', 'but', 'still', 'achieve', 'a', 'rate', 'of', 'O(1/n).\\n1\\n\\n\\x0cSmoothness', 'plays', 'a', 'central', 'role', 'in', 'the', 'context', 'of', 'deterministic', 'optimization.', 'The', 'known', 'convergence\\nrates', 'for', 'smooth', 'optimization', 'are', 'better', 'than', 'for', 'non-smooth', 'optimization', '(e.g.,', 'see', '[9]).', 'However,\\nfor', 'stochastic', 'optimization', 'the', 'use', 'of', 'smoothness', 'only?leads', 'to', 'improvements', 'on', 'constants', '(e.g.,\\nsee', '[10])', 'but', 'not', 'on', 'the', 'rate', 'itself,', 'which', 'remains', 'O(1/', 'n)', 'for', 'non-strongly-convex', 'problems.\\nWe', 'show', 'that', 'for', 'the', 'square', 'loss', 'and', 'for', 'the', 'logistic', 'loss,', 'we', 'may', 'use', 'the', 'smoothness', 'of', 'the', 'loss', 'and\\nobtain', 'algorithms', 'that', 'have', 'a', 'convergence', 'rate', 'of', 'O(1/n)', 'without', 'any', 'strong', 'convexity', 'assumptions.\\nMore', 'precisely,', 'for', 'least-squares', 'regression,', 'we', 'show', 'in', 'Section', '2', 'that', 'averaged', 'stochastic', 'gradient\\ndescent', 'with', 'constant', 'step-size', 'achieves', 'the', 'desired', 'rate.', 'For', 'logistic', 'regression', 'this', 'is', 'achieved', 'by\\na', 'novel', 'stochastic', 'gradient', 'algorithm', 'that', '(a)', 'constructs', 'successive', 'local', 'quadratic', 'approximations\\nof', 'the', 'loss', 'functions,', 'while', '(b)', 'preserving', 'the', 'same', 'running-time', 'complexity', 'as', 'stochastic', 'gradient', 'descent', '(see', 'Section', '3).', 'For', 'these', 'algorithms,', 'we', 'provide', 'a', 'non-asymptotic', 'analysis', 'of', 'their\\ngeneralization', 'error', '(in', 'expectation,', 'and', 'also', 'in', 'high', 'probability', 'for', 'least-squares),', 'and', 'run', 'extensive', 'experiments', 'on', 'standard', 'machine', 'learning', 'benchmarks', 'showing', 'in', 'Section', '4', 'that', 'they', 'often\\noutperform', 'existing', 'approaches.\\n\\n2', 'Constant-step-size', 'least-mean-square', 'algorithm\\nIn', 'this', 'section,', 'we', 'consider', 'stochastic', 'approximation', 'for', 'least-squares', 'regression,', 'where', 'SGD', 'is\\noften', 'referred', 'to', 'as', 'the', 'least-mean-square', '(LMS)', 'algorithm.', 'The', 'novelty', 'of', 'our', 'convergence', 'result\\nis', 'the', 'use', 'of', 'the', 'constant', 'step-size', 'with', 'averaging,', 'which', 'was', 'already', 'considered', 'by', '[11],', 'but', 'now\\nwith', 'an', 'explicit', 'non-asymptotic', 'rate', 'O(1/n)', 'without', 'any', 'dependence', 'on', 'the', 'lowest', 'eigenvalue', 'of\\nthe', 'covariance', 'matrix.\\n2.1', 'Convergence', 'in', 'expectation\\nWe', 'make', 'the', 'following', 'assumptions:\\n(A1)', 'F', 'is', 'a', 'd-dimensional', 'Euclidean', 'space,', 'with', 'd', '>', '1.\\n(A2)', 'The', 'observations', '(xn', ',', 'zn', ')', '?', 'F', '?', 'F', 'are', 'independent', 'and', 'identically', 'distributed.\\n(A3)', 'Ekxn', 'k2', 'and', 'Ekzn', 'k2', 'are', 'finite.', 'Denote', 'by', 'H', '=', 'E(xn', '?', 'xn', ')', 'the', 'covariance', 'operator', 'from\\nF', 'to', 'F', '.', 'Without', 'loss', 'of', 'generality,', 'H', 'is', 'assumed', 'invertible', '(by', 'projecting', 'onto', 'the', 'minimal\\nsubspace', 'where', 'xn', 'lies', 'almost', 'surely).', 'However,', 'its', 'eigenvalues', 'may', 'be', 'arbitrarily', 'small.\\n\\x02\\n\\x03\\n(A4)', 'The', 'global', 'minimum', 'of', 'f', '(?)', '=', '(1/2)E', 'h?,', 'xn', 'i2', '?', '2h?,', 'zn', 'i', '\\x02', 'is', '\\x03attained', 'at', 'a', 'certain', '??', '?', 'F', '.\\nWe', 'denote', '\\x02by', '?\\x0cn', '=', '\\x03zn', '?', 'h??', ',', 'xn', 'ixn', 'the', 'residual.', 'We', 'have', 'E', '?n', '=', '0,', 'but', 'in', 'general,', 'it', 'is', 'not\\ntrue', 'that', 'E', '?n', '\\x0c', 'xn', '=', '0', '(unless', 'the', 'model', 'is', 'well-specified).\\n(A5)', 'We', 'study', 'the', 'stochastic', 'gradient', '(a.k.a.', 'least', 'mean', 'square)', 'recursion', 'defined', 'as\\n?n', '=', '?n?1', '?', '?(h?n?1', ',', 'xn', 'ixn', '?', 'zn', ')', '=', '(I', '?', '?xn', '?', 'xn', ')?n?1', '+', '?zn', ',\\n(1)\\nP\\nstarted', 'from', '?0', '?', 'F', '.', 'We', 'also', 'consider', 'the', 'averaged', 'iterates', '??n', '=', '(n', '+', '1)?1', 'nk=0', '?k', '.\\n\\x03\\n\\x01\\n\\x02\\n(A6)', 'There', 'exists', 'R', '>', '0', 'and', '?', '>', '0', 'such', 'that', 'E', '?n', '?', '?n', '4', '?', '2', 'H', 'and', 'E', 'kxn', 'k2', 'xn', '?', 'xn', '4', 'R2', 'H,\\nwhere', '4', 'denotes', 'the', 'the', 'order', 'between', 'self-adjoint', 'operators,', 'i.e.,', 'A', '4', 'B', 'if', 'and', 'only', 'if', 'B', '?', 'A\\nis', 'positive', 'semi-definite.\\nDiscussion', 'of', 'assumptions.', 'Assumptions', '(A1-5)', 'are', 'standard', 'in', 'stochastic', 'approximation', '(see,\\ne.g.,', '[12,', '6]).', 'Note', 'that', 'for', 'least-squares', 'problems,', 'zn', 'is', 'of', 'the', 'form', 'yn', 'xn', ',', 'where', 'yn', '?', 'R', 'is\\nthe', 'response', 'to', 'be', 'predicted', 'as', 'a', 'linear', 'function', 'of', 'xn', '.', 'We', 'consider', 'a', 'slightly', 'more', 'general', 'case\\nthan', 'least-squares', 'because', 'we', 'will', 'need', 'it', 'for', 'the', 'quadratic', 'approximation', 'of', 'the', 'logistic', 'loss', 'in\\nSection', '3.1.', 'Note', 'that', 'in', 'assumption', '(A4),', 'we', 'do', 'not', 'assume', 'that', 'the', 'model', 'is', 'well-specified.\\nAssumption', '(A6)', 'is', 'true', 'for', 'least-square', 'regression\\nbounded', 'data,', 'since,', 'if\\n\\x01\\n\\x01', 'with', 'almost', 'surely\\nkxn', 'k2', '6', 'R2', 'almost', 'surely,', 'then', 'E', 'kxn', 'k2', 'xn', '?', 'xn', '4', 'E', 'R2', 'xn', '?', 'xn', '=', 'R2', 'H;', 'a', 'similar', 'inequality\\nholds', 'for', 'the', 'output', 'variables', 'yn', '.', 'Moreover,', 'it', 'also', 'holds', 'for', 'data', 'with', 'infinite', 'supports,', 'such', 'as\\nGaussians', 'or', 'mixtures', 'of', 'Gaussians', '(where', 'all', 'covariance', 'matrices', 'of', 'the', 'mixture', 'components', 'are\\nlower', 'and', 'upper', 'bounded', 'by', 'a', 'constant', 'times', 'the', 'same', 'matrix).', 'Note', 'that', 'the', 'finite-dimensionality\\nassumption', 'could', 'be', 'relaxed,', 'but', 'this', 'would', 'require', 'notions', 'similar', 'to', 'degrees', 'of', 'freedom', '[13],\\nwhich', 'is', 'outside', 'of', 'the', 'scope', 'of', 'this', 'paper.\\n\\x02\\n\\x03\\nThe', 'goal', 'of', 'this', 'section', 'is', 'to', 'provide', 'a', 'non-asymptotic', 'bound', 'on', 'the', 'expectation', 'E', 'f', '(??n', ')', '?', 'f', '(??', ')', ',\\nthat', '(a)', 'does', 'not', 'depend', 'on', 'the', 'smallest', 'non-zero', 'eigenvalue', 'of', 'H', '(which', 'could', 'be', 'arbitrarily', 'small)\\nand', '(b)', 'still', 'scales', 'as', 'O(1/n).\\n2\\n\\n\\x0cTheorem', '1', 'Assume', '(A1-6).', 'For', 'any', 'constant', 'step-size', '?', '<', '1/R2', ',', 'we', 'have\\n?\\n\\x152\\n\\x14\\n\\x02\\n\\x03\\n1\\n?', 'd\\n1\\n?\\np\\n.\\n+', 'Rk?0', '?', '??', 'k', 'p\\nE', 'f', '(?n?1', ')', '?', 'f', '(??', ')', '6\\n2n', '1', '?', '?R2\\n?R2\\nh', '?\\ni2\\n\\x02\\n\\x03\\nWhen', '?', '=', '1/(4R2', '),', 'we', 'obtain', 'E', 'f', '(??n?1', ')', '?', 'f', '(??', ')', '6', 'n2', '?', 'd', '+', 'Rk?0', '?', '??', 'k', '.\\n\\n(2)\\n\\nProof', 'technique.', 'We', 'adapt', 'and', 'extend', 'a', 'proof', 'technique', 'from', '[14]', 'which', 'is', 'based', 'on', 'nonasymptotic', 'expansions', 'in', 'powers', 'of', '?.', 'We', 'also', 'use', 'a', 'result', 'from', '[2]', 'which', 'studied', 'the', 'recursion', 'in\\nEq.', '(1),', 'with', 'xn', '?', 'xn', 'replaced', 'by', 'its', 'expectation', 'H.', 'See', '[15]', 'for', 'details.\\n\\nOptimality', 'of', 'bounds.', 'Our', 'bound', 'in', 'Eq.', '(2)', 'leads', 'to', 'a', 'rate', 'of', 'O(1/n),', 'which', 'is', 'known', 'to', 'be', 'optimal\\nfor', 'least-squares', 'regression', '(i.e.,', 'under', 'reasonable', 'assumptions,', 'no', 'algorithm,', 'even', 'more', 'complex\\nthan', 'averaged', 'SGD', 'can', 'have', 'a', 'better', 'dependence', 'in', 'n)', '[16].', 'The', 'term', '?', '2', 'd/n', 'is', 'also', 'unimprovable.\\n\\nInitial', 'conditions.', 'If', '?', 'is', 'small,', 'then', 'the', 'initial', 'condition', 'is', 'forgotten', 'more', 'slowly.', 'Note', 'that', 'with\\nadditional', 'strong', 'convexity', 'assumptions,', 'the', 'initial', 'condition', 'would', 'be', 'forgotten', 'faster', '(exponentially', 'fast', 'without', 'averaging),', 'which', 'is', 'one', 'of', 'the', 'traditional', 'uses', 'of', 'constant-step-size', 'LMS', '[17].\\nSpecificity', 'of', 'constant', 'step-sizes.', 'The', 'non-averaged', 'iterate', 'sequence', '(?n', ')', 'is', 'a', 'homogeneous\\nMarkov', 'chain;', 'under', 'appropriate', 'technical', 'conditions,', 'this', 'Markov', 'chain', 'has', 'a', 'unique', 'stationary\\n(invariant)', 'distribution', 'and', 'the', 'sequence', 'of', 'iterates', '(?n', ')', 'converges', 'in', 'distribution', 'to', 'this', 'invariant', 'distribution;', 'see', '[18,', 'Chapter', '17].', 'Denote', 'by', '??', 'the', 'invariant', 'distribution.', 'Assuming', 'that\\nthe', 'Markov', 'Chain', 'is', 'Harris-recurrent,', 'the', 'ergodic', 'theorem', 'for', 'Harris', 'Markov', 'chain', 'shows', 'that\\nPn?1\\ndef', 'R\\n???', '(d?),', 'which', 'is', 'the', 'mean', 'of', 'the\\n??n?1', '=', 'n?1', 'k=0', '?k', 'converges', 'almost-surely', 'to', '???', '=\\nstationary', 'distribution.', 'Taking', 'the', 'expectation', 'on', 'both', 'side', 'of', 'Eq.', '(1),', 'we', 'get', 'E[?n', ']', '?', '??', '=\\n(I', '?', '?H)(E[?n?1', ']', '?', '??', '),', 'which', 'shows,', 'using', 'that', 'limn??', 'E[?n', ']', '=', '???', 'that', 'H', '???', '=', 'H??', 'and\\ntherefore', '???', '=', '??', 'since', 'H', 'is', 'invertible.', 'Under', 'slightly', 'stronger', 'assumptions,', 'it', 'can', 'be', 'shown', 'that\\nP\\nlimn??', 'nE[(??n', '?', '??', ')2', ']', '=', 'Var?', '(?0', ')', '+', '2', '?', 'Cov?', '(?0', ',', '?k', ')', ',\\n?\\n\\nk=1\\n\\n?\\n\\nwhere', 'Cov??', '(?0', ',', '?k', ')', 'denotes', 'the', 'covariance', 'of', '?0', 'and', '?k', 'when', 'the', 'Markov', 'chain', 'is', 'started', 'from\\nstationarity.', 'This', 'implies', 'that', 'limn??', 'nE[f', '(??n', ')', '?', 'f', '(??', ')]', 'has', 'a', 'finite', 'limit.', 'Therefore,', 'this', 'interpretation', 'explains', 'why', 'the', 'averaging', 'produces', 'a', 'sequence', 'of', 'estimators', 'which', 'converges', 'to', 'the\\nsolution', '??', 'pointwise,', 'and', 'that', 'the', 'rate', 'of', 'convergence', 'of', 'E[f', '(?n', ')?f', '(??', ')]', 'is', 'of', 'order', 'O(1/n).', 'Note\\nthat', '(a)', 'our', 'result', 'is', 'stronger', 'since', 'it', 'is', 'independent', 'of', 'the', 'lowest', 'eigenvalue', 'of', 'H,', 'and', '(b)', 'for', 'other\\nlosses', 'than', 'quadratic,', 'the', 'same', 'properties', 'hold', 'except', 'that', 'the', 'mean', 'under', 'the', 'stationary', 'distribution\\ndoes', 'not', 'coincide', 'with', '??', 'and', 'its', 'distance', 'to', '??', 'is', 'typically', 'of', 'order', '?', '2', '(see', 'Section', '3).\\n2.2', 'Convergence', 'in', 'higher', 'orders\\nWe', 'are', 'now', 'going', 'to', 'consider', 'an', 'extra', 'assumption', 'in', 'order', 'to', 'bound', 'the', 'p-th', 'moment', 'of', 'the', 'excess\\nrisk', 'and', 'then', 'get', 'a', 'high-probability', 'bound.', 'Let', 'p', 'be', 'a', 'real', 'number', 'greater', 'than', '1.\\n(A7)', 'There', 'exists', 'R', '>', '0,', '?', '>', '0', 'and', '?', '>', '?', '>', '0', 'such', 'that,', 'for', 'all', 'n', '>', '1,', 'kxn', 'k2', '6', 'R2', 'a.s.,', 'and\\n\\x02\\n\\x03\\nEk?n', 'kp', '6', '?', 'p', 'Rp', 'and', 'E', '?n', '?', '?n', '4', '?', '2', 'H,\\n(3)\\n\\x01\\n2\\n(4)\\n?z', '?', 'F', ',', 'Ehz,', 'xn', 'i4', '6', '?', 'Ehz,', 'xn', 'i2', '=', '?hz,', 'Hzi2', '.\\n\\nThe', 'last', 'condition', 'in', 'Eq.', '(4)', 'says', 'that', 'the', 'kurtosis', 'of', 'the', 'projection', 'of', 'the', 'covariates', 'xn', 'on', 'any\\ndirection', 'z', '?', 'F', 'is', 'bounded.', 'Note', 'that', 'computing', 'the', 'constant', '?', 'happens', 'to', 'be', 'equivalent', 'to', 'the\\noptimization', 'problem', 'solved', 'by', 'the', 'FastICA', 'algorithm', '[19],', 'which', 'thus', 'provides', 'an', 'estimate', 'of', '?.', 'In\\nTable', '1,', 'we', 'provide', 'such', 'an', 'estimate', 'for', 'the', 'non-sparse', 'datasets', 'which', 'we', 'have', 'used', 'in', 'experiments,\\nwhile', 'we', 'consider', 'only', 'directions', 'z', 'along', 'the', 'axes', 'for', 'high-dimensional', 'sparse', 'datasets.', 'For', 'these\\ndatasets', 'where', 'a', 'given', 'variable', 'is', 'equal', 'to', 'zero', 'except', 'for', 'a', 'few', 'observations,', '?', 'is', 'typically', 'quite\\nlarge.', 'Adapting', 'and', 'analyzing', 'normalized', 'LMS', 'techniques', '[20]', 'to', 'this', 'set-up', 'is', 'likely', 'to', 'improve\\nthe', 'theoretical', 'robustness', 'of', 'the', 'algorithm', '(but', 'note', 'that', 'results', 'in', 'expectation', 'from', 'Theorem', '1', 'do\\nnot', 'use', '?).', 'The', 'next', 'theorem', 'provides', 'a', 'bound', 'for', 'the', 'p-th', 'moment', 'of', 'the', 'excess', 'risk.\\nTheorem', '2', 'Assume', '(A1-7).', 'For', 'any', 'real', 'p', '>', '1,', 'and', 'for', 'a', 'step-size', '?', '6', '1/(12p?R2),', 'we', 'have:\\nr\\n\\x12\\n\\x132\\n?\\n\\x0c\\n\\x0cp', '\\x011/p\\np\\n2\\n?\\n\\x0c\\n\\x0c\\nE', 'f', '(?n?1', ')', '?', 'f', '(??', ')\\n6\\n7?', 'd', '+', 'Rk?0', '?', '??', 'k', '3', '+\\n.\\n(5)\\n2n\\n?pR2\\n3\\n\\n\\x0c\\x0c\\n\\x0cp', '\\x011/p\\nFor', '?', '=', '1/(12p?R2),', 'we', 'get:', 'E\\x0cf', '(??n?1', ')', '?', 'f', '(??', ')\\x0c\\n6\\n\\np\\n2n\\n\\n?\\n\\x012\\n?\\n7?', 'd', '+', '6', '?Rk?0', '?', '??', 'k', '.\\n\\nNote', 'that', 'to', 'control', 'the', 'p-th', 'order', 'moment,', 'a', 'smaller', 'step-size', 'is', 'needed,', 'which', 'scales', 'as', '1/p.', 'We\\n2\\ncan', 'now', 'provide', 'a', 'high-probability', 'bound;', 'the', 'tails', 'decay', 'polynomially', 'as', '1/(n?', '12??R', ')', 'and', 'the\\nsmaller', 'the', 'step-size', '?,', 'the', 'lighter', 'the', 'tails.\\nCorollary', '1', 'For', 'any', 'step-size', 'such', 'that', '?', '6', '1/(12?R2),', 'any', '?', '?', '(0,', '1),\\n?\\n?\\n\\x032', '\\x13\\n\\x02', '?\\n\\x12\\n7?', 'd', '+', 'Rk?0', '?', '??', 'k(', '3', '+', '24?)\\n1\\n?\\nP', 'f', '(?n?1', ')', '?', 'f', '(??', ')', '>', '12??R2\\n6?.\\n24??R2\\nn?\\n\\n(6)\\n\\n3', 'Beyond', 'least-squares:', 'M-estimation\\nIn', 'Section', '2,', 'we', 'have', 'shown', 'that', 'for', 'least-squares', 'regression,', 'averaged', 'SGD', 'achieves', 'a', 'convergence\\nrate', 'of', 'O(1/n)', 'with', 'no', 'assumption', 'regarding', 'strong', 'convexity.', 'For', 'all', 'losses,', 'with', 'a', 'constant', 'stepsize', '?,', 'the', 'stationary\\ndistribution', '??', 'corresponding', 'to', 'the', 'homogeneous', 'Markov', 'chain', '(?n', ')', 'does\\nR\\nalways', 'satisfy', 'f', '?', '(?)??', '(d?)', '=', '0,', 'where', 'f', 'is', 'Rthe', 'generalization', 'error.', 'When', 'the', 'gradient', 'f', '?', 'is', 'linear\\n?\\n(i.e.,', 'f', 'is', 'quadratic),\\nR', 'then', 'this', 'implies', 'that', 'f', '(', '???', '(d?))', '=', '0,', 'i.e.,', 'the', 'averaged', 'recursion', '?converges\\n?\\npathwise', 'to', '??', '=', '???', '(d?)', 'which', 'coincides', 'withR', 'the', 'optimal', 'value', '??', '(defined\\nthrough', 'f', '(??', ')', '=', '0).\\nR\\nWhen', 'the', 'gradient', 'f', '?', 'is', 'no', 'longer', 'linear,', 'then', 'f', '?', '(?)??', '(d?)', '6=', 'f', '?', '(', '???', '(d?)).', 'Therefore,', 'for\\ngeneral', 'M', '-estimation', 'problems', 'we', 'should', 'expect', 'that', 'the', 'averaged', 'sequence', 'still', 'converges', 'at', 'rate\\nO(1/n)', 'to', 'the', 'mean', 'of', 'the', 'stationary', 'distribution', '???', ',', 'but', 'not', 'to', 'the', 'optimal', 'predictor', '??', '.', 'Typically,\\nthe', 'average', 'distance', 'between', '?n', 'and', '??', 'is', 'of', 'order', '?', '(see', 'Section', '4', 'and', '[21]),', 'while', 'for', 'the', 'averaged\\niterates', 'that', 'converge', 'pointwise', 'to', '???', ',', 'it', 'is', 'of', 'order', '?', '2', 'for', 'strongly', 'convex', 'problems', 'under', 'some\\nadditional', 'smoothness', 'conditions', 'on', 'the', 'loss', 'functions', '(these', 'are', 'satisfied,', 'for', 'example,', 'by', 'the\\nlogistic', 'loss', '[22]).\\nSince', 'quadratic', 'functions', 'may', 'be', 'optimized', 'with', 'rate', 'O(1/n)', 'under', 'weak', 'conditions,', 'we', 'are', 'going\\nto', 'use', 'a', 'quadratic', 'approximation', 'around', 'a', 'well', 'chosen', 'support', 'point,', 'which', 'shares', 'some', 'similarity\\nwith', 'the', 'Newton', 'procedure', '(however,', 'with', 'a', 'non', 'trivial', 'adaptation', 'to', 'the', 'stochastic', 'approximation\\nframework).', 'The', 'Newton', 'step', 'for', 'f', 'around', 'a', 'certain', 'point', '??', 'is', 'equivalent', 'to', 'minimizing', 'a', 'quadratic\\n?', 'i.e.,', 'g(?)', '=', 'f', '(?)\\n?', '+', 'hf', '?', '(?),\\n?', '?', '?', '?i\\n?', '+', '1', 'h?', '?', '?,\\n?', 'f', '??', '(?)(?\\n?', '?', '?)i.\\n?', 'If', 'fn', '(?)', 'def\\nsurrogate', 'g', 'of', 'f', 'around', '?,\\n=\\n2\\n1\\n?', '?\\n?', 'f', '??', '(?)(??\\n?\\n?', 'the\\n?\\n?\\nh??\\n?,\\n?)i;\\n?(yn', ',', 'h?,', 'xn', 'i),', 'then', 'g(?)', '=', 'Egn', '(?),', 'with', 'gn', '(?)', '=', 'f', '(?)+hf\\n(\\n?),\\n??\\n?i+\\nn\\nn\\n2\\nNewton', 'step', 'may', 'thus', 'be', 'solved', 'approximately', 'with', 'stochastic', 'approximation', '(here', 'constant-step\\nsize', 'LMS),', 'with', 'the', 'following', 'recursion:\\n\\x02\\n\\x03\\n?', '+', 'f', '??', '(?)(?\\n?', 'n?1', '?', '?)\\n?', '.\\n?n', '=', '?n?1', '?', '?g', '?', '(?n?1', ')', '=', '?n?1', '?', '?', 'f', '?', '(?)\\n(7)\\nn\\n\\nn\\n\\nn\\n\\n?', 'A\\nThis', 'is', 'equivalent', 'to', 'replacing', 'the', 'gradient\\nby', 'its', 'first-order', 'approximation', 'around', '?.\\ncrucial', 'point', 'is', 'that', 'for', 'machine', 'learning', 'scenarios', 'where', 'fn', 'is', 'a', 'loss', 'associated', 'to', 'a', 'single', 'data\\npoint,', 'its', 'complexity', 'is', 'only', 'twice', 'the', 'complexity', 'of', 'a', 'regular', 'stochastic', 'approximation', 'step,', 'since,\\nwith', 'fn', '(?)', '=', '?(yn', ',', 'hxn', ',', '?i),', 'fn??', '(?)', 'is', 'a', 'rank-one', 'matrix.\\nfn?', '(?n?1', ')\\n\\nChoice', 'of', 'support', 'points', 'for', 'quadratic', 'approximation.', 'An', 'important', 'aspect', 'is', 'the', 'choice', 'of', 'the\\n?', 'In', 'this', 'paper,', 'we', 'consider', 'two', 'strategies:\\nsupport', 'point', '?.\\n?\\n?', 'Two-step', 'procedure:', 'for', 'convex', 'losses,', 'averaged\\n?', 'SGD', 'with', 'a', 'step-size', 'decaying', 'at', 'O(1/', 'n)\\nachieves', 'a', 'rate', '(up', 'to', 'logarithmic', 'terms)', 'of', 'O(1/', 'n)', '[5,', '6].', 'We', 'may', 'thus', 'use', 'it', 'to', 'obtain', 'a', 'first\\ndecent', 'estimate.', 'The', 'two-stage', 'procedure', 'is', 'as', 'follows', '(and', 'uses', '2n', 'observations):', 'n', 'steps', 'of\\n?\\n?', 'and', 'then', 'averaged', 'LMS', 'for', 'the\\naveraged', 'SGD', 'with', 'constant', 'step', 'size', '?', '?', '1/', 'n', 'to', 'obtain', '?,\\n?\\nNewton', 'step', 'around', '?.', 'As', 'shown', 'below,', 'this', 'algorithm', 'achieves', 'the', 'rate', 'O(1/n)', 'for', 'logistic\\nregression.', 'However,', 'it', 'is', 'not', 'the', 'most', 'efficient', 'in', 'practice.\\n?', 'Support', 'point', '=', 'current', 'average', 'iterate:', 'we', 'simply', 'consider', 'the', 'current', 'averaged', 'iterate', '??n?1\\n?', 'leading', 'to', 'the', 'recursion:\\nas', 'the', 'support', 'point', '?,\\n\\x02\\n\\x03\\n?n', '=', '?n?1', '?', '?', 'fn?', '(??n?1', ')', '+', 'fn??', '(??n?1', ')(?n?1', '?', '??n?1', ')', '.\\n(8)\\nAlthough', 'this', 'algorithm', 'has', 'shown', 'to', 'be', 'the', 'most', 'efficient', 'in', 'practice', '(see', 'Section', '4)', 'we', 'currently', 'have', 'no', 'proof', 'of', 'convergence.', 'Given', 'that', 'the', 'behavior', 'of', 'the', 'algorithms', 'does', 'not', 'change\\nmuch', 'when', 'the', 'support', 'point', 'is', 'updated', 'less', 'frequently', 'than', 'each', 'iteration,', 'there', 'may', 'be', 'some\\nconnections', 'to', 'two-time-scale', 'algorithms', '(see,', 'e.g.,', '[23]).', 'In', 'Section', '4,', 'we', 'also', 'consider', 'several\\nother', 'strategies', 'based', 'on', 'doubling', 'tricks.\\n4\\n\\n\\x0cInterestingly,', 'for', 'non-quadratic', 'functions,', 'our', 'algorithm', 'imposes', 'a', 'new', 'bias', '(by', 'replacing', 'the', 'true\\ngradient', 'by', 'an', 'approximation', 'which', 'is', 'only', 'valid', 'close', 'to', '??n?1', ')', 'in', 'order', 'to', 'reach', 'faster', 'convergence\\n(due', 'to', 'the', 'linearity', 'of', 'the', 'underlying', 'gradients).\\nRelationship', 'with', 'one-step-estimators.', 'One-step', 'estimators', '(see,', 'e.g.,', '[24])', 'typically', 'take', 'any\\nestimator', 'with', 'O(1/n)-convergence', 'rate,', 'and', 'make', 'a', 'full', 'Newton', 'step', 'to', 'obtain', 'an', 'efficient', 'estimator', '(i.e.,', 'one', 'that', 'achieves', 'the', 'Cramer-Rao', 'lower', 'bound).', 'Although', 'our', 'novel', 'algorithm', 'is', 'largely\\ninspired', 'by', 'one-step', 'estimators,\\nour', 'situation', 'is', 'slightly', 'different', 'since', 'our', 'first', 'estimator', 'has', 'only\\n?\\nconvergence', 'rate', 'O(1/', 'n)', 'and', 'is', 'estimated', 'on', 'different', 'observations.\\n3.1', 'Self-concordance', 'and', 'logistic', 'regression\\nWe', 'make', 'the', 'following', 'assumptions:\\n(B1)', 'F', 'is', 'a', 'd-dimensional', 'Euclidean', 'space,', 'with', 'd', '>', '1.\\n(B2)', 'The', 'observations', '(xn', ',', 'yn', ')', '?', 'F', '?', '{?1,', '1}', 'are', 'independent', 'and', 'identically', 'distributed.\\n\\x02\\n\\x03\\n(B3)', 'We', 'consider', 'f', '(?)', '=', 'E', '?(yn', ',', 'hxn', ',', '?i)', ',', 'with', 'the', 'following', 'assumption', 'on', 'the', 'loss', 'function', '?\\n(whenever', 'we', 'take', 'derivatives', 'of', '?,', 'this', 'will', 'be', 'with', 'respect', 'to', 'the', 'second', 'variable):\\n?(y,', 'y?)', '?', '{?1,', '1}', '?', 'R,', '??', '(y,', 'y?)', '6', '1,', '???', '(y,', 'y?)', '6', '1/4,', '|????', '(y,', 'y?)|', '6', '???', '(y,', 'y?).\\n\\nWe', 'denote', 'by', '??', 'a', 'global', 'minimizer', 'of', 'f', ',', 'which', 'we', 'thus', 'assume', 'to', 'exist,', 'and', 'we', 'denote', 'by\\nH', '=', 'f', '??', '(??', ')', 'the', 'Hessian', 'operator', 'at', 'a', 'global', 'optimum', '??', '.\\n(B4)', 'We', 'assume', 'that', 'there', 'exists', 'R', '>', '0,', '?', '>', '0', 'and', '?', '>', '0', 'such', 'that', 'kxn', 'k2', '6', 'R2', 'almost', 'surely,', 'and\\n\\x02\\n\\x03\\n\\x02\\n\\x03\\nE', 'xn', '?', 'xn', '4', '?E', '???', '(yn', ',', 'h??', ',', 'xn', 'i)xn', '?', 'xn', '=', '?H,\\n(9)\\n\\x03\\x01\\n\\x03\\n\\x02\\n\\x02', '??\\n2\\n(10)\\n?z', '?', 'F', ',', '?', '?', 'F', ',', 'E', '?', '(yn', ',', 'h?,', 'xn', 'i)2', 'hz,', 'xn', 'i4', '6', '?', 'E', '???', '(yn', ',', 'h?,', 'xn', 'i)hz,', 'xn', 'i2', '.\\n\\nAssumption', '(B3)', 'is', 'satisfied', 'for', 'the', 'logistic', 'loss', 'and', 'extends', 'to', 'all', 'generalized', 'linear', 'models', '(see\\nmore', 'details', 'in', '[22]),', 'and', 'the', 'relationship', 'between', 'the', 'third', 'derivative', 'and', 'second', 'derivative', 'of', 'the\\nloss', '?', 'is', 'often', 'referred', 'to', 'as', 'self-concordance', '(see', '[9,', '25]', 'and', 'references', 'therein).', 'Note', 'moreover\\nthat', 'we', 'must', 'have', '?', '>', '4', 'and', '?', '>', '1.\\nA', 'loose', 'upper', 'bound', 'for', '?', 'is', '1/', 'inf', 'n', '???', '(yn', ',', 'h??', ',', 'xn', 'i)', 'but', 'in', 'practice,', 'it', 'is', 'typically', 'much', 'smaller\\n(see', 'Table', '1).', 'The', 'condition', 'in', 'Eq.', '(10)', 'is', 'hard', 'to', 'check', 'because', 'it', 'is', 'uniform', 'in', '?.', 'With', 'a', 'slightly\\nmore', 'complex', 'proof,', 'we', 'could', 'restrict', '?', 'to', 'be', 'close', 'to', '??', ';', 'with', 'such', 'constraints,', 'the', 'value', 'of', '?', 'we\\nhave', 'found', 'is', 'close', 'to', 'the', 'one', 'from', 'Section', '2.2', '(i.e.,', 'without', 'the', 'terms', 'in', '???', '(yn', ',', 'h?,', 'xn', 'i)).\\nTheorem', '3', 'Assume', '(B1-4),', 'and', 'consider', 'the', 'vector', '?n', 'obtained', 'as', 'follows:', '(a)', 'perform', 'n', 'steps', 'of\\n?\\naveraged', 'stochastic', 'gradient', 'descent', 'with', 'constant', 'step', 'size', '1/2R2', 'n,', 'to', 'get', '??n', ',', 'and', '(b)', 'perform', 'n\\nstep', 'of', 'averaged', 'LMS', 'with', 'constant', 'step-size', '1/R2', 'for', 'the', 'quadratic', 'approximation', 'of', 'f', 'around', '??n', '.\\nIf', 'n', '>', '(19', '+', '9Rk?0', '?', '??', 'k)4', ',', 'then\\n?3/2', '?3', 'd\\n(16Rk?0', '?', '??', 'k', '+', '19)4', '.\\n(11)\\nEf', '(?n', ')', '?', 'f', '(??', ')', '6\\nn\\nWe', 'get', 'an', 'O(1/n)', 'convergence', 'rate', 'without', 'assuming', 'strong', 'convexity,', 'even', 'locally,', 'thus', 'improving\\non', 'results', 'from', '[22]', 'where', 'the', 'the', 'rate', 'is', 'proportional', 'to', '1/(n?min(H)).', 'The', 'proof', 'relies', 'on', 'selfconcordance', 'properties', 'and', 'the', 'sharp', 'analysis', 'of', 'the', 'Newton', 'step', '(see', '[15]', 'for', 'details).\\n\\n4', 'Experiments\\n4.1', 'Synthetic', 'data\\nLeast-mean-square', 'algorithm.', 'We', 'consider', 'normally', 'distributed', 'inputs,', 'with', 'covariance', 'matrix', 'H\\nthat', 'has', 'random', 'eigenvectors', 'and', 'eigenvalues', '1/k,', 'k', '=', '1,', '.', '.', '.', ',', 'd.', 'The', 'outputs', 'are', 'generated', 'from', 'a\\nlinear', 'function', 'with', 'homoscedastic', 'noise', 'with', 'unit', 'signal', 'to', 'noise-ratio.', 'We', 'consider', 'd', '=', '20', 'and\\nthe?least-mean-square', 'algorithm', 'with', 'several', 'settings', 'of', 'the', 'step', 'size', '?n', ',', 'constant', 'or', 'proportional', 'to\\n1/', 'n.', 'Here', 'R2', 'denotes', 'the', 'average', 'radius', 'of', 'the', 'data,', 'i.e.,', 'R2', '=', 'tr', 'H.', 'In', 'the', 'left', 'plot', 'of', 'Figure', '1,\\nwe', 'show', 'the', 'results,', 'averaged', 'over', '10', 'replications.\\nWithout', 'averaging,', 'the', 'algorithm', 'with', 'constant', 'step-size', 'does', 'not', 'converge', 'pointwise', '(it', 'oscillates),\\nand', 'its', 'average', 'excess', 'risk', 'decays', 'as', 'a', 'linear', 'function', 'of', '?', '(indeed,', 'the', 'gap', 'between', 'each', 'values', 'of\\nthe', 'constant', 'step-size', 'is', 'close', 'to', 'log10', '(4),', 'which', 'corresponds', 'to', 'a', 'linear', 'function', 'in', '?).\\n5\\n\\n\\x0c0\\n\\nsynthetic', 'square\\n\\nsynthetic', 'logistic', '?', '1\\n\\nsynthetic', 'logistic', '?', '2\\n\\n?2\\n2\\n\\n?3\\n?4\\n?5\\n0\\n\\n1/2R\\n2\\n1/8R\\n2\\n1/32R\\n2', '1/2\\n1/2R', 'n\\n2\\n\\n4\\nlog', '(n)\\n\\n6\\n\\n0\\nlog10[f(?)?f(?*)]\\n\\n?1\\n\\nlog10[f(?)?f(?*)]\\n\\nlog10[f(?)?f(?*)]\\n\\n0\\n?1\\n?2\\n2\\n\\n?3\\n?4\\n?5\\n0\\n\\n1/2R\\n2\\n1/8R\\n2\\n1/32R\\n2', '1/2\\n1/2R', 'n\\n2\\n\\n4\\nlog', '(n)\\n\\n10\\n\\n10\\n\\n6\\n\\n?1\\n?2\\n?3\\n?4\\n?5\\n0\\n\\np\\n\\nevery', '2\\nevery', 'iter.\\n2?step\\n2?step?dbl.\\n2\\n\\n4\\nlog', '(n)\\n\\n6\\n\\n10\\n\\nFigure', '1:', 'Synthetic', 'data.', 'Left:', 'least-squares', 'regression.', 'Middle:', 'logistic', 'regression', 'with', 'averaged\\nSGD', 'with', 'various', 'step-sizes,', 'averaged', '(plain)', 'and', 'non-averaged', '(dashed).', 'Right:', 'various', 'Newtonbased', 'schemes', 'for', 'the', 'same', 'logistic', 'regression', 'problem.', 'Best', 'seen', 'in', 'color;', 'see', 'text', 'for', 'details.\\nWith', 'averaging,', 'the', 'algorithm', 'with', 'constant', 'step-size', 'does', 'converge', 'at', 'rate', 'O(1/n),', 'and', 'for', 'all\\nvalues', 'of', 'the', 'constant', '?,', 'the', 'rate', 'is', 'actually', 'the', 'same.', 'Moreover', '(although', 'it', 'is', 'not', 'shown', 'in', 'the\\nplots),', 'the', 'standard', 'deviation', 'is', 'much', 'lower.\\n?\\nWith', '?\\ndecaying', 'step-size', '?n', '=', '1/(2R2', 'n)', 'and', 'without', 'averaging,', 'the', 'convergence', 'rate', 'is\\nO(1/', 'n),', 'and', 'improves', 'to', 'O(1/n)', 'with', 'averaging.\\nLogistic', 'regression.', 'We', 'consider', 'the', 'same', 'input', 'data', 'as', 'for', 'least-squares,', 'but', 'now', 'generates', 'outputs\\nfrom', 'the', 'logistic', 'probabilistic', 'model.', 'We', 'compare', 'several', 'algorithms', 'and', 'display', 'the', 'results', 'in\\nFigure', '1', '(middle', 'and', 'right', 'plots).\\nOn', 'the', 'middle', 'plot,', 'we', 'consider', 'SGD;', 'without', 'averaging,', 'the', 'algorithm', 'with', 'constant', 'step-size', 'does\\nnot', 'converge', 'and', 'its', 'average', 'excess', 'risk', 'reaches', 'a', 'constant', 'value', 'which', 'is', 'a', 'linear', 'function', 'of', '?\\n(indeed,', 'the', 'gap', 'between', 'each', 'values', 'of', 'the', 'constant', 'step-size', 'is', 'close', 'to', 'log10', '(4)).', 'With', 'averaging,\\nthe', 'algorithm', 'does', 'converge,', 'but', 'as', 'opposed', 'to', 'least-squares,', 'to', 'a', 'point', 'which', 'is', 'not', 'the', 'optimal\\nsolution,', 'with', 'an', 'error', 'proportional', 'to', '?', '2', '(the', 'gap', 'between', 'curves', 'is', 'twice', 'as', 'large).\\nOn', 'the', 'right', 'plot,', 'we', 'consider', 'various', 'variations', 'of', 'our', 'online', 'Newton-approximation', 'scheme.', 'The\\n?2-step?', 'algorithm', 'is', 'the', 'one', 'for', 'which', 'our', 'convergence', 'rate', 'holds', '(n', 'being', 'the', 'total', 'number', 'of\\nexamples,', 'we', 'perform', 'n/2', 'steps', 'of', 'averaged', 'SGD,', 'then', 'n/2', 'steps', 'of', 'LMS).', 'Not', 'surprisingly,', 'it', 'is\\nnot', 'the', 'best', 'in', 'practice', '(in', 'particular', 'at', 'n/2,', 'when', 'starting', 'the', 'constant-size', 'LMS,', 'the', 'performance\\nworsens', 'temporarily).', 'It', 'is', 'classical', 'to', 'use', 'doubling', 'tricks', 'to', 'remedy', 'this', 'problem', 'while', 'preserving\\nconvergence', 'rates', '[26],', 'this', 'is', 'done', 'in', '?2-step-dbl.?,', 'which', 'avoids', 'the', 'previous', 'erratic', 'behavior.\\nWe', 'have', 'also', 'considered', 'getting', 'rid', 'of', 'the', 'first', 'stage', 'where', 'plain', 'averaged', 'stochastic', 'gradient', 'is\\nused', 'to', 'obtain', 'a', 'support', 'point', 'for', 'the', 'quadratic', 'approximation.', 'We', 'now', 'consider', 'only', 'Newton-steps\\nbut', 'change', 'only', 'these', 'support', 'points.', 'We', 'consider', 'updating', 'the', 'support', 'point', 'at', 'every', 'iteration,', 'i.e.,\\nthe', 'recursion', 'from', 'Eq.', '(8),', 'while', 'we', 'also', 'consider', 'updating', 'it', 'every', 'dyadic', 'point', '(?dbl.-approx?).\\nThe', 'last', 'two', 'algorithms', 'perform', 'very', 'similarly', 'and', 'achieve', 'the', 'O(1/n)', 'early.', 'In', 'all', 'experiments', 'on\\nreal', 'data,', 'we', 'have', 'considered', 'the', 'simplest', 'variant', '(which', 'corresponds', 'to', 'Eq.', '(8)).\\n4.2', 'Standard', 'benchmarks\\nWe', 'have', 'considered', '6', 'benchmark', 'datasets', 'which', 'are', 'often', 'used', 'in', 'comparing', 'large-scale', 'optimization', 'methods.', 'The', 'datasets', 'are', 'described', 'in', 'Table', '1', 'and', 'vary', 'in', 'values', 'of', 'd,', 'n', 'and', 'sparsity', 'levels.\\nThese', 'are', 'all', 'finite', 'binary', 'classification', 'datasets', 'with', 'outputs', 'in', '{?1,', '1}.', 'For', 'least-squares', 'and', 'logistic', 'regression,', 'we', 'have', 'followed', 'the', 'following', 'experimental', 'protocol:', '(1)', 'remove', 'all', 'outliers', '(i.e.,\\nsample', 'points', 'xn', 'whose', 'norm', 'is', 'greater', 'than', '5', 'times', 'the', 'average', 'norm),', '(2)', 'divide', 'the', 'dataset', 'in', 'two\\nequal', 'parts,', 'one', 'for', 'training,', 'one', 'for', 'testing,', '(3)', 'sample', 'within', 'the', 'training', 'dataset', 'with', 'replacement,\\nfor', '100', 'times', 'the', 'number', 'of', 'observations', 'in', 'the', 'training', 'set', '(this', 'corresponds', 'to', '100', 'effective', 'passes;\\nin', 'all', 'plots,', 'a', 'black', 'dashed', 'line', 'marks', 'the', 'first', 'effective', 'pass),', '(4)', 'compute', 'averaged', 'costs', 'on', 'training\\nand', 'testing', 'data', '(based', 'on', '10', 'replications).', 'All', 'the', 'costs', 'are', 'shown', 'in', 'log-scale,', 'normalized', 'to', 'that\\nthe', 'first', 'iteration', 'leads', 'to', 'f', '(?0', ')', '?', 'f', '(??', ')', '=', '1.\\nAll', 'algorithms', 'that', 'we', 'consider', '(ours', 'and', 'others)', 'have', 'a', 'step-size,', 'and', 'typically', 'a', 'theoretical', 'value\\nthat', 'ensures', 'convergence.', 'We', 'consider', 'two', 'settings:', '(1)', 'one', 'when', 'this', 'theoretical', 'value', 'is', 'used,', '(2)\\none', 'with', 'the', 'best', 'testing', 'error', 'after', 'one', 'effective', 'pass', 'through', 'the', 'data', '(testing', 'powers', 'of', '4', 'times', 'the\\ntheoretical', 'step-size).\\n6\\n\\n\\x0cHere,', 'we', 'only', 'consider', 'covertype,', 'alpha,', 'sido', 'and', 'news,', 'as', 'well', 'as', 'test', 'errors.', 'For', 'all', 'training', 'errors\\nand', 'the', 'two', 'other', 'datasets', '(quantum,', 'rcv1),', 'see', '[15].\\nLeast-squares', 'regression.', 'We', 'compare', 'three', 'algorithms:\\naveraged', 'SGD', 'with', 'constant', 'step-size,\\n?\\naveraged', 'SGD', 'with', 'step-size', 'decaying', 'as', 'C/R2', 'n,', 'and', 'the', 'stochastic', 'averaged', 'gradient', '(SAG)\\nmethod', 'which', 'is', 'dedicated', 'to', 'finite', 'training', 'data', 'sets', '[27],', 'which', 'has', 'shown', 'state-of-the-art', 'performance', 'in', 'this', 'set-up.', 'We', 'show', 'the', 'results', 'in', 'the', 'two', 'left', 'plots', 'of', 'Figure', '2', 'and', 'Figure', '3.\\n?\\nAveraged', 'SGD', 'with', 'decaying', 'step-size', 'equal', 'to', 'C/R2', 'n', 'is', 'slowest', '(except', 'for', 'sido).', 'In', 'particular,', 'when', 'the', 'best', 'constant', 'C', 'is', 'used', '(right', 'columns),', 'the', 'performance', 'typically', 'starts', 'to', 'increase\\nsignificantly.', 'With', 'that', 'step', 'size,', 'even', 'after', '100', 'passes,', 'there', 'is', 'no', 'sign', 'of', 'overfitting,', 'even', 'for', 'the\\nhigh-dimensional', 'sparse', 'datasets.\\nSAG', 'and', 'constant-step-size', 'averaged', 'SGD', 'exhibit', 'the', 'best', 'behavior,', 'for', 'the', 'theoretical', 'step-sizes\\nand', 'the', 'best', 'constants,', 'with', 'a', 'significant', 'advantage', 'for', 'constant-step-size', 'SGD.', 'The', 'non-sparse\\ndatasets', 'do', 'not', 'lead', 'to', 'overfitting,', 'even', 'close', 'to', 'the', 'global', 'optimum', 'of', 'the', '(unregularized)', 'training\\nobjectives,', 'while', 'the', 'sparse', 'datasets', 'do', 'exhibit', 'some', 'overfitting', 'after', 'more', 'than', '10', 'passes.\\nLogistic', 'regression.', 'We', 'also', 'compare', 'two', 'additional', 'algorithms:', 'our', 'Newton-based', 'technique', 'and\\n1\\n?Adagrad?', '[7],', 'which', 'is', 'a', 'stochastic', 'gradient', 'method', 'with', 'a', 'form', 'a', 'diagonal\\n?', 'scaling', 'that', 'allows', 'to\\nreduce', 'the', 'convergence', 'rate', '(which', 'is', 'still', 'in', 'theory', 'proportional', 'to', 'O(1/', 'n)).', 'We', 'show', 'results', 'in\\nthe', 'two', 'right', 'plots', 'of', 'Figure', '2', 'and', 'Figure', '3.\\n?\\nAveraged', 'SGD', 'with', 'decaying', 'step-size', 'proportional', 'to', '1/R2', 'n', 'has', 'the', 'same', 'behavior', 'than', 'for\\nleast-squares', '(step-size', 'harder', 'to', 'tune,', 'always', 'inferior', 'performance', 'except', 'for', 'sido).\\nSAG,', 'constant-step-size', 'SGD', 'and', 'the', 'novel', 'Newton', 'technique', 'tend', 'to', 'behave', 'similarly', '(good', 'with\\ntheoretical', 'step-size,', 'always', 'among', 'the', 'best', 'methods).', 'They', 'differ', 'notably', 'in', 'some', 'aspects:', '(1)\\nSAG', 'converges', 'quicker', 'for', 'the', 'training', 'errors', '(shown', 'in', '[15])', 'while', 'it', 'is', 'a', 'bit', 'slower', 'for', 'the', 'testing\\nerror,', '(2)', 'in', 'some', 'instances,', 'constant-step-size', 'averaged', 'SGD', 'does', 'underfit', '(covertype,', 'alpha,', 'news),\\nwhich', 'is', 'consistent', 'with', 'the', 'lack', 'of', 'convergence', 'to', 'the', 'global', 'optimum', 'mentioned', 'earlier,', '(3)', 'the\\nnovel', 'online', 'Newton', 'algorithm', 'is', 'consistently', 'better.\\nOn', 'the', 'non-sparse', 'datasets,', 'Adagrad', 'performs', 'similarly', 'to', 'the', 'Newton-type', 'method', '(often', 'better', 'in\\nearly', 'iterations', 'and', 'worse', 'later),', 'except', 'for', 'the', 'alpha', 'dataset', 'where', 'the', 'step-size', 'is', 'harder', 'to', 'tune\\n(the', 'best', 'step-size', 'tends', 'to', 'have', 'early', 'iterations', 'that', 'make', 'the', 'cost', 'go', 'up', 'significantly).', 'On', 'sparse\\ndatasets', 'like', 'rcv1,', 'the', 'performance', 'is', 'essentially', 'the', 'same', 'as', 'Newton.', 'On', 'the', 'sido', 'data', 'set,', 'Adagrad\\n(with', 'fixed', 'steps', 'size,', 'left', 'column)', 'achieves', 'a', 'good', 'testing', 'loss', 'quickly', 'then', 'levels', 'off,', 'for', 'reasons\\nwe', 'cannot', 'explain.', 'On', 'the', 'news', 'dataset,', 'it', 'is', 'inferior', 'without', 'parameter-tuning', 'and', 'a', 'bit', 'better', 'with.\\nAdagrad', 'uses', 'a', 'diagonal', 'rescaling;', 'it', 'could', 'be', 'combined', 'with', 'our', 'technique,', 'early', 'experiments', 'show\\nthat', 'it', 'improves', 'results', 'but', 'that', 'it', 'is', 'more', 'sensitive', 'to', 'the', 'choice', 'of', 'step-size.\\nOverall,', 'even', 'with', 'd', 'and', '?', 'very', 'large', '(where', 'our', 'bounds', 'are', 'vacuous),', 'the', 'performance', 'of', 'our\\nalgorithm', 'still', 'achieves', 'the', 'state', 'of', 'the', 'art,', 'while', 'being', 'more', 'robust', 'to', 'the', 'selection', 'of', 'the', 'step-size:\\nfiner', 'quantities', 'likes', 'degrees', 'of', 'freedom', '[13]', 'should', 'be', 'able', 'to', 'quantify', 'more', 'accurately', 'the', 'quality\\nof', 'the', 'new', 'algorithms.\\n\\n5', 'Conclusion\\nIn', 'this', 'paper,', 'we', 'have', 'presented', 'two', 'stochastic', 'approximation', 'algorithms', 'that', 'can', 'achieve', 'rates\\nof', 'O(1/n)', 'for', 'logistic', 'and', 'least-squares', 'regression,', 'without', 'strong-convexity', 'assumptions.', 'Our\\nanalysis', 'reinforces', 'the', 'key', 'role', 'of', 'averaging', 'in', 'obtaining', 'fast', 'rates,', 'in', 'particular', 'with', 'large', 'stepsizes.', 'Our', 'work', 'can', 'naturally', 'be', 'extended', 'in', 'several', 'ways:', '(a)', 'an', 'analysis', 'of', 'the', 'algorithm', 'that\\nupdates', 'the', 'support', 'point', 'of', 'the', 'quadratic', 'approximation', 'at', 'every', 'iteration,', '(b)', 'proximal', 'extensions\\n(easy', 'to', 'implement,', 'but', 'potentially', 'harder', 'to', 'analyze);', '(c)', 'adaptive', 'ways', 'to', 'find', 'the', 'constant-stepsize;', '(d)', 'step-sizes', 'that', 'depend', 'on', 'the', 'iterates', 'to', 'increase', 'robustness,', 'like', 'in', 'normalized', 'LMS', '[20],\\nand', '(e)', 'non-parametric', 'analysis', 'to', 'improve', 'our', 'theoretical', 'results', 'for', 'large', 'values', 'of', 'd.\\nAcknowledgements.', 'Francis', 'Bach', 'was', 'partially', 'supported', 'by', 'the', 'European', 'Research', 'Council\\n(SIERRA', 'Project).', 'We', 'thank', 'Aymeric', 'Dieuleveut', 'and', 'Nicolas', 'Flammarion', 'for', 'helpful', 'discussions.\\n1\\n\\nSince', 'a', 'bound', 'on', 'k??', 'k', 'is', 'not', 'available,', 'we', 'have', 'used', 'step-sizes', 'proportional', 'to', '1/', 'supn', 'kxn', 'k?', '.\\n\\n7\\n\\n\\x0cTable', '1:', 'Datasets', 'used', 'in', 'our', 'experiments.', 'We', 'report', 'the', 'proportion', 'of', 'non-zero', 'entries,', 'as', 'well\\nas', 'estimates', 'for', 'the', 'constant', '?', 'and', '?', 'used', 'in', 'our', 'theoretical', 'results,', 'together', 'with', 'the', 'non-sharp\\nconstant', 'which', 'is', 'typically', 'used', 'in', 'analysis', 'of', 'logistic', 'regression', 'and', 'which', 'our', 'analysis', 'avoids\\n(these', 'are', 'computed', 'for', 'non-sparse', 'datasets', 'only).\\nd\\n79\\n55\\n501\\n4', '933\\n47', '237\\n1', '355', '192\\n\\nn\\n50', '000\\n581', '012\\n500', '000\\n12', '678\\n20', '242\\n19', '996\\n\\ncovertype', 'square', 'C=opt', 'test\\n\\n0\\n\\n0\\n\\n?0.5\\n\\n?0.5\\n\\n?1\\n\\n?1\\n\\n?1.5\\n\\n?1.5\\n\\n?2\\n\\n?2\\n\\n?2.5\\n?3\\n0\\n\\n1/R2\\n1/R2n1/2\\nSAG\\n2\\n\\n?2.5\\n?3\\n\\n4\\nlog10(n)\\n\\n6\\n\\n0\\n\\nlog10[f(?)?f(?*)]\\n\\nalpha', 'square', 'C=1', 'test\\n1\\n\\n0.5\\n\\n0.5\\n\\n0\\n\\n0\\n\\n?0.5\\n\\n?0.5\\n\\n?1\\n\\n?1\\n\\n?1.5\\n?2\\n0\\n\\n1/R2\\n1/R2n1/2\\nSAG\\n2\\n\\n?1.5\\n?2\\n\\n4\\nlog10(n)\\n\\n6\\n\\n0\\n\\nC/R2\\nC/R2n1/2\\nSAG\\n2\\n\\n4\\nlog10(n)\\n\\n6\\n\\n0\\n\\n2\\n\\n?1\\n\\n?1\\n2\\n\\n?2\\n\\n0.5\\n\\n?3\\n\\n4\\nlog10(n)\\n\\n6\\n\\nalpha', 'logistic', 'C=1', 'test\\n\\n0\\n\\n0.5\\n\\n0\\n\\n0\\n?0.5\\n\\n?1\\n?1.5\\n\\n?2.5\\n0\\n\\n6\\n\\n2\\n\\nC/R\\n2', '1/2\\nC/R', 'n\\nSAG\\nAdagrad\\nNewton\\n\\n?2\\n\\n?0.5\\n\\n?2\\n\\n4\\nlog10(n)\\n\\n2\\n\\n1/R\\n2', '1/2\\n1/R', 'n\\nSAG\\nAdagrad\\nNewton\\n\\n0\\n\\nC/R2\\nC/R2n1/2\\nSAG\\n\\ncovertype', 'logistic', 'C=opt', 'test\\n0\\n\\n?3\\n\\nalpha', 'square', 'C=opt', 'test\\n\\n1\\n\\n1/', 'inf', 'n', '???', '(yn', ',', 'h??', ',', 'xn', 'i)\\n8.5', '?102\\n3', '?1012\\n8', '?104\\n?\\n?\\n?\\n\\n?\\n16\\n160\\n18\\n?\\n?\\n?\\n\\ncovertype', 'logistic', 'C=1', 'test\\n\\nlog10[f(?)?f(?*)]\\n\\nlog10[f(?)?f(?*)]\\n\\ncovertype', 'square', 'C=1', 'test\\n\\n?\\n5.8', '?102\\n9.6', '?102\\n6\\n1.3', '?104\\n2', '?104\\n2', '?104\\n\\nsparsity\\n100', '%\\n100', '%\\n100', '%\\n10', '%\\n0.2', '%\\n0.03', '%\\n\\nlog10[f(?)?f(?*)]\\n\\nName\\nquantum\\ncovertype\\nalpha\\nsido\\nrcv1\\nnews\\n\\n?1\\n\\n1/R2\\n1/R2n1/2\\nSAG\\nAdagrad\\nNewton\\n2\\n\\n?1.5\\n?2\\n\\n4\\nlog10(n)\\n\\n6\\n\\n?2.5\\n0\\n\\n2\\n\\n4\\nlog10(n)\\n\\n6\\n\\nalpha', 'logistic', 'C=opt', 'test\\n\\nC/R2\\nC/R2n1/2\\nSAG\\nAdagrad\\nNewton\\n2\\n\\n4\\nlog10(n)\\n\\n6\\n\\nFigure', '2:', 'Test', 'performance', 'for', 'least-square', 'regression', '(two', 'left', 'plots)', 'and', 'logistic', 'regression', '(two\\nright', 'plots).', 'From', 'top', 'to', 'bottom:', 'covertype,', 'alpha.', 'Left:', 'theoretical', 'steps,', 'right:', 'steps', 'optimized', 'for\\nperformance', 'after', 'one', 'effective', 'pass', 'through', 'the', 'data.', 'Best', 'seen', 'in', 'color.\\n\\n1/R2\\n1/R2n1/2\\nSAG\\n\\n0\\n\\n?0.5\\n\\n?0.5\\n\\n?1\\n\\n?1\\n\\n0\\n\\n2\\n4\\nlog10(n)\\n\\n0\\n\\nlog10[f(?)?f(?*)]\\n\\nnews', 'square', 'C=1', 'test\\n\\nsido', 'logistic', 'C=1', 'test\\n\\nC/R2\\nC/R2n1/2\\nSAG\\n\\n2\\n4\\nlog10(n)\\n\\nsido', 'logistic', 'C=opt', 'test\\n\\n?0.5\\n\\n1/R2\\n0\\n1/R2n1/2\\nSAG\\nAdagrad\\nNewton', '?0.5\\n\\n?1\\n\\n?1\\n\\n0\\n\\n0\\n\\n2\\n4\\nlog10(n)\\n\\n0\\n\\nnews', 'logistic', 'C=1', 'test\\n\\nnews', 'square', 'C=opt', 'test\\n0.2\\n\\n0.2\\n\\n0.2\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n?0.2\\n\\n?0.2\\n\\n?0.4\\n?0.6\\n?0.8\\n0\\n\\n?0.4\\n1/R2\\n1/R2n1/2\\nSAG\\n2\\n\\nlog10(n)\\n\\n?0.6\\n?0.8\\n4\\n\\n0\\n\\nC/R2\\nC/R2n1/2\\nSAG\\n2\\n\\nlog10(n)\\n\\n?0.2\\n?0.4\\n?0.6\\n?0.8\\n?1\\n0\\n\\n4\\n\\nC/R2\\nC/R2n1/2\\nSAG\\nAdagrad\\nNewton\\n\\n2\\n4\\nlog10(n)\\nnews', 'logistic', 'C=opt', 'test\\n\\n0.2\\n\\nlog10[f(?)?f(?*)]\\n\\nlog10[f(?)?f(?*)]\\n\\n0\\n\\nsido', 'square', 'C=opt', 'test\\n\\nlog10[f(?)?f(?*)]\\n\\nsido', 'square', 'C=1', 'test\\n\\n?0.2\\n1/R2\\n1/R2n1/2\\nSAG\\nAdagrad\\nNewton\\n2\\n\\nlog10(n)\\n\\n?0.4\\n?0.6\\n?0.8\\n4\\n\\n?1\\n0\\n\\nC/R2\\nC/R2n1/2\\nSAG\\nAdagrad\\nNewton\\n2\\n\\nlog10(n)\\n\\n4\\n\\nFigure', '3:', 'Test', 'performance', 'for', 'least-square', 'regression', '(two', 'left', 'plots)', 'and', 'logistic', 'regression', '(two\\nright', 'plots).', 'From', 'top', 'to', 'bottom:', 'sido,', 'news.', 'Left:', 'theoretical', 'steps,', 'right:', 'steps', 'optimized', 'for\\nperformance', 'after', 'one', 'effective', 'pass', 'through', 'the', 'data.', 'Best', 'seen', 'in', 'color.\\n8\\n\\n\\x0cReferences\\n[1]', 'H.', 'Robbins', 'and', 'S.', 'Monro.', 'A', 'stochastic', 'approximation', 'method.', 'The', 'Annals', 'of', 'Mathematical\\nStatistics,', 'pages', '400?407,', '1951.\\n[2]', 'B.', 'T.', 'Polyak', 'and', 'A.', 'B.', 'Juditsky.', 'Acceleration', 'of', 'stochastic', 'approximation', 'by', 'averaging.', 'SIAM\\nJournal', 'on', 'Control', 'and', 'Optimization,', '30(4):838?855,', '1992.\\n[3]', 'L.', 'Bottou', 'and', 'O.', 'Bousquet.', 'The', 'tradeoffs', 'of', 'large', 'scale', 'learning.', 'In', 'Adv.', 'NIPS,', '2008.\\n[4]', 'S.', 'Shalev-Shwartz,', 'Y.', 'Singer,', 'and', 'N.', 'Srebro.', 'Pegasos:', 'Primal', 'estimated', 'sub-gradient', 'solver\\nfor', 'SVM.', 'In', 'Proc.', 'ICML,', '2007.\\n[5]', 'A.', 'Nemirovski,', 'A.', 'Juditsky,', 'G.', 'Lan,', 'and', 'A.', 'Shapiro.', 'Robust', 'stochastic', 'approximation', 'approach\\nto', 'stochastic', 'programming.', 'SIAM', 'Journal', 'on', 'Optimization,', '19(4):1574?1609,', '2009.\\n[6]', 'F.', 'Bach', 'and', 'E.', 'Moulines.', 'Non-asymptotic', 'analysis', 'of', 'stochastic', 'approximation', 'algorithms', 'for\\nmachine', 'learning.', 'In', 'Adv.', 'NIPS,', '2011.\\n[7]', 'J.', 'Duchi,', 'E.', 'Hazan,', 'and', 'Y.', 'Singer.', 'Adaptive', 'subgradient', 'methods', 'for', 'online', 'learning', 'and\\nstochastic', 'optimization.', 'Journal', 'of', 'Machine', 'Learning', 'Research,', '12:2121?2159,', '2010.\\n[8]', 'A.', 'S.', 'Nemirovsky', 'and', 'D.', 'B.', 'Yudin.', 'Problem', 'complexity', 'and', 'method', 'efficiency', 'in', 'optimization.\\nWiley', '&', 'Sons,', '1983.\\n[9]', 'Y.', 'Nesterov.', 'Introductory', 'lectures', 'on', 'convex', 'optimization.', 'Kluwer,', '2004.\\n[10]', 'G.', 'Lan.', 'An', 'optimal', 'method', 'for', 'stochastic', 'composite', 'optimization.', 'Mathematical', 'Programming,', '133(1-2):365?397,', '2012.\\n[11]', 'L.', 'Gy?orfi', 'and', 'H.', 'Walk.', 'On', 'the', 'averaged', 'stochastic', 'approximation', 'for', 'linear', 'regression.', 'SIAM\\nJournal', 'on', 'Control', 'and', 'Optimization,', '34(1):31?61,', '1996.\\n[12]', 'H.', 'J.', 'Kushner', 'and', 'G.', 'G.', 'Yin.', 'Stochastic', 'approximation', 'and', 'recursive', 'algorithms', 'and', 'applications.', 'Springer-Verlag,', 'second', 'edition,', '2003.\\n[13]', 'C.', 'Gu.', 'Smoothing', 'spline', 'ANOVA', 'models.', 'Springer,', '2002.\\n[14]', 'R.', 'Aguech,', 'E.', 'Moulines,', 'and', 'P.', 'Priouret.', 'On', 'a', 'perturbation', 'approach', 'for', 'the', 'analysis', 'of\\nstochastic', 'tracking', 'algorithms.', 'SIAM', 'J.', 'Control', 'and', 'Optimization,', '39(3):872?899,', '2000.\\n[15]', 'F.', 'Bach', 'and', 'E.', 'Moulines.', 'Non-strongly-convex', 'smooth', 'stochastic', 'approximation', 'with', 'convergence', 'rate', 'O(1/n).', 'Technical', 'Report', '00831977,', 'HAL,', '2013.\\n[16]', 'A.', 'B.', 'Tsybakov.', 'Optimal', 'rates', 'of', 'aggregation.', 'In', 'Proc.', 'COLT,', '2003.\\n[17]', 'O.', 'Macchi.', 'Adaptive', 'processing:', 'The', 'least', 'mean', 'squares', 'approach', 'with', 'applications', 'in', 'transmission.', 'Wiley', 'West', 'Sussex,', '1995.\\n[18]', 'S.', 'Meyn', 'and', 'R.', 'Tweedie.', 'Markov', 'Chains', 'and', 'Stochastic', 'Stability.', 'Cambridge', 'U.', 'P.,', '2009.\\n[19]', 'A.', 'Hyv?arinen', 'and', 'E.', 'Oja.', 'A', 'fast', 'fixed-point', 'algorithm', 'for', 'independent', 'component', 'analysis.\\nNeural', 'computation,', '9(7):1483?1492,', '1997.\\n[20]', 'N.J.', 'Bershad.', 'Analysis', 'of', 'the', 'normalized', 'LMS', 'algorithm', 'with', 'Gaussian', 'inputs.', 'IEEE', 'Transactions', 'on', 'Acoustics,', 'Speech', 'and', 'Signal', 'Processing,', '34(4):793?806,', '1986.\\n[21]', 'A.', 'Nedic', 'and', 'D.', 'Bertsekas.', 'Convergence', 'rate', 'of', 'incremental', 'subgradient', 'algorithms.', 'Stochastic', 'Optimization:', 'Algorithms', 'and', 'Applications,', 'pages', '263?304,', '2000.\\n[22]', 'F.', 'Bach.', 'Adaptivity', 'of', 'averaged', 'stochastic', 'gradient', 'descent', 'to', 'local', 'strong', 'convexity', 'for', 'logistic', 'regression.', 'Technical', 'Report', '00804431-v2,', 'HAL,', '2013.\\n[23]', 'V.', 'S.', 'Borkar.', 'Stochastic', 'approximation', 'with', 'two', 'time', 'scales.', 'Systems', '&', 'Control', 'Letters,\\n29(5):291?294,', '1997.\\n[24]', 'A.', 'W.', 'Van', 'der', 'Vaart.', 'Asymptotic', 'statistics,', 'volume', '3.', 'Cambridge', 'Univ.', 'Press,', '2000.\\n[25]', 'F.', 'Bach.', 'Self-concordant', 'analysis', 'for', 'logistic', 'regression.', 'Electronic', 'Journal', 'of', 'Statistics,\\n4:384?414,', '2010.\\n[26]', 'E.', 'Hazan', 'and', 'S.', 'Kale.', 'Beyond', 'the', 'regret', 'minimization', 'barrier:', 'an', 'optimal', 'algorithm', 'for\\nstochastic', 'strongly-convex', 'optimization.', 'In', 'Proc.', 'COLT,', '2001.\\n[27]', 'M.', 'Schmidt,', 'N.', 'Le', 'Roux,', 'and', 'F.', 'Bach.', 'Minimizing', 'finite', 'sums', 'with', 'the', 'stochastic', 'average\\ngradient.', 'Technical', 'Report', '00860051,', 'HAL,', '2013.\\n9\\n\\n\\x0c']\n",
            "\n",
            "\n",
            " Tokenized and lemmatized document: \n",
            "['strong', 'convex', 'smooth', 'stochast', 'approxim', 'converg', 'rate', 'eric', 'moulin', 'ltci', 'telecom', 'paristech', 'pari', 'franc', 'eric', 'moulin', 'enst', 'franci', 'bach', 'inria', 'sierra', 'project', 'team', 'ecol', 'normal', 'erieur', 'pari', 'franc', 'franci', 'bach', 'abstract', 'consid', 'stochast', 'approxim', 'problem', 'convex', 'function', 'minim', 'give', 'knowledg', 'unbias', 'estim', 'gradient', 'certain', 'point', 'framework', 'includ', 'machin', 'learn', 'method', 'base', 'minim', 'empir', 'risk', 'focus', 'problem', 'strong', 'convex', 'previous', 'know', 'algorithm', 'achiev', 'converg', 'rate', 'function', 'valu', 'iter', 'consid', 'analyz', 'algorithm', 'achiev', 'rate', 'classic', 'supervis', 'learn', 'problem', 'squar', 'regress', 'averag', 'stochast', 'gradient', 'descent', 'constant', 'step', 'size', 'achiev', 'desir', 'rate', 'logist', 'regress', 'achiev', 'simpl', 'novel', 'stochast', 'gradient', 'algorithm', 'construct', 'success', 'local', 'quadrat', 'approxim', 'loss', 'function', 'preserv', 'run', 'time', 'complex', 'stochast', 'gradient', 'descent', 'algorithm', 'provid', 'asymptot', 'analysi', 'general', 'error', 'expect', 'high', 'probabl', 'squar', 'extens', 'experi', 'show', 'outperform', 'exist', 'approach', 'introduct', 'larg', 'scale', 'machin', 'learn', 'problem', 'ubiquit', 'area', 'scienc', 'engin', 'face', 'larg', 'amount', 'data', 'practition', 'typic', 'prefer', 'algorithm', 'process', 'observ', 'time', 'stochast', 'approxim', 'algorithm', 'stochast', 'gradient', 'descent', 'variant', 'introduc', 'year', 'remain', 'wide', 'studi', 'method', 'context', 'convex', 'function', 'defin', 'euclidean', 'space', 'give', 'consid', 'minim', 'denot', 'data', 'denot', 'loss', 'function', 'convex', 'respect', 'second', 'variabl', 'includ', 'logist', 'squar', 'regress', 'stochast', 'approxim', 'framework', 'independ', 'ident', 'distribut', 'pair', 'observ', 'sequenti', 'predictor', 'defin', 'updat', 'pair', 'see', 'partial', 'understand', 'properti', 'affect', 'problem', 'difficulti', 'strong', 'convex', 'twice', 'differenti', 'uniform', 'strict', 'posit', 'lower', 'bind', 'hessian', 'properti', 'observ', 'proper', 'step', 'size', 'averag', 'achiev', 'rate', 'strong', 'convex', 'case', 'achiev', 'nonstrong', 'convex', 'case', 'match', 'lower', 'bound', 'main', 'issu', 'strong', 'convex', 'typic', 'machin', 'learn', 'problem', 'high', 'dimension', 'correl', 'variabl', 'strong', 'convex', 'constant', 'zero', 'close', 'zero', 'case', 'smaller', 'make', 'strong', 'convex', 'method', 'better', 'paper', 'obtain', 'algorithm', 'deal', 'arbitrarili', 'small', 'strong', 'convex', 'constant', 'achiev', 'rate', 'smooth', 'play', 'central', 'role', 'context', 'determinist', 'optim', 'know', 'converg', 'rat', 'smooth', 'optim', 'better', 'smooth', 'optim', 'stochast', 'optim', 'smooth', 'lead', 'improv', 'constant', 'rate', 'remain', 'strong', 'convex', 'problem', 'squar', 'loss', 'logist', 'loss', 'smooth', 'loss', 'obtain', 'algorithm', 'converg', 'rate', 'strong', 'convex', 'assumpt', 'precis', 'squar', 'regress', 'section', 'averag', 'stochast', 'gradient', 'descent', 'constant', 'step', 'size', 'achiev', 'desir', 'rate', 'logist', 'regress', 'achiev', 'novel', 'stochast', 'gradient', 'algorithm', 'construct', 'success', 'local', 'quadrat', 'approxim', 'loss', 'function', 'preserv', 'run', 'time', 'complex', 'stochast', 'gradient', 'descent', 'section', 'algorithm', 'provid', 'asymptot', 'analysi', 'general', 'error', 'expect', 'high', 'probabl', 'squar', 'extens', 'experi', 'standard', 'machin', 'learn', 'benchmark', 'show', 'section', 'outperform', 'exist', 'approach', 'constant', 'step', 'size', 'mean', 'squar', 'algorithm', 'section', 'consid', 'stochast', 'approxim', 'squar', 'regress', 'refer', 'mean', 'squar', 'algorithm', 'novelti', 'converg', 'result', 'constant', 'step', 'size', 'averag', 'consid', 'explicit', 'asymptot', 'rate', 'depend', 'lowest', 'eigenvalu', 'covari', 'matrix', 'converg', 'expect', 'follow', 'assumpt', 'dimension', 'euclidean', 'space', 'observ', 'independ', 'ident', 'distribut', 'ekxn', 'ekzn', 'finit', 'denot', 'covari', 'oper', 'loss', 'general', 'assum', 'invert', 'project', 'minim', 'subspac', 'lie', 'sure', 'eigenvalu', 'arbitrarili', 'small', 'global', 'minimum', 'attain', 'certain', 'denot', 'residu', 'general', 'true', 'model', 'specifi', 'studi', 'stochast', 'gradient', 'mean', 'squar', 'recurs', 'defin', 'start', 'consid', 'averag', 'iter', 'exist', 'denot', 'order', 'self', 'adjoint', 'oper', 'posit', 'semi', 'definit', 'discuss', 'assumpt', 'assumpt', 'standard', 'stochast', 'approxim', 'note', 'squar', 'problem', 'form', 'respons', 'predict', 'linear', 'function', 'consid', 'slight', 'general', 'case', 'squar', 'need', 'quadrat', 'approxim', 'logist', 'loss', 'section', 'note', 'assumpt', 'assum', 'model', 'specifi', 'assumpt', 'true', 'squar', 'regress', 'bound', 'data', 'sure', 'sure', 'similar', 'inequ', 'hold', 'output', 'variabl', 'hold', 'data', 'infinit', 'support', 'gaussian', 'mixtur', 'gaussian', 'covari', 'matric', 'mixtur', 'compon', 'lower', 'upper', 'bound', 'constant', 'time', 'matrix', 'note', 'finit', 'dimension', 'assumpt', 'relax', 'requir', 'notion', 'similar', 'degre', 'freedom', 'outsid', 'scope', 'paper', 'goal', 'section', 'provid', 'asymptot', 'bind', 'expect', 'depend', 'smallest', 'zero', 'eigenvalu', 'arbitrarili', 'small', 'scale', 'theorem', 'assum', 'constant', 'step', 'size', 'obtain', 'proof', 'techniqu', 'adapt', 'extend', 'proof', 'techniqu', 'base', 'nonasymptot', 'expans', 'power', 'result', 'studi', 'recurs', 'replac', 'expect', 'detail', 'optim', 'bound', 'bind', 'lead', 'rate', 'know', 'optim', 'squar', 'regress', 'reason', 'assumpt', 'algorithm', 'complex', 'averag', 'better', 'depend', 'term', 'unimprov', 'initi', 'condit', 'small', 'initi', 'condit', 'forget', 'slowli', 'note', 'addit', 'strong', 'convex', 'assumpt', 'initi', 'condit', 'forget', 'faster', 'exponenti', 'fast', 'averag', 'tradit', 'use', 'constant', 'step', 'size', 'specif', 'constant', 'step', 'size', 'averag', 'iter', 'sequenc', 'homogen', 'markov', 'chain', 'appropri', 'technic', 'condit', 'markov', 'chain', 'uniqu', 'stationari', 'invari', 'distribut', 'sequenc', 'iter', 'converg', 'distribut', 'invari', 'distribut', 'chapter', 'denot', 'invari', 'distribut', 'assum', 'markov', 'chain', 'harri', 'recurr', 'ergod', 'theorem', 'harri', 'markov', 'chain', 'show', 'mean', 'converg', 'sure', 'stationari', 'distribut', 'take', 'expect', 'show', 'limn', 'invert', 'slight', 'stronger', 'assumpt', 'show', 'limn', 'denot', 'covari', 'markov', 'chain', 'start', 'stationar', 'impli', 'limn', 'finit', 'limit', 'interpret', 'explain', 'averag', 'produc', 'sequenc', 'estim', 'converg', 'solut', 'pointwis', 'rate', 'converg', 'order', 'note', 'result', 'stronger', 'independ', 'lowest', 'eigenvalu', 'loss', 'quadrat', 'properti', 'hold', 'mean', 'stationari', 'distribut', 'coincid', 'distanc', 'typic', 'order', 'section', 'converg', 'higher', 'order', 'go', 'consid', 'extra', 'assumpt', 'order', 'bind', 'moment', 'excess', 'risk', 'high', 'probabl', 'bind', 'real', 'number', 'greater', 'exist', 'condit', 'say', 'kurtosi', 'project', 'covari', 'direct', 'bound', 'note', 'comput', 'constant', 'happen', 'equival', 'optim', 'problem', 'solv', 'fastica', 'algorithm', 'provid', 'estim', 'tabl', 'provid', 'estim', 'spars', 'dataset', 'experi', 'consid', 'direct', 'ax', 'high', 'dimension', 'spars', 'dataset', 'dataset', 'give', 'variabl', 'equal', 'zero', 'observ', 'typic', 'larg', 'adapt', 'analyz', 'normal', 'techniqu', 'like', 'improv', 'theoret', 'robust', 'algorithm', 'note', 'result', 'expect', 'theorem', 'theorem', 'provid', 'bind', 'moment', 'excess', 'risk', 'theorem', 'assum', 'real', 'step', 'size', 'note', 'control', 'order', 'moment', 'smaller', 'step', 'size', 'need', 'scale', 'provid', 'high', 'probabl', 'bind', 'tail', 'decay', 'polynomi', 'smaller', 'step', 'size', 'lighter', 'tail', 'corollari', 'step', 'size', 'squar', 'estim', 'section', 'show', 'squar', 'regress', 'averag', 'achiev', 'converg', 'rate', 'assumpt', 'strong', 'convex', 'loss', 'constant', 'stepsiz', 'stationari', 'distribut', 'correspond', 'homogen', 'markov', 'chain', 'satisfi', 'rthe', 'general', 'error', 'gradient', 'linear', 'quadrat', 'impli', 'averag', 'recurs', 'converg', 'pathwis', 'coincid', 'withr', 'optim', 'valu', 'defin', 'gradient', 'longer', 'linear', 'general', 'estim', 'problem', 'expect', 'averag', 'sequenc', 'converg', 'rate', 'mean', 'stationari', 'distribut', 'optim', 'predictor', 'typic', 'averag', 'distanc', 'order', 'section', 'averag', 'iter', 'converg', 'pointwis', 'order', 'strong', 'convex', 'problem', 'addit', 'smooth', 'condit', 'loss', 'function', 'satisfi', 'exampl', 'logist', 'loss', 'quadrat', 'function', 'optim', 'rate', 'weak', 'condit', 'go', 'quadrat', 'approxim', 'choos', 'support', 'point', 'share', 'similar', 'newton', 'procedur', 'trivial', 'adapt', 'stochast', 'approxim', 'framework', 'newton', 'step', 'certain', 'point', 'equival', 'minim', 'quadrat', 'surrog', 'newton', 'step', 'solv', 'approxim', 'stochast', 'approxim', 'constant', 'step', 'size', 'follow', 'recurs', 'equival', 'replac', 'gradient', 'order', 'approxim', 'crucial', 'point', 'machin', 'learn', 'scenario', 'loss', 'associ', 'singl', 'data', 'point', 'complex', 'twice', 'complex', 'regular', 'stochast', 'approxim', 'step', 'rank', 'matrix', 'choic', 'support', 'point', 'quadrat', 'approxim', 'import', 'aspect', 'choic', 'paper', 'consid', 'strategi', 'support', 'point', 'step', 'procedur', 'convex', 'loss', 'averag', 'step', 'size', 'decay', 'achiev', 'rate', 'logarithm', 'term', 'obtain', 'decent', 'estim', 'stage', 'procedur', 'follow', 'use', 'observ', 'step', 'averag', 'averag', 'constant', 'step', 'size', 'obtain', 'newton', 'step', 'show', 'algorithm', 'achiev', 'rate', 'logist', 'regress', 'effici', 'practic', 'support', 'point', 'current', 'averag', 'iter', 'simpli', 'consid', 'current', 'averag', 'iter', 'lead', 'recurs', 'support', 'point', 'algorithm', 'show', 'effici', 'practic', 'section', 'current', 'proof', 'converg', 'give', 'behavior', 'algorithm', 'chang', 'support', 'point', 'updat', 'frequent', 'iter', 'connect', 'time', 'scale', 'algorithm', 'section', 'consid', 'strategi', 'base', 'doubl', 'trick', 'interest', 'quadrat', 'function', 'algorithm', 'impos', 'bias', 'replac', 'true', 'gradient', 'approxim', 'valid', 'close', 'order', 'reach', 'faster', 'converg', 'linear', 'underli', 'gradient', 'relationship', 'step', 'estim', 'step', 'estim', 'typic', 'estim', 'converg', 'rate', 'newton', 'step', 'obtain', 'effici', 'estim', 'achiev', 'cramer', 'lower', 'bind', 'novel', 'algorithm', 'larg', 'inspir', 'step', 'estim', 'situat', 'slight', 'differ', 'estim', 'converg', 'rate', 'estim', 'differ', 'observ', 'self', 'concord', 'logist', 'regress', 'follow', 'assumpt', 'dimension', 'euclidean', 'space', 'observ', 'independ', 'ident', 'distribut', 'consid', 'follow', 'assumpt', 'loss', 'function', 'deriv', 'respect', 'second', 'variabl', 'denot', 'global', 'minim', 'assum', 'exist', 'denot', 'hessian', 'oper', 'global', 'optimum', 'assum', 'exist', 'sure', 'assumpt', 'satisfi', 'logist', 'loss', 'extend', 'general', 'linear', 'model', 'detail', 'relationship', 'deriv', 'second', 'deriv', 'loss', 'refer', 'self', 'concord', 'refer', 'note', 'loos', 'upper', 'bind', 'practic', 'typic', 'smaller', 'tabl', 'condit', 'hard', 'check', 'uniform', 'slight', 'complex', 'proof', 'restrict', 'close', 'constraint', 'valu', 'close', 'section', 'term', 'theorem', 'assum', 'consid', 'vector', 'obtain', 'follow', 'perform', 'step', 'averag', 'stochast', 'gradient', 'descent', 'constant', 'step', 'size', 'perform', 'step', 'averag', 'constant', 'step', 'size', 'quadrat', 'approxim', 'converg', 'rate', 'assum', 'strong', 'convex', 'local', 'improv', 'result', 'rate', 'proport', 'proof', 'reli', 'selfconcord', 'properti', 'sharp', 'analysi', 'newton', 'step', 'detail', 'experi', 'synthet', 'data', 'mean', 'squar', 'algorithm', 'consid', 'normal', 'distribut', 'input', 'covari', 'matrix', 'random', 'eigenvector', 'eigenvalu', 'output', 'generat', 'linear', 'function', 'homoscedast', 'nois', 'unit', 'signal', 'nois', 'ratio', 'consid', 'mean', 'squar', 'algorithm', 'set', 'step', 'size', 'constant', 'proport', 'denot', 'averag', 'radius', 'data', 'leav', 'plot', 'figur', 'result', 'averag', 'replic', 'averag', 'algorithm', 'constant', 'step', 'size', 'converg', 'pointwis', 'oscil', 'averag', 'excess', 'risk', 'decay', 'linear', 'function', 'valu', 'constant', 'step', 'size', 'close', 'correspond', 'linear', 'function', 'synthet', 'squar', 'synthet', 'logist', 'synthet', 'logist', 'iter', 'step', 'step', 'figur', 'synthet', 'data', 'leav', 'squar', 'regress', 'middl', 'logist', 'regress', 'averag', 'step', 'size', 'averag', 'plain', 'averag', 'dash', 'right', 'newtonbas', 'scheme', 'logist', 'regress', 'problem', 'best', 'see', 'color', 'text', 'detail', 'averag', 'algorithm', 'constant', 'step', 'size', 'converg', 'rate', 'valu', 'constant', 'rate', 'actual', 'show', 'plot', 'standard', 'deviat', 'lower', 'decay', 'step', 'size', 'averag', 'converg', 'rate', 'improv', 'averag', 'logist', 'regress', 'consid', 'input', 'data', 'squar', 'generat', 'output', 'logist', 'probabilist', 'model', 'compar', 'algorithm', 'display', 'result', 'figur', 'middl', 'right', 'plot', 'middl', 'plot', 'consid', 'averag', 'algorithm', 'constant', 'step', 'size', 'converg', 'averag', 'excess', 'risk', 'reach', 'constant', 'valu', 'linear', 'function', 'valu', 'constant', 'step', 'size', 'close', 'averag', 'algorithm', 'converg', 'oppos', 'squar', 'point', 'optim', 'solut', 'error', 'proport', 'curv', 'twice', 'larg', 'right', 'plot', 'consid', 'variat', 'onlin', 'newton', 'approxim', 'scheme', 'step', 'algorithm', 'converg', 'rate', 'hold', 'total', 'number', 'exampl', 'perform', 'step', 'averag', 'step', 'surpris', 'best', 'practic', 'particular', 'start', 'constant', 'size', 'perform', 'worsen', 'temporarili', 'classic', 'doubl', 'trick', 'remedi', 'problem', 'preserv', 'converg', 'rat', 'step', 'avoid', 'previous', 'errat', 'behavior', 'consid', 'get', 'stage', 'plain', 'averag', 'stochast', 'gradient', 'obtain', 'support', 'point', 'quadrat', 'approxim', 'consid', 'newton', 'step', 'chang', 'support', 'point', 'consid', 'updat', 'support', 'point', 'iter', 'recurs', 'consid', 'updat', 'dyadic', 'point', 'approx', 'algorithm', 'perform', 'similar', 'achiev', 'earli', 'experi', 'real', 'data', 'consid', 'simplest', 'variant', 'correspond', 'standard', 'benchmark', 'consid', 'benchmark', 'dataset', 'compar', 'larg', 'scale', 'optim', 'method', 'dataset', 'describ', 'tabl', 'vari', 'valu', 'sparsiti', 'level', 'finit', 'binari', 'classif', 'dataset', 'output', 'squar', 'logist', 'regress', 'follow', 'follow', 'experiment', 'protocol', 'remov', 'outlier', 'sampl', 'point', 'norm', 'greater', 'time', 'averag', 'norm', 'divid', 'dataset', 'equal', 'part', 'train', 'test', 'sampl', 'train', 'dataset', 'replac', 'time', 'number', 'observ', 'train', 'correspond', 'effect', 'pass', 'plot', 'black', 'dash', 'line', 'mark', 'effect', 'pass', 'comput', 'averag', 'cost', 'train', 'test', 'data', 'base', 'replic', 'cost', 'show', 'scale', 'normal', 'iter', 'lead', 'algorithm', 'consid', 'step', 'size', 'typic', 'theoret', 'valu', 'ensur', 'converg', 'consid', 'set', 'theoret', 'valu', 'best', 'test', 'error', 'effect', 'pass', 'data', 'test', 'power', 'time', 'theoret', 'step', 'size', 'consid', 'covertyp', 'alpha', 'sido', 'news', 'test', 'error', 'train', 'error', 'dataset', 'quantum', 'squar', 'regress', 'compar', 'algorithm', 'averag', 'constant', 'step', 'size', 'averag', 'step', 'size', 'decay', 'stochast', 'averag', 'gradient', 'method', 'dedic', 'finit', 'train', 'data', 'set', 'show', 'state', 'perform', 'result', 'leav', 'plot', 'figur', 'figur', 'averag', 'decay', 'step', 'size', 'equal', 'slowest', 'sido', 'particular', 'best', 'constant', 'right', 'column', 'perform', 'typic', 'start', 'increas', 'signific', 'step', 'size', 'pass', 'sign', 'overfit', 'high', 'dimension', 'spars', 'dataset', 'constant', 'step', 'size', 'averag', 'exhibit', 'best', 'behavior', 'theoret', 'step', 'size', 'best', 'constant', 'signific', 'advantag', 'constant', 'step', 'size', 'spars', 'dataset', 'lead', 'overfit', 'close', 'global', 'optimum', 'unregular', 'train', 'object', 'spars', 'dataset', 'exhibit', 'overfit', 'pass', 'logist', 'regress', 'compar', 'addit', 'algorithm', 'newton', 'base', 'techniqu', 'adagrad', 'stochast', 'gradient', 'method', 'form', 'diagon', 'scale', 'allow', 'reduc', 'converg', 'rate', 'theori', 'proport', 'result', 'right', 'plot', 'figur', 'figur', 'averag', 'decay', 'step', 'size', 'proport', 'behavior', 'squar', 'step', 'size', 'harder', 'tune', 'inferior', 'perform', 'sido', 'constant', 'step', 'size', 'novel', 'newton', 'techniqu', 'tend', 'behav', 'similar', 'good', 'theoret', 'step', 'size', 'best', 'method', 'differ', 'notabl', 'aspect', 'converg', 'quicker', 'train', 'error', 'show', 'slower', 'test', 'error', 'instanc', 'constant', 'step', 'size', 'averag', 'underfit', 'covertyp', 'alpha', 'news', 'consist', 'lack', 'converg', 'global', 'optimum', 'mention', 'earlier', 'novel', 'onlin', 'newton', 'algorithm', 'consist', 'better', 'spars', 'dataset', 'adagrad', 'perform', 'similar', 'newton', 'type', 'method', 'better', 'earli', 'iter', 'wors', 'later', 'alpha', 'dataset', 'step', 'size', 'harder', 'tune', 'best', 'step', 'size', 'tend', 'earli', 'iter', 'cost', 'signific', 'spars', 'dataset', 'like', 'perform', 'essenti', 'newton', 'sido', 'data', 'adagrad', 'fix', 'step', 'size', 'leav', 'column', 'achiev', 'good', 'test', 'loss', 'quick', 'level', 'reason', 'explain', 'news', 'dataset', 'inferior', 'paramet', 'tune', 'better', 'adagrad', 'use', 'diagon', 'rescal', 'combin', 'techniqu', 'earli', 'experi', 'improv', 'result', 'sensit', 'choic', 'step', 'size', 'overal', 'larg', 'bound', 'vacuous', 'perform', 'algorithm', 'achiev', 'state', 'robust', 'select', 'step', 'size', 'finer', 'quantiti', 'like', 'degre', 'freedom', 'abl', 'quantifi', 'accur', 'qualiti', 'algorithm', 'conclus', 'paper', 'present', 'stochast', 'approxim', 'algorithm', 'achiev', 'rat', 'logist', 'squar', 'regress', 'strong', 'convex', 'assumpt', 'analysi', 'reinforc', 'role', 'averag', 'obtain', 'fast', 'rat', 'particular', 'larg', 'stepsiz', 'work', 'natur', 'extend', 'way', 'analysi', 'algorithm', 'updat', 'support', 'point', 'quadrat', 'approxim', 'iter', 'proxim', 'extens', 'easi', 'implement', 'potenti', 'harder', 'analyz', 'adapt', 'way', 'constant', 'stepsiz', 'step', 'size', 'depend', 'iter', 'increas', 'robust', 'like', 'normal', 'parametr', 'analysi', 'improv', 'theoret', 'result', 'larg', 'valu', 'franci', 'bach', 'partial', 'support', 'european', 'research', 'council', 'sierra', 'project', 'thank', 'aymer', 'dieuleveut', 'nicola', 'flammarion', 'help', 'discuss', 'bind', 'avail', 'step', 'size', 'proport', 'supn', 'tabl', 'dataset', 'experi', 'report', 'proport', 'zero', 'entri', 'estim', 'constant', 'theoret', 'result', 'sharp', 'constant', 'typic', 'analysi', 'logist', 'regress', 'analysi', 'avoid', 'comput', 'spars', 'dataset', 'covertyp', 'squar', 'test', 'alpha', 'squar', 'test', 'alpha', 'logist', 'test', 'adagrad', 'newton', 'adagrad', 'newton', 'covertyp', 'logist', 'test', 'alpha', 'squar', 'test', 'covertyp', 'logist', 'test', 'covertyp', 'squar', 'test', 'sparsiti', 'quantum', 'covertyp', 'alpha', 'sido', 'news', 'adagrad', 'newton', 'alpha', 'logist', 'test', 'adagrad', 'newton', 'figur', 'test', 'perform', 'squar', 'regress', 'leav', 'plot', 'logist', 'regress', 'right', 'plot', 'covertyp', 'alpha', 'leav', 'theoret', 'step', 'right', 'step', 'optim', 'perform', 'effect', 'pass', 'data', 'best', 'see', 'color', 'news', 'squar', 'test', 'sido', 'logist', 'test', 'sido', 'logist', 'test', 'adagrad', 'newton', 'news', 'logist', 'test', 'news', 'squar', 'test', 'adagrad', 'newton', 'news', 'logist', 'test', 'sido', 'squar', 'test', 'sido', 'squar', 'test', 'adagrad', 'newton', 'adagrad', 'newton', 'figur', 'test', 'perform', 'squar', 'regress', 'leav', 'plot', 'logist', 'regress', 'right', 'plot', 'sido', 'news', 'leav', 'theoret', 'step', 'right', 'step', 'optim', 'perform', 'effect', 'pass', 'data', 'best', 'see', 'color', 'refer', 'robbin', 'monro', 'stochast', 'approxim', 'method', 'annal', 'mathemat', 'statist', 'page', 'polyak', 'juditski', 'acceler', 'stochast', 'approxim', 'averag', 'siam', 'journal', 'control', 'optim', 'bottou', 'bousquet', 'tradeoff', 'larg', 'scale', 'learn', 'nip', 'shalev', 'shwartz', 'singer', 'srebro', 'pegaso', 'primal', 'estim', 'gradient', 'solver', 'proc', 'icml', 'nemirovski', 'juditski', 'shapiro', 'robust', 'stochast', 'approxim', 'approach', 'stochast', 'program', 'siam', 'journal', 'optim', 'bach', 'moulin', 'asymptot', 'analysi', 'stochast', 'approxim', 'algorithm', 'machin', 'learn', 'nip', 'duchi', 'hazan', 'singer', 'adapt', 'subgradi', 'method', 'onlin', 'learn', 'stochast', 'optim', 'journal', 'machin', 'learn', 'research', 'nemirovski', 'yudin', 'problem', 'complex', 'method', 'effici', 'optim', 'wiley', 'son', 'nesterov', 'introductori', 'lectur', 'convex', 'optim', 'kluwer', 'optim', 'method', 'stochast', 'composit', 'optim', 'mathemat', 'program', 'orfi', 'walk', 'averag', 'stochast', 'approxim', 'linear', 'regress', 'siam', 'journal', 'control', 'optim', 'kushner', 'stochast', 'approxim', 'recurs', 'algorithm', 'applic', 'springer', 'verlag', 'second', 'edit', 'smooth', 'spline', 'anova', 'model', 'springer', 'aguech', 'moulin', 'priouret', 'perturb', 'approach', 'analysi', 'stochast', 'track', 'algorithm', 'siam', 'control', 'optim', 'bach', 'moulin', 'strong', 'convex', 'smooth', 'stochast', 'approxim', 'converg', 'rate', 'technic', 'report', 'tsybakov', 'optim', 'rat', 'aggreg', 'proc', 'colt', 'macchi', 'adapt', 'process', 'mean', 'squar', 'approach', 'applic', 'transmiss', 'wiley', 'west', 'sussex', 'meyn', 'tweedi', 'markov', 'chain', 'stochast', 'stabil', 'cambridg', 'arinen', 'fast', 'fix', 'point', 'algorithm', 'independ', 'compon', 'analysi', 'neural', 'comput', 'bershad', 'analysi', 'normal', 'algorithm', 'gaussian', 'input', 'ieee', 'transact', 'acoust', 'speech', 'signal', 'process', 'nedic', 'bertseka', 'converg', 'rate', 'increment', 'subgradi', 'algorithm', 'stochast', 'optim', 'algorithm', 'applic', 'page', 'bach', 'adapt', 'averag', 'stochast', 'gradient', 'descent', 'local', 'strong', 'convex', 'logist', 'regress', 'technic', 'report', 'borkar', 'stochast', 'approxim', 'time', 'scale', 'system', 'control', 'letter', 'vaart', 'asymptot', 'statist', 'volum', 'cambridg', 'univ', 'press', 'bach', 'self', 'concord', 'analysi', 'logist', 'regress', 'electron', 'journal', 'statist', 'hazan', 'kale', 'regret', 'minim', 'barrier', 'optim', 'algorithm', 'stochast', 'strong', 'convex', 'optim', 'proc', 'colt', 'schmidt', 'roux', 'bach', 'minim', 'finit', 'sum', 'stochast', 'averag', 'gradient', 'technic', 'report']\n"
          ]
        }
      ],
      "source": [
        "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
        "\n",
        "stemmer = SnowballStemmer('english')\n",
        "print('Original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n Tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aWWTABOjHBt"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO0RXhuziGVx",
        "outputId": "ed89972d-fbd8-4c5f-ae85-f7fde9e87ac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4261    [scalabl, influenc, estim, continu, time, diff...\n",
              "4262    [adapt, anonym, match, krzysztof, choromanski,...\n",
              "4263    [exact, stabl, recoveri, pairwis, interact, te...\n",
              "4265    [matrix, factor, binari, compon, martin, slaws...\n",
              "4266    [complex, approxim, binari, evid, lift, infer,...\n",
              "4267    [unsupervis, spectral, learn, fsts, rapha, bai...\n",
              "4268    [decompos, proxim, yaoliang, depart, comput, s...\n",
              "4269    [uniform, camera, shake, remov, spatial, adapt...\n",
              "4270    [provabl, subspac, cluster, meet, xiang, wang,...\n",
              "4271    [matrix, complet, give, observ, troy, nanyang,...\n",
              "Name: paper_text, dtype: object"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_docs = documents['paper_text'].map(preprocess)\n",
        "processed_docs[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sEHm2iQjHBz"
      },
      "source": [
        "### Bag of words on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hndB3L6ibMx"
      },
      "outputs": [],
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msEkAc15ik0B",
        "outputId": "716a3edf-483b-4899-fb27-dbd038441c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 absolut\n",
            "1 abstract\n",
            "2 accumul\n",
            "3 accur\n",
            "4 accuraci\n",
            "5 achiev\n",
            "6 acknowledg\n",
            "7 actual\n",
            "8 acycl\n",
            "9 adapt\n",
            "10 add\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEtOeP8binYs"
      },
      "outputs": [],
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=len(documents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc9pC950iqd7"
      },
      "outputs": [],
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trjC1QPxi_rl",
        "outputId": "c29bfc68-4c80-4f16-a7a7-3f901b669004",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word 2 (\"accur\") appears 1 time.\n",
            "Word 6 (\"address\") appears 1 time.\n",
            "Word 7 (\"adopt\") appears 9 time.\n",
            "Word 15 (\"appendix\") appears 2 time.\n",
            "Word 20 (\"argument\") appears 2 time.\n",
            "Word 23 (\"artifici\") appears 3 time.\n",
            "Word 33 (\"binari\") appears 3 time.\n",
            "Word 36 (\"cambridg\") appears 1 time.\n",
            "Word 37 (\"captur\") appears 7 time.\n",
            "Word 44 (\"chen\") appears 1 time.\n",
            "Word 50 (\"collect\") appears 1 time.\n",
            "Word 58 (\"context\") appears 1 time.\n",
            "Word 74 (\"difficult\") appears 2 time.\n",
            "Word 86 (\"easi\") appears 1 time.\n",
            "Word 87 (\"easili\") appears 1 time.\n",
            "Word 94 (\"entir\") appears 2 time.\n",
            "Word 104 (\"exponenti\") appears 2 time.\n",
            "Word 115 (\"flexibl\") appears 1 time.\n",
            "Word 117 (\"formul\") appears 7 time.\n",
            "Word 122 (\"furthermor\") appears 1 time.\n",
            "Word 123 (\"gain\") appears 2 time.\n",
            "Word 135 (\"greater\") appears 1 time.\n",
            "Word 144 (\"heurist\") appears 3 time.\n",
            "Word 145 (\"hide\") appears 3 time.\n",
            "Word 157 (\"infinit\") appears 1 time.\n",
            "Word 165 (\"intuit\") appears 2 time.\n",
            "Word 166 (\"invari\") appears 3 time.\n",
            "Word 167 (\"investig\") appears 4 time.\n",
            "Word 168 (\"jmlr\") appears 2 time.\n",
            "Word 169 (\"joint\") appears 11 time.\n",
            "Word 172 (\"kernel\") appears 14 time.\n",
            "Word 176 (\"label\") appears 26 time.\n",
            "Word 179 (\"later\") appears 1 time.\n",
            "Word 181 (\"length\") appears 1 time.\n",
            "Word 185 (\"literatur\") appears 1 time.\n",
            "Word 195 (\"margin\") appears 19 time.\n",
            "Word 197 (\"markov\") appears 1 time.\n",
            "Word 198 (\"match\") appears 3 time.\n",
            "Word 203 (\"methodolog\") appears 1 time.\n",
            "Word 211 (\"mixtur\") appears 2 time.\n",
            "Word 223 (\"nest\") appears 2 time.\n",
            "Word 237 (\"occur\") appears 1 time.\n",
            "Word 240 (\"outer\") appears 1 time.\n",
            "Word 241 (\"overal\") appears 3 time.\n",
            "Word 243 (\"parallel\") appears 1 time.\n",
            "Word 251 (\"perspect\") appears 3 time.\n",
            "Word 258 (\"proc\") appears 4 time.\n",
            "Word 261 (\"program\") appears 1 time.\n",
            "Word 265 (\"qualiti\") appears 4 time.\n",
            "Word 268 (\"question\") appears 1 time.\n",
            "Word 270 (\"rank\") appears 6 time.\n",
            "Word 275 (\"recov\") appears 3 time.\n",
            "Word 281 (\"return\") appears 2 time.\n",
            "Word 285 (\"rich\") appears 1 time.\n",
            "Word 288 (\"round\") appears 2 time.\n",
            "Word 292 (\"search\") appears 2 time.\n",
            "Word 293 (\"seek\") appears 1 time.\n",
            "Word 303 (\"simpli\") appears 5 time.\n",
            "Word 307 (\"slight\") appears 1 time.\n",
            "Word 309 (\"smallest\") appears 1 time.\n",
            "Word 314 (\"spars\") appears 7 time.\n",
            "Word 315 (\"special\") appears 1 time.\n",
            "Word 319 (\"split\") appears 1 time.\n",
            "Word 336 (\"synthet\") appears 4 time.\n",
            "Word 348 (\"transform\") appears 5 time.\n",
            "Word 364 (\"util\") appears 1 time.\n",
            "Word 382 (\"zhang\") appears 3 time.\n",
            "Word 385 (\"abil\") appears 1 time.\n",
            "Word 387 (\"accept\") appears 1 time.\n",
            "Word 389 (\"accommod\") appears 4 time.\n",
            "Word 391 (\"admit\") appears 1 time.\n",
            "Word 401 (\"appear\") appears 1 time.\n",
            "Word 402 (\"archiv\") appears 1 time.\n",
            "Word 408 (\"automat\") appears 1 time.\n",
            "Word 410 (\"belief\") appears 2 time.\n",
            "Word 412 (\"benchmark\") appears 1 time.\n",
            "Word 418 (\"break\") appears 1 time.\n",
            "Word 431 (\"cluster\") appears 10 time.\n",
            "Word 432 (\"code\") appears 3 time.\n",
            "Word 440 (\"concern\") appears 1 time.\n",
            "Word 447 (\"correct\") appears 2 time.\n",
            "Word 448 (\"creat\") appears 1 time.\n",
            "Word 450 (\"criterion\") appears 1 time.\n",
            "Word 456 (\"desir\") appears 2 time.\n",
            "Word 457 (\"destroy\") appears 1 time.\n",
            "Word 459 (\"discov\") appears 2 time.\n",
            "Word 460 (\"discoveri\") appears 2 time.\n",
            "Word 461 (\"disjoint\") appears 1 time.\n",
            "Word 463 (\"drop\") appears 3 time.\n",
            "Word 469 (\"ensur\") appears 1 time.\n",
            "Word 470 (\"exploit\") appears 6 time.\n",
            "Word 476 (\"famili\") appears 1 time.\n",
            "Word 486 (\"foundat\") appears 2 time.\n",
            "Word 495 (\"group\") appears 5 time.\n",
            "Word 496 (\"grow\") appears 2 time.\n",
            "Word 498 (\"handl\") appears 1 time.\n",
            "Word 504 (\"http\") appears 4 time.\n",
            "Word 508 (\"identifi\") appears 1 time.\n",
            "Word 512 (\"intermedi\") appears 3 time.\n",
            "Word 514 (\"issu\") appears 1 time.\n",
            "Word 526 (\"lemma\") appears 12 time.\n",
            "Word 531 (\"maintain\") appears 1 time.\n",
            "Word 534 (\"maxi\") appears 4 time.\n",
            "Word 540 (\"necessari\") appears 1 time.\n",
            "Word 542 (\"offer\") appears 1 time.\n",
            "Word 545 (\"part\") appears 1 time.\n",
            "Word 556 (\"polynomi\") appears 2 time.\n",
            "Word 557 (\"poor\") appears 1 time.\n",
            "Word 559 (\"portion\") appears 1 time.\n",
            "Word 563 (\"preserv\") appears 6 time.\n",
            "Word 564 (\"prevent\") appears 1 time.\n",
            "Word 568 (\"probabilist\") appears 2 time.\n",
            "Word 580 (\"reduct\") appears 2 time.\n",
            "Word 581 (\"redund\") appears 1 time.\n",
            "Word 583 (\"regress\") appears 1 time.\n",
            "Word 584 (\"relationship\") appears 2 time.\n",
            "Word 585 (\"relax\") appears 25 time.\n",
            "Word 592 (\"saul\") appears 1 time.\n",
            "Word 594 (\"scenario\") appears 1 time.\n",
            "Word 603 (\"specifi\") appears 1 time.\n",
            "Word 605 (\"srivastava\") appears 1 time.\n",
            "Word 613 (\"supplement\") appears 1 time.\n",
            "Word 625 (\"tradit\") appears 4 time.\n",
            "Word 627 (\"treat\") appears 1 time.\n",
            "Word 628 (\"trivial\") appears 3 time.\n",
            "Word 633 (\"understand\") appears 1 time.\n",
            "Word 637 (\"unknown\") appears 2 time.\n",
            "Word 639 (\"usual\") appears 1 time.\n",
            "Word 640 (\"variat\") appears 1 time.\n",
            "Word 641 (\"versa\") appears 1 time.\n",
            "Word 642 (\"versus\") appears 3 time.\n",
            "Word 644 (\"vertic\") appears 1 time.\n",
            "Word 645 (\"vice\") appears 1 time.\n",
            "Word 648 (\"weaker\") appears 1 time.\n",
            "Word 655 (\"aaai\") appears 1 time.\n",
            "Word 669 (\"attent\") appears 1 time.\n",
            "Word 671 (\"avoid\") appears 2 time.\n",
            "Word 679 (\"believ\") appears 1 time.\n",
            "Word 686 (\"boyd\") appears 2 time.\n",
            "Word 688 (\"cand\") appears 1 time.\n",
            "Word 700 (\"column\") appears 3 time.\n",
            "Word 704 (\"conduct\") appears 4 time.\n",
            "Word 705 (\"cone\") appears 1 time.\n",
            "Word 709 (\"convex\") appears 45 time.\n",
            "Word 714 (\"decompos\") appears 1 time.\n",
            "Word 715 (\"decomposit\") appears 1 time.\n",
            "Word 718 (\"descript\") appears 1 time.\n",
            "Word 719 (\"determinist\") appears 1 time.\n",
            "Word 722 (\"dhillon\") appears 1 time.\n",
            "Word 723 (\"diag\") appears 7 time.\n",
            "Word 727 (\"encod\") appears 8 time.\n",
            "Word 728 (\"energi\") appears 1 time.\n",
            "Word 729 (\"evgeniou\") appears 1 time.\n",
            "Word 760 (\"interior\") appears 1 time.\n",
            "Word 782 (\"latent\") appears 61 time.\n",
            "Word 783 (\"letter\") appears 4 time.\n",
            "Word 791 (\"matric\") appears 4 time.\n",
            "Word 793 (\"meaning\") appears 1 time.\n",
            "Word 802 (\"norm\") appears 1 time.\n",
            "Word 814 (\"phase\") appears 1 time.\n",
            "Word 818 (\"pontil\") appears 1 time.\n",
            "Word 825 (\"promis\") appears 1 time.\n",
            "Word 827 (\"proport\") appears 2 time.\n",
            "Word 838 (\"recht\") appears 1 time.\n",
            "Word 840 (\"reconstruct\") appears 1 time.\n",
            "Word 843 (\"reformul\") appears 9 time.\n",
            "Word 862 (\"semi\") appears 1 time.\n",
            "Word 870 (\"sigir\") appears 1 time.\n",
            "Word 872 (\"signal\") appears 1 time.\n",
            "Word 873 (\"simplic\") appears 4 time.\n",
            "Word 874 (\"simul\") appears 1 time.\n",
            "Word 883 (\"subject\") appears 1 time.\n",
            "Word 884 (\"subsequ\") appears 1 time.\n",
            "Word 899 (\"trend\") appears 3 time.\n",
            "Word 903 (\"unlik\") appears 2 time.\n",
            "Word 905 (\"varieti\") appears 1 time.\n",
            "Word 906 (\"verifi\") appears 1 time.\n",
            "Word 908 (\"visual\") appears 1 time.\n",
            "Word 921 (\"affin\") appears 1 time.\n",
            "Word 936 (\"bach\") appears 2 time.\n",
            "Word 940 (\"banerje\") appears 1 time.\n",
            "Word 951 (\"boolean\") appears 2 time.\n",
            "Word 971 (\"concept\") appears 2 time.\n",
            "Word 982 (\"denois\") appears 1 time.\n",
            "Word 984 (\"despit\") appears 4 time.\n",
            "Word 993 (\"elimin\") appears 1 time.\n",
            "Word 996 (\"establish\") appears 6 time.\n",
            "Word 998 (\"expens\") appears 1 time.\n",
            "Word 1001 (\"fail\") appears 1 time.\n",
            "Word 1012 (\"ghosh\") appears 1 time.\n",
            "Word 1013 (\"global\") appears 3 time.\n",
            "Word 1016 (\"great\") appears 1 time.\n",
            "Word 1024 (\"impos\") appears 5 time.\n",
            "Word 1033 (\"interv\") appears 1 time.\n",
            "Word 1035 (\"intract\") appears 3 time.\n",
            "Word 1036 (\"invers\") appears 2 time.\n",
            "Word 1053 (\"mina\") appears 1 time.\n",
            "Word 1054 (\"mind\") appears 1 time.\n",
            "Word 1057 (\"modif\") appears 1 time.\n",
            "Word 1061 (\"neal\") appears 1 time.\n",
            "Word 1068 (\"outlin\") appears 1 time.\n",
            "Word 1079 (\"ponc\") appears 1 time.\n",
            "Word 1081 (\"pose\") appears 1 time.\n",
            "Word 1082 (\"princip\") appears 2 time.\n",
            "Word 1083 (\"principl\") appears 2 time.\n",
            "Word 1094 (\"refin\") appears 1 time.\n",
            "Word 1100 (\"robust\") appears 1 time.\n",
            "Word 1105 (\"scheme\") appears 3 time.\n",
            "Word 1116 (\"simplex\") appears 1 time.\n",
            "Word 1117 (\"smooth\") appears 3 time.\n",
            "Word 1121 (\"sparsiti\") appears 1 time.\n",
            "Word 1122 (\"stack\") appears 1 time.\n",
            "Word 1125 (\"strategi\") appears 3 time.\n",
            "Word 1129 (\"submatrix\") appears 1 time.\n",
            "Word 1141 (\"tractabl\") appears 2 time.\n",
            "Word 1142 (\"tran\") appears 1 time.\n",
            "Word 1154 (\"wise\") appears 3 time.\n",
            "Word 1158 (\"advantag\") appears 7 time.\n",
            "Word 1166 (\"balanc\") appears 1 time.\n",
            "Word 1167 (\"behav\") appears 1 time.\n",
            "Word 1178 (\"caus\") appears 3 time.\n",
            "Word 1180 (\"classic\") appears 3 time.\n",
            "Word 1181 (\"classif\") appears 11 time.\n",
            "Word 1182 (\"classifi\") appears 2 time.\n",
            "Word 1196 (\"deep\") appears 10 time.\n",
            "Word 1197 (\"depart\") appears 1 time.\n",
            "Word 1199 (\"diverg\") appears 2 time.\n",
            "Word 1200 (\"divid\") appears 3 time.\n",
            "Word 1205 (\"extract\") appears 1 time.\n",
            "Word 1210 (\"fold\") appears 1 time.\n",
            "Word 1222 (\"implicit\") appears 2 time.\n",
            "Word 1257 (\"overcom\") appears 1 time.\n",
            "Word 1260 (\"parameter\") appears 1 time.\n",
            "Word 1270 (\"receiv\") appears 1 time.\n",
            "Word 1291 (\"think\") appears 2 time.\n",
            "Word 1293 (\"trade\") appears 1 time.\n",
            "Word 1294 (\"transfer\") appears 5 time.\n",
            "Word 1299 (\"unfortun\") appears 6 time.\n",
            "Word 1300 (\"unsupervis\") appears 4 time.\n",
            "Word 1316 (\"baselin\") appears 1 time.\n",
            "Word 1322 (\"build\") appears 1 time.\n",
            "Word 1328 (\"dean\") appears 1 time.\n",
            "Word 1332 (\"discrimin\") appears 1 time.\n",
            "Word 1342 (\"forward\") appears 1 time.\n",
            "Word 1353 (\"hilbert\") appears 1 time.\n",
            "Word 1358 (\"kakad\") appears 2 time.\n",
            "Word 1363 (\"longer\") appears 1 time.\n",
            "Word 1370 (\"parikh\") appears 1 time.\n",
            "Word 1375 (\"realist\") appears 1 time.\n",
            "Word 1380 (\"spectral\") appears 2 time.\n",
            "Word 1388 (\"supervis\") appears 4 time.\n",
            "Word 1389 (\"target\") appears 2 time.\n",
            "Word 1392 (\"transduct\") appears 8 time.\n",
            "Word 1397 (\"alberta\") appears 1 time.\n",
            "Word 1410 (\"canada\") appears 1 time.\n",
            "Word 1413 (\"cheng\") appears 1 time.\n",
            "Word 1416 (\"cod\") appears 3 time.\n",
            "Word 1419 (\"componentwis\") appears 1 time.\n",
            "Word 1420 (\"composit\") appears 1 time.\n",
            "Word 1425 (\"dale\") appears 2 time.\n",
            "Word 1432 (\"encourag\") appears 4 time.\n",
            "Word 1433 (\"enjoy\") appears 1 time.\n",
            "Word 1436 (\"exhibit\") appears 2 time.\n",
            "Word 1456 (\"hybrid\") appears 1 time.\n",
            "Word 1457 (\"immedi\") appears 1 time.\n",
            "Word 1476 (\"let\") appears 1 time.\n",
            "Word 1484 (\"minor\") appears 1 time.\n",
            "Word 1491 (\"nesterov\") appears 1 time.\n",
            "Word 1505 (\"predictor\") appears 1 time.\n",
            "Word 1521 (\"schuurman\") appears 4 time.\n",
            "Word 1526 (\"singer\") appears 1 time.\n",
            "Word 1532 (\"suitabl\") appears 1 time.\n",
            "Word 1541 (\"ualberta\") appears 1 time.\n",
            "Word 1556 (\"activ\") appears 5 time.\n",
            "Word 1568 (\"augment\") appears 5 time.\n",
            "Word 1569 (\"auxiliari\") appears 1 time.\n",
            "Word 1577 (\"boost\") appears 8 time.\n",
            "Word 1592 (\"cvpr\") appears 1 time.\n",
            "Word 1600 (\"dictionari\") appears 1 time.\n",
            "Word 1611 (\"emb\") appears 3 time.\n",
            "Word 1613 (\"enhanc\") appears 2 time.\n",
            "Word 1618 (\"facilit\") appears 1 time.\n",
            "Word 1646 (\"likelihood\") appears 2 time.\n",
            "Word 1648 (\"mach\") appears 3 time.\n",
            "Word 1655 (\"nation\") appears 1 time.\n",
            "Word 1670 (\"primari\") appears 3 time.\n",
            "Word 1677 (\"relev\") appears 1 time.\n",
            "Word 1678 (\"reproduc\") appears 1 time.\n",
            "Word 1681 (\"respons\") appears 7 time.\n",
            "Word 1683 (\"retain\") appears 2 time.\n",
            "Word 1699 (\"simplifi\") appears 2 time.\n",
            "Word 1704 (\"stage\") appears 5 time.\n",
            "Word 1714 (\"translat\") appears 1 time.\n",
            "Word 1729 (\"admm\") appears 3 time.\n",
            "Word 1734 (\"bodi\") appears 1 time.\n",
            "Word 1747 (\"eckstein\") appears 1 time.\n",
            "Word 1749 (\"elad\") appears 1 time.\n",
            "Word 1753 (\"euclidean\") appears 1 time.\n",
            "Word 1773 (\"multipli\") appears 3 time.\n",
            "Word 1777 (\"peleato\") appears 1 time.\n",
            "Word 1801 (\"text\") appears 1 time.\n",
            "Word 1815 (\"weak\") appears 1 time.\n",
            "Word 1824 (\"eigenvalu\") appears 1 time.\n",
            "Word 1844 (\"semidefinit\") appears 7 time.\n",
            "Word 1848 (\"unobserv\") appears 1 time.\n",
            "Word 1850 (\"acceler\") appears 2 time.\n",
            "Word 1851 (\"acquir\") appears 1 time.\n",
            "Word 1852 (\"adequ\") appears 1 time.\n",
            "Word 1853 (\"aharon\") appears 1 time.\n",
            "Word 1854 (\"allerton\") appears 1 time.\n",
            "Word 1855 (\"anandkumar\") appears 1 time.\n",
            "Word 1856 (\"architectur\") appears 9 time.\n",
            "Word 1857 (\"argyriou\") appears 1 time.\n",
            "Word 1858 (\"arithmet\") appears 1 time.\n",
            "Word 1859 (\"australia\") appears 1 time.\n",
            "Word 1860 (\"auto\") appears 6 time.\n",
            "Word 1861 (\"autoencod\") appears 1 time.\n",
            "Word 1862 (\"bagnel\") appears 1 time.\n",
            "Word 1863 (\"bengio\") appears 3 time.\n",
            "Word 1864 (\"bialek\") appears 1 time.\n",
            "Word 1865 (\"bird\") appears 1 time.\n",
            "Word 1866 (\"blow\") appears 1 time.\n",
            "Word 1867 (\"boltzmann\") appears 2 time.\n",
            "Word 1868 (\"book\") appears 1 time.\n",
            "Word 1869 (\"bottleneck\") appears 3 time.\n",
            "Word 1870 (\"box\") appears 2 time.\n",
            "Word 1871 (\"bradley\") appears 1 time.\n",
            "Word 1872 (\"bregman\") appears 2 time.\n",
            "Word 1873 (\"bypass\") appears 1 time.\n",
            "Word 1874 (\"calibr\") appears 1 time.\n",
            "Word 1875 (\"capac\") appears 1 time.\n",
            "Word 1876 (\"carreira\") appears 1 time.\n",
            "Word 1877 (\"chapell\") appears 2 time.\n",
            "Word 1878 (\"cifar\") appears 5 time.\n",
            "Word 1879 (\"clarifi\") appears 1 time.\n",
            "Word 1880 (\"cognit\") appears 1 time.\n",
            "Word 1881 (\"coil\") appears 4 time.\n",
            "Word 1882 (\"commit\") appears 1 time.\n",
            "Word 1883 (\"comp\") appears 1 time.\n",
            "Word 1884 (\"compet\") appears 1 time.\n",
            "Word 1885 (\"competit\") appears 1 time.\n",
            "Word 1886 (\"concurr\") appears 2 time.\n",
            "Word 1887 (\"conf\") appears 1 time.\n",
            "Word 1888 (\"conic\") appears 1 time.\n",
            "Word 1889 (\"connectionist\") appears 1 time.\n",
            "Word 1890 (\"contract\") appears 1 time.\n",
            "Word 1891 (\"cope\") appears 2 time.\n",
            "Word 1892 (\"corrado\") appears 1 time.\n",
            "Word 1893 (\"crammer\") appears 1 time.\n",
            "Word 1894 (\"cross\") appears 1 time.\n",
            "Word 1895 (\"decoupl\") appears 1 time.\n",
            "Word 1896 (\"depict\") appears 1 time.\n",
            "Word 1897 (\"devin\") appears 1 time.\n",
            "Word 1898 (\"difficulti\") appears 5 time.\n",
            "Word 1899 (\"discrep\") appears 1 time.\n",
            "Word 1900 (\"eigenvector\") appears 1 time.\n",
            "Word 1901 (\"exceed\") appears 1 time.\n",
            "Word 1902 (\"exemplar\") appears 1 time.\n",
            "Word 1903 (\"fee\") appears 1 time.\n",
            "Word 1904 (\"freita\") appears 1 time.\n",
            "Word 1905 (\"glorot\") appears 1 time.\n",
            "Word 1906 (\"goldberg\") appears 1 time.\n",
            "Word 1907 (\"hinton\") appears 2 time.\n",
            "Word 1908 (\"html\") appears 2 time.\n",
            "Word 1909 (\"imput\") appears 1 time.\n",
            "Word 1910 (\"inact\") appears 1 time.\n",
            "Word 1911 (\"innov\") appears 1 time.\n",
            "Word 1912 (\"inter\") appears 1 time.\n",
            "Word 1913 (\"interven\") appears 2 time.\n",
            "Word 1914 (\"itc\") appears 1 time.\n",
            "Word 1915 (\"joachim\") appears 1 time.\n",
            "Word 1916 (\"joulin\") appears 2 time.\n",
            "Word 1917 (\"keerthi\") appears 1 time.\n",
            "Word 1918 (\"lagrangian\") appears 1 time.\n",
            "Word 1919 (\"lawrenc\") appears 1 time.\n",
            "Word 1920 (\"layer\") appears 72 time.\n",
            "Word 1921 (\"lbfgs\") appears 3 time.\n",
            "Word 1922 (\"lecun\") appears 2 time.\n",
            "Word 1923 (\"loglikelihood\") appears 1 time.\n",
            "Word 1924 (\"marlin\") appears 1 time.\n",
            "Word 1925 (\"merugu\") appears 1 time.\n",
            "Word 1926 (\"minh\") appears 1 time.\n",
            "Word 1927 (\"minm\") appears 1 time.\n",
            "Word 1928 (\"minn\") appears 4 time.\n",
            "Word 1929 (\"mitig\") appears 1 time.\n",
            "Word 1930 (\"mnist\") appears 4 time.\n",
            "Word 1931 (\"moment\") appears 3 time.\n",
            "Word 1932 (\"monga\") appears 1 time.\n",
            "Word 1933 (\"moor\") appears 1 time.\n",
            "Word 1934 (\"muller\") appears 1 time.\n",
            "Word 1935 (\"multiclass\") appears 2 time.\n",
            "Word 1936 (\"multilabel\") appears 2 time.\n",
            "Word 1937 (\"multimod\") appears 1 time.\n",
            "Word 1938 (\"net\") appears 1 time.\n",
            "Word 1939 (\"neur\") appears 1 time.\n",
            "Word 1940 (\"nonlinear\") appears 8 time.\n",
            "Word 1941 (\"nowak\") appears 1 time.\n",
            "Word 1942 (\"nowozin\") appears 1 time.\n",
            "Word 1943 (\"olivi\") appears 1 time.\n",
            "Word 1944 (\"osindero\") appears 1 time.\n",
            "Word 1945 (\"outcom\") appears 1 time.\n",
            "Word 1946 (\"particip\") appears 2 time.\n",
            "Word 1947 (\"penros\") appears 1 time.\n",
            "Word 1948 (\"percentag\") appears 1 time.\n",
            "Word 1949 (\"perceptron\") appears 4 time.\n",
            "Word 1950 (\"pereira\") appears 1 time.\n",
            "Word 1951 (\"predecessor\") appears 1 time.\n",
            "Word 1952 (\"primal\") appears 1 time.\n",
            "Word 1953 (\"protocol\") appears 1 time.\n",
            "Word 1954 (\"pseudo\") appears 2 time.\n",
            "Word 1955 (\"ranzato\") appears 2 time.\n",
            "Word 1956 (\"rbms\") appears 3 time.\n",
            "Word 1957 (\"readili\") appears 1 time.\n",
            "Word 1958 (\"realiz\") appears 1 time.\n",
            "Word 1959 (\"resurg\") appears 1 time.\n",
            "Word 1960 (\"rifai\") appears 1 time.\n",
            "Word 1961 (\"roux\") appears 1 time.\n",
            "Word 1962 (\"salakhutdinov\") appears 1 time.\n",
            "Word 1963 (\"score\") appears 1 time.\n",
            "Word 1964 (\"semant\") appears 1 time.\n",
            "Word 1965 (\"sigmoid\") appears 1 time.\n",
            "Word 1966 (\"simplif\") appears 2 time.\n",
            "Word 1967 (\"sindhwani\") appears 1 time.\n",
            "Word 1968 (\"softmax\") appears 3 time.\n",
            "Word 1969 (\"sole\") appears 1 time.\n",
            "Word 1970 (\"spheric\") appears 1 time.\n",
            "Word 1971 (\"spline\") appears 1 time.\n",
            "Word 1972 (\"stone\") appears 1 time.\n",
            "Word 1973 (\"stop\") appears 1 time.\n",
            "Word 1974 (\"subproblem\") appears 1 time.\n",
            "Word 1975 (\"svms\") appears 1 time.\n",
            "Word 1976 (\"swerski\") appears 1 time.\n",
            "Word 1977 (\"tion\") appears 1 time.\n",
            "Word 1978 (\"tishbi\") appears 1 time.\n",
            "Word 1979 (\"toronto\") appears 1 time.\n",
            "Word 1980 (\"trainabl\") appears 1 time.\n",
            "Word 1981 (\"unabl\") appears 1 time.\n",
            "Word 1982 (\"unlabel\") appears 6 time.\n",
            "Word 1983 (\"usp\") appears 4 time.\n",
            "Word 1984 (\"vandenbergh\") appears 1 time.\n",
            "Word 1985 (\"vincent\") appears 2 time.\n",
            "Word 1986 (\"viterbi\") appears 1 time.\n",
            "Word 1987 (\"wahba\") appears 1 time.\n",
            "Word 1988 (\"wright\") appears 1 time.\n"
          ]
        }
      ],
      "source": [
        "bow_doc = bow_corpus[10]\n",
        "\n",
        "for i in range(len(bow_doc)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc[i][0], \n",
        "                                                     dictionary[bow_doc[i][0]], \n",
        "                                                     bow_doc[i][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQBZ2g5HjHB_"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlmnB4l-jCvd"
      },
      "outputs": [],
      "source": [
        "from gensim import corpora, models\n",
        "tfidf = models.TfidfModel(bow_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GrbYyn6jFdB"
      },
      "outputs": [],
      "source": [
        "corpus_tfidf = tfidf[bow_corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry8BZ4HrjLiW",
        "outputId": "f212eaa0-d292-4a9a-c593-35ce55fc2350",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 0.010573822214664387),\n",
            " (1, 0.008537777306848201),\n",
            " (2, 0.011563731961775459),\n",
            " (3, 0.003391710143789426),\n",
            " (4, 0.010971074137179739),\n",
            " (5, 0.01073944337777098),\n",
            " (6, 0.0027352773815965668),\n",
            " (7, 0.014824890423594625),\n",
            " (8, 0.011554676922430665),\n",
            " (9, 0.01112530646217485),\n",
            " (10, 0.0069654144948065495),\n",
            " (11, 0.012789038602890905),\n",
            " (12, 0.011153326184540647),\n",
            " (13, 0.022866533390483883),\n",
            " (14, 0.005698014203755539),\n",
            " (15, 0.0329471533825011),\n",
            " (16, 0.003387900122181393),\n",
            " (17, 0.008593547357834882),\n",
            " (18, 0.009265009766316694),\n",
            " (19, 0.006446292573761128),\n",
            " (20, 0.00457331801389896),\n",
            " (21, 0.004382296408484927),\n",
            " (22, 0.031201641977399622),\n",
            " (23, 0.0057686207783572575),\n",
            " (24, 0.006775800244362786),\n",
            " (25, 0.01078588551655733),\n",
            " (26, 0.006428439594294781),\n",
            " (27, 0.01735316618623997),\n",
            " (28, 0.0038204710217507793),\n",
            " (29, 0.004037477762656758),\n",
            " (30, 0.0447999182149534),\n",
            " (31, 0.014872035482003486),\n",
            " (32, 0.010441987804218088),\n",
            " (33, 0.005729031571889921),\n",
            " (34, 0.016669281107526687),\n",
            " (35, 0.0145612210730634),\n",
            " (36, 0.0042490668274344735),\n",
            " (37, 0.0026692502005870827),\n",
            " (38, 0.005280444050536419),\n",
            " (39, 0.018218203012170107),\n",
            " (40, 0.2045961258406256),\n",
            " (41, 0.028859114954016326),\n",
            " (42, 0.008158337397361624),\n",
            " (43, 0.015377028435405574),\n",
            " (44, 0.010547468310701543),\n",
            " (45, 0.02601209068759377),\n",
            " (46, 0.013749293556886756),\n",
            " (47, 0.0068036009574954474),\n",
            " (48, 0.013358413057370976),\n",
            " (49, 0.050269675490525204),\n",
            " (50, 0.010802159465128193),\n",
            " (51, 0.0055278666117012055),\n",
            " (52, 0.006706060454624135),\n",
            " (53, 0.01259461433285715),\n",
            " (54, 0.012842069424133972),\n",
            " (55, 0.013548520471753913),\n",
            " (56, 0.04256445120987061),\n",
            " (57, 0.07187322700907943),\n",
            " (58, 0.0025861093412905397),\n",
            " (59, 0.017751300011363876),\n",
            " (60, 0.03235203200275983),\n",
            " (61, 0.0062292858328551505),\n",
            " (62, 0.0050308994799636774),\n",
            " (63, 0.0050855496248999555),\n",
            " (64, 0.012438316265104369),\n",
            " (65, 0.008718848849501864),\n",
            " (66, 0.009385004744062333),\n",
            " (67, 0.007124060028620722),\n",
            " (68, 0.01188207080996693),\n",
            " (69, 0.009242731832047633),\n",
            " (70, 0.005657015117147371),\n",
            " (71, 0.012747200482303418),\n",
            " (72, 0.08018231429092035),\n",
            " (73, 0.004101975272710878),\n",
            " (74, 0.003008857088778083),\n",
            " (75, 0.18899452259372435),\n",
            " (76, 0.009509162217873028),\n",
            " (77, 0.01950489925525274),\n",
            " (78, 0.023153991132212517),\n",
            " (79, 0.008674666625043034),\n",
            " (80, 0.002954466451215884),\n",
            " (81, 0.013006045343796886),\n",
            " (82, 0.012297925135520539),\n",
            " (83, 0.01548717604803337),\n",
            " (84, 0.009446545199043034),\n",
            " (85, 0.01669367691272184),\n",
            " (86, 0.003301370586453892),\n",
            " (87, 0.008215356353740768),\n",
            " (88, 0.10026377476149206),\n",
            " (89, 0.005081481980911173),\n",
            " (90, 0.006639329880960563),\n",
            " (91, 0.0038898940940323315),\n",
            " (92, 0.010816092573144299),\n",
            " (93, 0.031574743918681196),\n",
            " (94, 0.0034804789453285277),\n",
            " (95, 0.004042046384799348),\n",
            " (96, 0.010229806292031279),\n",
            " (97, 0.01682839685677179),\n",
            " (98, 0.0027321054585154603),\n",
            " (99, 0.004037477762656758),\n",
            " (100, 0.020464927925173557),\n",
            " (101, 0.01682839685677179),\n",
            " (102, 0.035722815807334586),\n",
            " (103, 0.010387751691433422),\n",
            " (104, 0.034532400216291066),\n",
            " (105, 0.01174614047055318),\n",
            " (106, 0.030131139819074837),\n",
            " (107, 0.0065645592258027526),\n",
            " (108, 0.003316269733720227),\n",
            " (109, 0.007684867927412831),\n",
            " (110, 0.0035555073780679106),\n",
            " (111, 0.010307907898654418),\n",
            " (112, 0.002867807294188659),\n",
            " (113, 0.008157428875990353),\n",
            " (114, 0.005248282873152089),\n",
            " (115, 0.004724969163631093),\n",
            " (116, 0.011158538463411428),\n",
            " (117, 0.002487047259241035),\n",
            " (118, 0.019188785582292305),\n",
            " (119, 0.005210067047925375),\n",
            " (120, 0.0136142014881712),\n",
            " (121, 0.0032096301739109275),\n",
            " (122, 0.0058084301298288385),\n",
            " (123, 0.012085073923136687),\n",
            " (124, 0.0552752035430447),\n",
            " (125, 0.012842069424133972),\n",
            " (126, 0.011738061652835759),\n",
            " (127, 0.007070393131860603),\n",
            " (128, 0.011907044636004758),\n",
            " (129, 0.0048488012121983455),\n",
            " (130, 0.08513983146763489),\n",
            " (131, 0.012118912086777652),\n",
            " (132, 0.0032939442041992196),\n",
            " (133, 0.02731724664878436),\n",
            " (134, 0.03530070941121861),\n",
            " (135, 0.005398677311424513),\n",
            " (136, 0.07172729937513371),\n",
            " (137, 0.013912578845715302),\n",
            " (138, 0.010029501453999999),\n",
            " (139, 0.0030398189681861898),\n",
            " (140, 0.007622177796827962),\n",
            " (141, 0.003515822770233848),\n",
            " (142, 0.03470633237247994),\n",
            " (143, 0.0422137017690075),\n",
            " (144, 0.005000894987745658),\n",
            " (145, 0.003790516746842725),\n",
            " (146, 0.015038599862561834),\n",
            " (147, 0.005676298171753867),\n",
            " (148, 0.08875650005681938),\n",
            " (149, 0.032231175186027236),\n",
            " (150, 0.009446545199043034),\n",
            " (151, 0.011825688521194385),\n",
            " (152, 0.007761574754772907),\n",
            " (153, 0.014266824228756027),\n",
            " (154, 0.012969546051947445),\n",
            " (155, 0.007885719046931548),\n",
            " (156, 0.43682298768359473),\n",
            " (157, 0.00495340487208809),\n",
            " (158, 0.47319060441010685),\n",
            " (159, 0.012895897731169087),\n",
            " (160, 0.021918905582980458),\n",
            " (161, 0.004191408963962097),\n",
            " (162, 0.010606830235710378),\n",
            " (163, 0.014513785244570062),\n",
            " (164, 0.007735822737494403),\n",
            " (165, 0.002656810518344252),\n",
            " (166, 0.004906536576157068),\n",
            " (167, 0.003418494453409937),\n",
            " (168, 0.006170809375461743),\n",
            " (169, 0.005033555241744308),\n",
            " (170, 0.09039341945722452),\n",
            " (171, 0.012162833066804983),\n",
            " (172, 0.0036731450854202907),\n",
            " (173, 0.040118005815999995),\n",
            " (174, 0.026782269833992848),\n",
            " (175, 0.03310498723758902),\n",
            " (176, 0.10014295555583701),\n",
            " (177, 0.013177895062226774),\n",
            " (178, 0.0042105252441772285),\n",
            " (179, 0.007471087577269136),\n",
            " (180, 0.014429557477008163),\n",
            " (181, 0.007429246254626026),\n",
            " (182, 0.07119681268979292),\n",
            " (183, 0.03303387666180728),\n",
            " (184, 0.053986773114245136),\n",
            " (185, 0.00536972168888549),\n",
            " (186, 0.005405361748404938),\n",
            " (187, 0.004263627586344257),\n",
            " (188, 0.010599760757263267),\n",
            " (189, 0.03972294171021196),\n",
            " (190, 0.013237061945885762),\n",
            " (191, 0.017546700613773905),\n",
            " (192, 0.008876059087429859),\n",
            " (193, 0.00838075586188291),\n",
            " (194, 0.08867433503854213),\n",
            " (195, 0.00819631637554638),\n",
            " (196, 0.0493149118098262),\n",
            " (197, 0.003996620458370702),\n",
            " (198, 0.002650606851344659),\n",
            " (199, 0.008230333941202279),\n",
            " (200, 0.012789038602890905),\n",
            " (201, 0.02523484182179707),\n",
            " (202, 0.008085979099319164),\n",
            " (203, 0.006592415513957694),\n",
            " (204, 0.054192469704697294),\n",
            " (205, 0.009467296068535188),\n",
            " (206, 0.005899625157646423),\n",
            " (207, 0.01060980830145271),\n",
            " (208, 0.01190760526911153),\n",
            " (209, 0.011307819816747878),\n",
            " (210, 0.013237061945885762),\n",
            " (211, 0.004854533022811079),\n",
            " (212, 0.004317529583098734),\n",
            " (213, 0.018562259050551932),\n",
            " (214, 0.023414039398107434),\n",
            " (215, 0.002763951887108508),\n",
            " (216, 0.005520949672422676),\n",
            " (217, 0.015269256592415174),\n",
            " (218, 0.039221508277597045),\n",
            " (219, 0.006010866706995298),\n",
            " (220, 0.027467074030827834),\n",
            " (221, 0.10318348154415509),\n",
            " (222, 0.013889684686470586),\n",
            " (223, 0.009981128894039647),\n",
            " (224, 0.012950547876105367),\n",
            " (225, 0.010029501453999999),\n",
            " (226, 0.237019686562429),\n",
            " (227, 0.20843052354520372),\n",
            " (228, 0.0026228226371049473),\n",
            " (229, 0.014967494871465712),\n",
            " (230, 0.007866476473387393),\n",
            " (231, 0.0062292858328551505),\n",
            " (232, 0.009748611132372133),\n",
            " (233, 0.002947725366431096),\n",
            " (234, 0.01516640798515489),\n",
            " (235, 0.003152126688877128),\n",
            " (236, 0.010078536672353098),\n",
            " (237, 0.004443139487427552),\n",
            " (238, 0.043509129412537956),\n",
            " (239, 0.017169561071488464),\n",
            " (240, 0.018297814422871515),\n",
            " (241, 0.02433601316588076),\n",
            " (242, 0.006121435972502335),\n",
            " (243, 0.017609850973220435),\n",
            " (244, 0.0043572472162491434),\n",
            " (245, 0.040714677977224105),\n",
            " (246, 0.004101975272710878),\n",
            " (247, 0.060588283740939684),\n",
            " (248, 0.012297925135520539),\n",
            " (249, 0.012950547876105367),\n",
            " (250, 0.008143024369779933),\n",
            " (251, 0.014409822528168827),\n",
            " (252, 0.005500278691227153),\n",
            " (253, 0.009364724151778081),\n",
            " (254, 0.0032643917972247295),\n",
            " (255, 0.0027543681733171624),\n",
            " (256, 0.015270169307127393),\n",
            " (257, 0.011907044636004758),\n",
            " (258, 0.006088894703271319),\n",
            " (259, 0.010581286118967357),\n",
            " (260, 0.005045506880456029),\n",
            " (261, 0.0025861093412905397),\n",
            " (262, 0.0050490236450783064),\n",
            " (263, 0.004443139487427552),\n",
            " (264, 0.00949433555436272),\n",
            " (265, 0.014791896761979777),\n",
            " (266, 0.0114543507661265),\n",
            " (267, 0.02468323750184697),\n",
            " (268, 0.0032643917972247295),\n",
            " (269, 0.005178529267146418),\n",
            " (270, 0.0032939442041992196),\n",
            " (271, 0.013358413057370976),\n",
            " (272, 0.01651693833090364),\n",
            " (273, 0.09673160620032824),\n",
            " (274, 0.0060246864352651785),\n",
            " (275, 0.003391710143789426),\n",
            " (276, 0.006187419683517311),\n",
            " (277, 0.009793922053380234),\n",
            " (278, 0.008521761553226821),\n",
            " (279, 0.00635434174747455),\n",
            " (280, 0.009054951293453585),\n",
            " (281, 0.010038766124183474),\n",
            " (282, 0.030235610017059295),\n",
            " (283, 0.00772301587244543),\n",
            " (284, 0.015294244505831436),\n",
            " (285, 0.005669088672916297),\n",
            " (286, 0.012297925135520539),\n",
            " (287, 0.08952327022023633),\n",
            " (288, 0.012033481565613223),\n",
            " (289, 0.016059657387242982),\n",
            " (290, 0.011067389767517427),\n",
            " (291, 0.05604081061363342),\n",
            " (292, 0.008253537886901497),\n",
            " (293, 0.0054797263957451145),\n",
            " (294, 0.003246044678826764),\n",
            " (295, 0.014224815612741502),\n",
            " (296, 0.004239392456781196),\n",
            " (297, 0.005493414806165567),\n",
            " (298, 0.003357565068063065),\n",
            " (299, 0.005365441093415115),\n",
            " (300, 0.004484283790570063),\n",
            " (301, 0.09817446616445093),\n",
            " (302, 0.016370815390707075),\n",
            " (303, 0.002516777620872154),\n",
            " (304, 0.003794780612698656),\n",
            " (305, 0.02127711916045368),\n",
            " (306, 0.011990292922109513),\n",
            " (307, 0.003198777669500466),\n",
            " (308, 0.007081062334879608),\n",
            " (309, 0.03168266430321851),\n",
            " (310, 0.007102496620260304),\n",
            " (311, 0.04934404760087019),\n",
            " (312, 0.039199807132486136),\n",
            " (313, 0.2334133936759839),\n",
            " (314, 0.002719445799120542),\n",
            " (315, 0.007559292850527517),\n",
            " (316, 0.008203950545421756),\n",
            " (317, 0.009771194897902256),\n",
            " (318, 0.008618948924843193),\n",
            " (319, 0.004268494364745633),\n",
            " (320, 0.052011302326522776),\n",
            " (321, 0.013962000579602703),\n",
            " (322, 0.008963398605566381),\n",
            " (323, 0.019060560723007314),\n",
            " (324, 0.006129617724550859),\n",
            " (325, 0.004432926884315129),\n",
            " (326, 0.031002975309459974),\n",
            " (327, 0.02157177103311466),\n",
            " (328, 0.006620490285035326),\n",
            " (329, 0.01411116861990873),\n",
            " (330, 0.005640395012552987),\n",
            " (331, 0.0032791375027853443),\n",
            " (332, 0.008489943432943252),\n",
            " (333, 0.006383121806036037),\n",
            " (334, 0.025901095752210734),\n",
            " (335, 0.008186412961174946),\n",
            " (336, 0.02337759987034096),\n",
            " (337, 0.006843373755159524),\n",
            " (338, 0.012736781981923982),\n",
            " (339, 0.004894914764120604),\n",
            " (340, 0.017861407903667293),\n",
            " (341, 0.0065645592258027526),\n",
            " (342, 0.0036607948202778996),\n",
            " (343, 0.008927423277997615),\n",
            " (344, 0.005801134934865927),\n",
            " (345, 0.008769864178032449),\n",
            " (346, 0.006592415513957694),\n",
            " (347, 0.006088894703271319),\n",
            " (348, 0.016193660409376837),\n",
            " (349, 0.005241885168208943),\n",
            " (350, 0.3526852542265038),\n",
            " (351, 0.02671682611474195),\n",
            " (352, 0.011233908859552184),\n",
            " (353, 0.004780725975746631),\n",
            " (354, 0.024325666133609966),\n",
            " (355, 0.014274956769466501),\n",
            " (356, 0.0037439464097765987),\n",
            " (357, 0.013484022961699796),\n",
            " (358, 0.014600042791014135),\n",
            " (359, 0.013184831027915388),\n",
            " (360, 0.009862982361965242),\n",
            " (361, 0.021754564706268978),\n",
            " (362, 0.006555321762707652),\n",
            " (363, 0.014895655390639164),\n",
            " (364, 0.004224929750387648),\n",
            " (365, 0.00819631637554638),\n",
            " (366, 0.0054642109170309205),\n",
            " (367, 0.05875372146900792),\n",
            " (368, 0.013237061945885762),\n",
            " (369, 0.012118912086777652),\n",
            " (370, 0.010106731825040323),\n",
            " (371, 0.008714494432498287),\n",
            " (372, 0.010204146576681917),\n",
            " (373, 0.00730140973394948),\n",
            " (374, 0.006783879062080207),\n",
            " (375, 0.12586362357419828),\n",
            " (376, 0.0136142014881712),\n",
            " (377, 0.026321894263047586),\n",
            " (378, 0.015065569909537418),\n",
            " (379, 0.010025733241707888),\n",
            " (380, 0.004814601764505753),\n",
            " (381, 0.016115587593013618),\n",
            " (382, 0.0030815225268509393),\n",
            " (383, 0.012768385726516375),\n",
            " (384, 0.011034995745863007)]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST9KhXwyjHCG"
      },
      "source": [
        "### LDA using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouK0d4N5jmzl"
      },
      "outputs": [],
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6UE5GskkAIA",
        "outputId": "ab161427-b98f-4ab0-b41a-d320d77fa34d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Word: 0.003*\"action\" + 0.003*\"submodular\" + 0.003*\"polici\" + 0.003*\"reward\" + 0.003*\"regret\" + 0.003*\"graph\" + 0.002*\"edg\" + 0.002*\"tree\" + 0.002*\"score\" + 0.002*\"bandit\"\n",
            "Topic: 1 \n",
            "Word: 0.003*\"privaci\" + 0.003*\"dropout\" + 0.003*\"layer\" + 0.002*\"label\" + 0.002*\"posterior\" + 0.002*\"variat\" + 0.002*\"deep\" + 0.002*\"privat\" + 0.002*\"classifi\" + 0.002*\"tree\"\n",
            "Topic: 2 \n",
            "Word: 0.003*\"kernel\" + 0.003*\"tree\" + 0.003*\"latent\" + 0.003*\"item\" + 0.002*\"rank\" + 0.002*\"user\" + 0.002*\"layer\" + 0.002*\"tensor\" + 0.002*\"neuron\" + 0.002*\"cluster\"\n",
            "Topic: 3 \n",
            "Word: 0.003*\"cluster\" + 0.003*\"convex\" + 0.002*\"topic\" + 0.002*\"kernel\" + 0.002*\"tensor\" + 0.002*\"norm\" + 0.002*\"proxim\" + 0.002*\"rank\" + 0.002*\"posterior\" + 0.002*\"subspac\"\n",
            "Topic: 4 \n",
            "Word: 0.004*\"layer\" + 0.003*\"cluster\" + 0.003*\"tensor\" + 0.003*\"neuron\" + 0.003*\"rank\" + 0.002*\"convolut\" + 0.002*\"worker\" + 0.002*\"lstm\" + 0.002*\"deep\" + 0.002*\"queri\"\n",
            "Topic: 5 \n",
            "Word: 0.007*\"submodular\" + 0.003*\"item\" + 0.002*\"rank\" + 0.002*\"graph\" + 0.002*\"svrg\" + 0.002*\"cluster\" + 0.002*\"kernel\" + 0.002*\"node\" + 0.002*\"convex\" + 0.002*\"nod\"\n",
            "Topic: 6 \n",
            "Word: 0.010*\"polici\" + 0.007*\"regret\" + 0.006*\"reward\" + 0.005*\"bandit\" + 0.005*\"action\" + 0.005*\"agent\" + 0.003*\"arm\" + 0.003*\"game\" + 0.003*\"player\" + 0.003*\"reinforc\"\n",
            "Topic: 7 \n",
            "Word: 0.004*\"kernel\" + 0.003*\"rank\" + 0.003*\"lasso\" + 0.003*\"graph\" + 0.002*\"norm\" + 0.002*\"convex\" + 0.002*\"tensor\" + 0.002*\"subspac\" + 0.002*\"recoveri\" + 0.002*\"cluster\"\n",
            "Topic: 8 \n",
            "Word: 0.005*\"regret\" + 0.002*\"kernel\" + 0.002*\"bandit\" + 0.002*\"convex\" + 0.002*\"classifi\" + 0.002*\"onlin\" + 0.002*\"action\" + 0.002*\"round\" + 0.002*\"lemma\" + 0.002*\"graph\"\n",
            "Topic: 9 \n",
            "Word: 0.004*\"layer\" + 0.004*\"cluster\" + 0.003*\"posterior\" + 0.003*\"graph\" + 0.003*\"deep\" + 0.003*\"neuron\" + 0.002*\"latent\" + 0.002*\"convolut\" + 0.002*\"label\" + 0.002*\"spike\"\n"
          ]
        }
      ],
      "source": [
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} \\nWord: {}'.format(idx, topic))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y14bFD6mjHCJ"
      },
      "source": [
        "### Performance evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvFpOSiIkFkZ",
        "outputId": "c04425c0-576e-47fd-c2e4-670b73dd24ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.8359755873680115\t \n",
            "Topic: 0.004*\"layer\" + 0.004*\"cluster\" + 0.003*\"posterior\" + 0.003*\"graph\" + 0.003*\"deep\" + 0.003*\"neuron\" + 0.002*\"latent\" + 0.002*\"convolut\" + 0.002*\"label\" + 0.002*\"spike\"\n",
            "\n",
            "Score: 0.09352096915245056\t \n",
            "Topic: 0.003*\"cluster\" + 0.003*\"convex\" + 0.002*\"topic\" + 0.002*\"kernel\" + 0.002*\"tensor\" + 0.002*\"norm\" + 0.002*\"proxim\" + 0.002*\"rank\" + 0.002*\"posterior\" + 0.002*\"subspac\"\n",
            "\n",
            "Score: 0.05353422090411186\t \n",
            "Topic: 0.004*\"kernel\" + 0.003*\"rank\" + 0.003*\"lasso\" + 0.003*\"graph\" + 0.002*\"norm\" + 0.002*\"convex\" + 0.002*\"tensor\" + 0.002*\"subspac\" + 0.002*\"recoveri\" + 0.002*\"cluster\"\n"
          ]
        }
      ],
      "source": [
        "for index, score in sorted(lda_model_tfidf[bow_corpus[10]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEGTuf9qjHCL"
      },
      "source": [
        "### Data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHw2ZyHnlkJB",
        "outputId": "a5aff8d0-d963-4177-a679-240931061e3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ]
        }
      ],
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "MiMlXkQdl5aN",
        "outputId": "187aea7a-02a9-4ebe-f950-e9a4cdb507f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el661404447422444321929867586\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el661404447422444321929867586_data = {\"mdsDat\": {\"x\": [0.02656659587687987, -0.00028381446425052075, -0.047809130300672964, 0.007201695217374909, 0.024308334081974036, 0.006959736072792564, 0.0036110031179652, -0.008002478747550988, 0.0025058346384478746, -0.015057775492959898], \"y\": [-0.014387390334480771, 0.01698388865675331, -0.00464765283473949, 0.0265940950345689, -0.0018513611639178217, 0.0041207383207302346, 0.004260817723559503, -0.009322008987750848, -0.024360759229626473, 0.002609632814903405], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [47.50354500055258, 16.24953921849105, 10.398158714951999, 6.852095385537778, 5.8848431335074896, 4.976879424702763, 4.459482743124992, 2.1599920819178626, 1.0835120288270632, 0.4319522683864389]}, \"tinfo\": {\"Term\": [\"regret\", \"polici\", \"layer\", \"kernel\", \"reward\", \"graph\", \"action\", \"posterior\", \"label\", \"cluster\", \"bandit\", \"rank\", \"tree\", \"agent\", \"convex\", \"neuron\", \"dropout\", \"submodular\", \"deep\", \"classifi\", \"adversari\", \"tensor\", \"node\", \"variat\", \"latent\", \"edg\", \"game\", \"classif\", \"lemma\", \"convolut\", \"sinkhorn\", \"ancestr\", \"pixelcnn\", \"slab\", \"coreset\", \"normaliz\", \"kitti\", \"convnet\", \"calcium\", \"quantize\", \"postsynapt\", \"foreground\", \"warp\", \"presynapt\", \"teacher\", \"grammar\", \"trail\", \"tikhonov\", \"bouchard\", \"langevin\", \"renorm\", \"sift\", \"pyramid\", \"renam\", \"auto\", \"svhn\", \"cplex\", \"cuturi\", \"gpus\", \"maxout\", \"hash\", \"clip\", \"bfgs\", \"minibatch\", \"bit\", \"dropout\", \"spike\", \"poisson\", \"layer\", \"neuron\", \"deep\", \"gibb\", \"frame\", \"pixel\", \"posterior\", \"convolut\", \"unsupervis\", \"block\", \"video\", \"cluster\", \"emb\", \"admm\", \"chain\", \"cifar\", \"bayesian\", \"recurr\", \"architectur\", \"latent\", \"graph\", \"variat\", \"mnist\", \"hide\", \"supervis\", \"label\", \"likelihood\", \"compress\", \"covari\", \"topic\", \"kernel\", \"classif\", \"tensor\", \"convex\", \"inlier\", \"breakdown\", \"anchor\", \"deblur\", \"lyapunov\", \"blockmodel\", \"isoton\", \"tracker\", \"theta\", \"extrapol\", \"elkan\", \"spec\", \"safeti\", \"spectra\", \"elicit\", \"advis\", \"dann\", \"pursuit\", \"safe\", \"stan\", \"fenchel\", \"disagr\", \"sandwich\", \"modulus\", \"chair\", \"backtrack\", \"household\", \"certif\", \"rpca\", \"covertyp\", \"outlier\", \"corrupt\", \"incoher\", \"restart\", \"dictionari\", \"serial\", \"prox\", \"topic\", \"acceler\", \"proxim\", \"sdca\", \"recoveri\", \"norm\", \"subspac\", \"nesterov\", \"newton\", \"spectral\", \"convex\", \"saga\", \"tensor\", \"composit\", \"queri\", \"spars\", \"rank\", \"cluster\", \"reward\", \"kernel\", \"regress\", \"lemma\", \"dual\", \"oracl\", \"posterior\", \"mixtur\", \"regret\", \"nois\", \"label\", \"latent\", \"smooth\", \"likelihood\", \"polici\", \"graph\", \"variat\", \"pareto\", \"mdps\", \"bandit\", \"elud\", \"thompson\", \"successor\", \"arm\", \"rollout\", \"optimist\", \"horizon\", \"dialog\", \"polici\", \"bellman\", \"reward\", \"duel\", \"tabular\", \"garivi\", \"sriperumbudur\", \"player\", \"muno\", \"discount\", \"agent\", \"lattimor\", \"caption\", \"regret\", \"episod\", \"jaksch\", \"frazier\", \"transduc\", \"auer\", \"bubeck\", \"action\", \"reinforc\", \"game\", \"navig\", \"environ\", \"trajectori\", \"screen\", \"market\", \"adversari\", \"plan\", \"decis\", \"oracl\", \"learner\", \"feedback\", \"convex\", \"confid\", \"kernel\", \"risk\", \"queri\", \"batch\", \"lemma\", \"smooth\", \"round\", \"transit\", \"sobolev\", \"precondition\", \"musco\", \"wirting\", \"invit\", \"utter\", \"censor\", \"reaction\", \"privileg\", \"hazard\", \"krylov\", \"puriti\", \"exercis\", \"attractor\", \"wavelet\", \"glimps\", \"grade\", \"satellit\", \"rpca\", \"dantzig\", \"nystrom\", \"precondit\", \"nystr\", \"plateau\", \"aid\", \"radon\", \"neyshabur\", \"unspecifi\", \"orthonorm\", \"fade\", \"fourier\", \"harmon\", \"schatten\", \"cyclic\", \"lasso\", \"svrg\", \"isometri\", \"counterfactu\", \"kernel\", \"singular\", \"polynomi\", \"nonconvex\", \"recoveri\", \"rank\", \"phase\", \"norm\", \"saddl\", \"eigenvalu\", \"subspac\", \"graph\", \"admm\", \"convex\", \"risk\", \"tensor\", \"matric\", \"entri\", \"spars\", \"spectral\", \"sparsiti\", \"descent\", \"densiti\", \"covari\", \"lemma\", \"regress\", \"smooth\", \"cluster\", \"layer\", \"proxim\", \"label\", \"hypergraph\", \"bptt\", \"cub\", \"glasso\", \"codeword\", \"slot\", \"mallow\", \"crowd\", \"multilinear\", \"cue\", \"lattic\", \"poincar\", \"dcnn\", \"dilat\", \"wave\", \"dorsal\", \"acut\", \"dialogu\", \"untrain\", \"rcnn\", \"membership\", \"assembl\", \"suffix\", \"crowdsourc\", \"winner\", \"spatiotempor\", \"liter\", \"glove\", \"angular\", \"assort\", \"ndcg\", \"nade\", \"resnet\", \"gate\", \"worker\", \"stimulus\", \"conic\", \"depth\", \"tensor\", \"conv\", \"lstm\", \"sketch\", \"layer\", \"transfer\", \"overlap\", \"rank\", \"neuron\", \"cluster\", \"scene\", \"queri\", \"convolut\", \"residu\", \"stream\", \"deep\", \"shape\", \"permut\", \"mixtur\", \"filter\", \"group\", \"respons\", \"visual\", \"spars\", \"label\", \"graph\", \"convex\", \"lemma\", \"spike\", \"pixel\", \"regret\", \"latent\", \"buyer\", \"hawk\", \"seller\", \"revenu\", \"shapley\", \"abel\", \"ordin\", \"orbit\", \"treewidth\", \"valuat\", \"dpps\", \"autocorrel\", \"hankel\", \"deliber\", \"netflix\", \"polyhedra\", \"demix\", \"campaign\", \"dispers\", \"forest\", \"auction\", \"anisotrop\", \"tall\", \"breiman\", \"exposur\", \"bidder\", \"reserv\", \"trim\", \"wake\", \"stitch\", \"haar\", \"user\", \"recommend\", \"item\", \"tree\", \"quadratur\", \"leaf\", \"stein\", \"event\", \"nuclear\", \"submodular\", \"price\", \"kernel\", \"denois\", \"latent\", \"rank\", \"tensor\", \"word\", \"shrinkag\", \"screen\", \"neuron\", \"dynam\", \"hash\", \"spike\", \"label\", \"subspac\", \"layer\", \"varianc\", \"norm\", \"convex\", \"regret\", \"variat\", \"cluster\", \"posterior\", \"nois\", \"regress\", \"node\", \"spectral\", \"graph\", \"submodular\", \"supermodular\", \"beth\", \"matroid\", \"infect\", \"fujishig\", \"contagion\", \"recover\", \"secret\", \"honor\", \"transmiss\", \"bilm\", \"motif\", \"modular\", \"fuzzi\", \"glms\", \"svrg\", \"bet\", \"halfspac\", \"epidem\", \"thread\", \"jegelka\", \"iyer\", \"backup\", \"cond\", \"queue\", \"skene\", \"opinion\", \"spam\", \"enyi\", \"item\", \"cascad\", \"communiti\", \"branch\", \"dpps\", \"influenc\", \"templat\", \"user\", \"cover\", \"ise\", \"greedi\", \"worker\", \"rank\", \"pairwis\", \"node\", \"asynchron\", \"nod\", \"graph\", \"queri\", \"edg\", \"detect\", \"stimulus\", \"kernel\", \"partit\", \"cluster\", \"group\", \"convex\", \"label\", \"decod\", \"round\", \"polici\", \"spike\", \"tree\", \"regret\", \"pomdp\", \"fixat\", \"metabol\", \"certifi\", \"watkin\", \"connectom\", \"congest\", \"seth\", \"attack\", \"peer\", \"salienc\", \"glimps\", \"defend\", \"tag\", \"fmri\", \"caron\", \"itti\", \"arc\", \"pitman\", \"finley\", \"exercis\", \"infant\", \"bilater\", \"glasso\", \"junction\", \"feder\", \"anomali\", \"malici\", \"boolean\", \"intervent\", \"submodular\", \"coverag\", \"traffic\", \"scan\", \"sensor\", \"stein\", \"action\", \"greedi\", \"contextu\", \"screen\", \"reward\", \"learner\", \"expert\", \"edg\", \"interact\", \"regret\", \"causal\", \"tree\", \"polici\", \"bandit\", \"score\", \"graph\", \"node\", \"nod\", \"path\", \"agent\", \"gene\", \"influenc\", \"rank\", \"activ\", \"lasso\", \"densiti\", \"block\", \"kernel\", \"cluster\", \"layer\", \"label\", \"sgld\", \"approv\", \"binar\", \"analyst\", \"campaign\", \"bet\", \"privaci\", \"holdout\", \"layout\", \"bad\", \"blackbox\", \"jacobian\", \"multilabel\", \"tabul\", \"hamiltonian\", \"slack\", \"wealth\", \"hear\", \"teach\", \"cold\", \"mesh\", \"privileg\", \"privat\", \"invest\", \"howard\", \"summand\", \"bounc\", \"stein\", \"congest\", \"reservoir\", \"vote\", \"handwrit\", \"dropout\", \"reject\", \"exclus\", \"langevin\", \"quantiz\", \"mutual\", \"ensembl\", \"differenti\", \"label\", \"diverg\", \"player\", \"variat\", \"classifi\", \"layer\", \"tree\", \"posterior\", \"mont\", \"adversari\", \"deep\", \"game\", \"densiti\", \"classif\", \"risk\", \"segment\", \"discrimin\", \"convolut\", \"node\", \"latent\", \"graph\", \"neuron\", \"convex\", \"polici\", \"bayesian\", \"trim\", \"shapley\", \"interrupt\", \"arcco\", \"contest\", \"gumbel\", \"fitc\", \"recover\", \"covtyp\", \"oppon\", \"professor\", \"queue\", \"hit\", \"pack\", \"mohan\", \"stroke\", \"kaplan\", \"mmse\", \"compil\", \"banach\", \"fidel\", \"condens\", \"epidemiolog\", \"taxonomi\", \"font\", \"pagerank\", \"censor\", \"broeck\", \"azuma\", \"wiki\", \"maker\", \"volatil\", \"payoff\", \"regret\", \"ellipsoid\", \"nystr\", \"forest\", \"particl\", \"bandit\", \"onlin\", \"round\", \"classifi\", \"learner\", \"polytop\", \"queri\", \"kernel\", \"ensembl\", \"lemma\", \"action\", \"convex\", \"tree\", \"agent\", \"minimax\", \"arm\", \"metric\", \"label\", \"decis\", \"rank\", \"graph\", \"adversari\", \"regress\", \"reward\", \"posterior\", \"risk\", \"cluster\", \"polici\", \"classif\", \"game\"], \"Freq\": [4144.0, 5091.0, 7031.0, 5532.0, 3355.0, 5358.0, 3352.0, 5488.0, 4442.0, 7122.0, 2425.0, 4104.0, 2783.0, 2678.0, 4456.0, 4465.0, 1904.0, 1704.0, 4540.0, 2548.0, 2686.0, 4091.0, 2768.0, 3706.0, 4557.0, 2755.0, 2184.0, 2896.0, 2583.0, 4033.0, 470.46237078691985, 557.9286009802446, 562.1551062659767, 742.9318633303664, 914.9996407245849, 345.15872173454363, 577.9077411499721, 913.3698951216198, 844.4043139624756, 1093.3232659998694, 393.8733374463284, 575.6838677152107, 608.4008049546035, 294.636519361539, 710.8039104195394, 638.8738977777253, 321.492505614455, 328.8740712543164, 341.7845126703517, 609.5362776333191, 332.4798798536328, 600.5599776848973, 588.9860312428066, 191.96251090230905, 1003.6833558688273, 851.6055732097749, 382.36469575904914, 261.40968358980643, 352.23877166777953, 398.1855796100503, 1793.2721143667854, 684.6664006230759, 950.2373911611112, 1024.6552985793826, 933.1128598119695, 1407.3046251654862, 2389.8018557547457, 1416.0360943601281, 4736.996775313294, 3087.76488620539, 3135.822942597889, 1724.3766976861948, 1785.6767563547087, 1621.9747273392131, 3617.400140086799, 2734.566975338617, 1479.0514581474163, 2333.7146844018625, 1621.9050594747646, 4339.874056305316, 2010.639540579548, 1499.42299440499, 1786.0985945644957, 1471.219286152112, 2320.486871100277, 1813.878761930655, 1748.6713434837632, 2774.2665906742236, 3160.645134464744, 2285.738498391822, 1731.8098757205432, 1737.7029824703209, 1736.8690964431028, 2412.906330377173, 1881.8375644091586, 1568.5530967226437, 1800.3538315045168, 1837.0746135484078, 2324.453966461003, 1685.9577791825889, 1791.5878831020116, 1681.4776105064946, 201.38899899894662, 189.15732311961966, 400.95366673777585, 218.49903917634433, 237.7976992847513, 270.73894706334823, 340.32672265254763, 155.05779462497046, 108.29063783717103, 357.3587651090576, 125.0342537495767, 148.83491609806188, 203.34923170180562, 147.14936205228696, 184.27888601720457, 88.41943223092814, 122.84624052143685, 238.907819927032, 356.6251642675154, 112.73631378285582, 161.82043242665358, 215.50161151610433, 119.02123374518742, 121.09248093908597, 179.844798096325, 198.86304013850352, 149.29576759764458, 124.48991993516702, 212.64739000115333, 85.95077038946947, 663.679743396505, 523.6569437950715, 295.07627450197407, 306.90790264328785, 549.0501769075701, 190.8978687134754, 426.26642678167957, 1038.5609610254517, 607.5829768326092, 878.9826718569442, 305.2265833835412, 648.2350297912171, 895.311230202348, 859.5123633727316, 400.0673709180676, 535.3093761768845, 749.540721761306, 1111.6812762056861, 353.8168094894897, 985.5937620067472, 464.8203556092753, 647.3125016761494, 776.8018231318289, 875.4366149259793, 1189.0789922237534, 754.0827421226487, 1002.0059968118962, 670.344932583308, 629.4120975367501, 633.1083255619444, 539.5106722067821, 866.1025155486494, 598.671725087124, 707.6866205416486, 590.8662742594894, 704.7976470863393, 705.7218739694414, 566.9770332920743, 595.3515072322579, 649.5842884364935, 634.5600441878021, 584.240545027311, 209.80393437214562, 530.3496464667743, 1418.440450972176, 117.2467463151723, 326.9395686604067, 142.5878667415216, 910.4296174004015, 255.98923622709356, 360.0239317258252, 403.72311944907847, 160.88454677883365, 2698.2317274998954, 279.73188086503535, 1713.1412881972724, 197.29677328505903, 86.7601218747312, 97.18834665620454, 132.9559991720728, 774.6603176123583, 176.8526417411928, 291.4600620088764, 1274.137623283077, 87.5467422256973, 316.83252053030697, 1961.3540335882853, 611.8948484280016, 69.9586556519697, 84.72451227143556, 96.81796546852505, 142.04142229666442, 187.02725778591036, 1282.9044631467204, 735.3715397164923, 790.315202446028, 151.54310787846862, 401.69443590644005, 601.2401445688939, 242.73393635475523, 262.93177345462254, 581.9547616081215, 326.20425706372635, 397.990825910337, 442.9404936971823, 359.870875102871, 366.647885692406, 550.0711538389758, 325.3595571906571, 543.4551819243632, 384.2507639091291, 381.8270774990533, 395.2091584458435, 383.7498202663474, 381.50807494743754, 354.1156292824, 327.12306267997104, 123.40575438771361, 93.57834542491071, 75.04166195630056, 76.94981579904785, 58.63722763529763, 75.79635714503323, 83.90398477078817, 92.66792403110892, 71.87836564572761, 67.79862560708753, 83.23994694697795, 69.63784239838431, 54.49180475471661, 105.3748855972146, 94.40538537505202, 68.85428400863982, 53.37884463571503, 71.38164331085315, 137.52590248348739, 90.98315427447653, 55.54677240425036, 139.7311103942975, 176.91057684156587, 40.958560507349205, 64.06435367798764, 65.04669003194209, 45.688523329428676, 53.49957785519296, 146.30910605010303, 35.88131315375483, 194.17301215318565, 126.6319654154717, 94.34941911150526, 140.11227247481068, 452.9287796992524, 227.17685706495868, 81.94497622943132, 116.06400190002849, 751.7785574095794, 265.1257700940668, 290.0564738141958, 210.06898647168052, 310.5059877725528, 489.2491143692662, 264.7193009062669, 397.073855144508, 156.6529998440944, 250.59953144493292, 335.3270921724065, 450.75570454900856, 264.93733294340853, 385.4754021843955, 273.09487891503676, 355.1257437621218, 249.13040935180777, 234.16671489099033, 301.4012826330996, 255.6911822572843, 236.19850822837506, 251.5411441298831, 242.7611026725079, 265.6030132220184, 244.5557685169495, 248.44594061829355, 238.8655887555538, 304.8785180610775, 300.9801183356904, 234.68980348624663, 229.2062353286193, 187.4035883678613, 69.44158703648934, 54.30557117265967, 81.09114945619923, 58.17946155389606, 81.75303443984944, 75.2722040135617, 81.05780472604428, 102.04949884739884, 89.3663288921401, 123.35436449474471, 43.97837690568517, 53.47901033004446, 65.23781760895993, 58.91403435798551, 38.4704936755869, 31.54555389356852, 44.630207495213796, 32.73709847104327, 68.93427078484625, 97.00429352301404, 58.93253040031842, 38.001096727647955, 105.10960291561416, 86.08379772040306, 89.26091595237247, 47.04462874373271, 37.19943896697635, 66.84391478741806, 38.0111994602028, 55.62179594996588, 66.65561901219282, 181.8027283585566, 188.5204874183491, 288.5230909142386, 211.08811993020007, 72.5081728491668, 214.48495831342768, 524.2028526568439, 181.7648310268676, 279.52948810532575, 174.20999092361768, 608.3817557650929, 210.4939966411979, 149.62402667992095, 385.286456896995, 392.1440458610482, 525.7888805966861, 180.4366315013178, 247.73285340330997, 315.03640516954806, 170.42087297113972, 169.98832309256676, 278.82664728548104, 156.2815296854324, 163.8180363392613, 206.13156729244494, 202.63270844858513, 193.04913066712587, 172.56782009072597, 177.52867924344577, 209.46593484226682, 226.66794852755618, 238.3152434353051, 223.99444645988268, 191.1214818361074, 187.4516807145687, 177.28234658746717, 183.25100055236598, 183.4310128778888, 140.16275739559308, 127.3059707955322, 80.05163966441835, 173.34666042161402, 43.14879379882231, 43.67098475640506, 100.99219202974587, 55.03657444985314, 68.50465262815044, 52.39276671150857, 73.55300645905508, 48.63565275724176, 64.81786777274702, 38.966969983103944, 54.396146318293475, 33.81667909593613, 44.97099161381962, 30.743162942030352, 48.94956195532862, 129.47124780951359, 137.77961031757832, 39.54298551999544, 30.106945488393553, 39.9766518984762, 43.390322446842404, 58.01594311583319, 50.32692190213986, 48.250775239989, 43.353381459593294, 30.087373083026606, 36.997324112864334, 275.02640821464047, 167.6059418095716, 322.18665503657945, 379.33297981122996, 79.4123524667707, 102.03402449649559, 72.14308715718454, 155.27747822232095, 125.94180034205569, 191.64960399897237, 128.23001577235505, 395.97280595177995, 137.5114648334739, 326.94025398008955, 294.6912924072108, 264.36537308484293, 196.67273092631095, 106.29818137373476, 97.19670255894643, 248.76117302787304, 197.200979611179, 176.721312516748, 209.09136917297934, 227.10618791538306, 186.17657003779303, 265.40483449023804, 166.36016090235339, 186.96428270312228, 216.2207567282313, 207.8035632472689, 198.56437705405716, 241.0334009415392, 210.97681635035016, 171.09984565509282, 168.866380186982, 166.81998328367715, 163.77780007378516, 168.09650622776905, 775.2264953172241, 160.15153215511924, 151.4300768383002, 108.017814070903, 89.59844905703413, 43.86748925870663, 41.9494160492248, 58.992242327933745, 49.36232206252085, 44.459317330815296, 62.98472081613516, 59.94687162441333, 63.387156179475696, 115.63257047351544, 46.629551177601506, 66.65136818674105, 232.99343183303614, 35.6461626958307, 51.02283996950497, 29.4384415369216, 106.24115768041152, 39.28808451763392, 35.104991195895266, 35.89481014067895, 34.9996087423721, 56.503636653695864, 29.28797033851113, 53.69616630605037, 52.98115338528061, 64.27811510651324, 327.4988283894233, 111.60263569266318, 168.7557567352313, 73.61231780824612, 52.73793723606833, 149.34902812929627, 119.35101329005761, 159.34911233805687, 131.58482189287335, 101.30429309951732, 151.57527991304661, 150.953881083582, 258.3514485189444, 138.48100223165625, 197.09583777871424, 114.17663691888704, 180.6916599379275, 252.84031183810148, 166.15021336782777, 178.60913269105578, 145.06920712862544, 118.2434019448245, 216.45350823179257, 146.41241216095509, 227.4503267658625, 148.53188953436077, 184.8990459032373, 173.33785214882016, 135.05577611857177, 133.52402420769565, 149.2406020189912, 140.63476569940164, 136.22354131075053, 136.8089623854321, 88.29807527162056, 48.5396754214366, 23.181173608757796, 22.733816112938268, 22.96140461787462, 32.840881582052376, 22.21310067185212, 17.619741016635537, 69.70935484800965, 22.231336527026464, 79.14031461533565, 30.324562604914306, 20.928785812019406, 65.19000476423079, 67.85387835865697, 17.93504904957974, 14.71631577046351, 14.258330638898025, 16.388849825216464, 10.785077661333498, 19.253442022637604, 12.518775864685988, 12.733916535524694, 24.212554286296147, 18.142698438854918, 23.225680966592652, 31.41644612726469, 14.204877937635175, 27.6408305416303, 80.46890940901777, 161.0601955033166, 49.98685650064217, 26.670607560947214, 44.74137872882701, 62.10895493367218, 35.11242783339548, 167.41552490526936, 89.07017486344061, 44.53147445493006, 49.55397994483283, 145.21574385945917, 79.80789595000928, 75.41552264517479, 120.24859033767072, 72.31196913060835, 144.5503883765581, 93.78934837069721, 108.70829084752303, 151.50931716527575, 98.49543128883344, 101.76956892185368, 139.6892829471432, 97.7960428549171, 94.20378906725989, 79.40492000301137, 87.73554123712337, 60.389152174537536, 58.409505414997184, 95.71820054761326, 75.70141233719161, 71.61723885605373, 73.02925470312493, 78.00652378809053, 77.84377853892272, 76.30456655360202, 75.45694284337726, 72.60590414772774, 44.47371298980294, 11.609772951556467, 19.82248902096092, 10.059421900588324, 11.329085458563894, 13.367258420383813, 84.73278655248895, 13.203471188693818, 12.757179239930318, 12.328463230040429, 10.97878679414334, 27.757591343714505, 18.526542868575262, 8.611566818708663, 28.45302665579855, 17.245655565073996, 11.66942822702902, 10.022191461548173, 20.37158034888875, 11.836269786815862, 13.976011496532475, 13.484963729754304, 53.21870985074628, 12.297831757876544, 11.356688493624066, 11.086331506893899, 9.691651670360251, 22.361044261679105, 8.383937252499443, 11.045996575957691, 40.48162930333354, 13.628632041588329, 71.59531474168023, 28.788379744429694, 17.039891751664083, 31.01587897539049, 26.47150804152768, 31.915176731075814, 30.75464856374177, 37.634820752865245, 63.832838997492956, 43.540896107125214, 37.08512584115987, 55.595270001955804, 45.42547884308418, 70.80173638372918, 44.567596967298606, 59.731485610855124, 32.45867074992443, 42.99734059716789, 53.361819078947214, 39.10754251546771, 39.59274943601247, 41.17799345479644, 37.65899646770866, 36.096740414457855, 36.462544547394444, 40.74998621084373, 37.246271382456165, 39.09093667974328, 37.488462205025385, 34.30975701350999, 33.30243232532689, 33.287891296305276, 32.732688075809605, 10.974617448733632, 5.60785249419108, 4.9552111877971345, 4.1409067640469175, 4.066724146547083, 7.042119437249243, 6.710519724416853, 5.894014200678728, 4.6885732769085555, 5.752230977161069, 3.9773031693273317, 7.790287644481211, 7.101277547504539, 5.154363644000786, 3.039534905678037, 4.394739975738553, 2.6064107461144315, 6.276728203206855, 7.418739128058213, 4.951012841161349, 8.6425178209539, 2.706999144755831, 2.874620779122158, 4.839965346944351, 4.011775672273934, 6.003044772529902, 4.908656826373533, 3.2048260964024196, 2.581745782181943, 4.551185802311648, 7.452085276790605, 5.521760583937213, 9.989298780758821, 57.78438646401612, 6.6636057166734215, 10.555584651299526, 9.581611453866136, 15.823994239911155, 24.468784767564173, 20.13304227080982, 18.93695473177724, 21.095962875601703, 14.656100391931185, 11.38160290083533, 17.234321317626044, 25.806214923053528, 11.463077145874239, 17.56156914871212, 19.11583345723061, 21.41320770070522, 17.01635693974966, 16.50409672005517, 11.881871899376474, 12.860584686965538, 13.962809374813906, 17.136066588154122, 12.309985847024464, 16.159296858350398, 17.280197350609647, 13.884875468794235, 13.945919222444799, 14.077211095111538, 15.419243433283697, 12.71936335034397, 14.925435811494863, 13.188774372090988, 12.367268635572596, 11.754339701601156], \"Total\": [4144.0, 5091.0, 7031.0, 5532.0, 3355.0, 5358.0, 3352.0, 5488.0, 4442.0, 7122.0, 2425.0, 4104.0, 2783.0, 2678.0, 4456.0, 4465.0, 1904.0, 1704.0, 4540.0, 2548.0, 2686.0, 4091.0, 2768.0, 3706.0, 4557.0, 2755.0, 2184.0, 2896.0, 2583.0, 4033.0, 536.9830595745283, 645.27285573245, 655.4327906355217, 875.2195925371817, 1086.1845900237388, 410.6352853930114, 690.4273623990975, 1095.9483471595838, 1016.1614732271527, 1322.8895649397837, 477.2458808026693, 702.3759966667864, 743.5830821468608, 365.03772923477874, 882.4048157127946, 796.5365866392802, 401.4340220559707, 412.53927789719575, 429.1077216129894, 767.0238183294585, 419.15682212881325, 762.3652523858515, 754.8992480224198, 246.52967792283238, 1290.5209066679226, 1095.877897944189, 492.3717803666716, 336.7687969169784, 457.78271074890785, 517.7204532165964, 2351.284255684959, 893.6006073659455, 1252.2990067178805, 1357.687001020792, 1236.6338617504314, 1904.7045837309215, 3378.1802707255615, 1938.672106095766, 7031.082722575461, 4465.313481925188, 4540.353558574033, 2411.1717738401167, 2504.7621195833362, 2259.1930708322884, 5488.951160244525, 4033.5629168633504, 2042.7176457080288, 3452.918708169475, 2296.3772882946055, 7122.738796747191, 2953.8909173243505, 2103.181449408615, 2611.0998036649844, 2084.400866743387, 3615.5352985499203, 2702.6363191938026, 2588.9512131523306, 4557.576240186302, 5358.546924149673, 3706.1481118258466, 2599.107911387651, 2614.605662925806, 2693.666520293616, 4442.005286183273, 3205.7764921202365, 2360.503741794233, 3119.9797608793397, 3316.284890890317, 5532.653046253988, 2896.6539494797503, 4091.339296034217, 4456.343024628412, 300.17941014150614, 296.58430056352626, 669.008460955903, 377.3157936210053, 412.2656282567227, 471.7199632413147, 594.3398043548834, 271.399685442611, 199.04052304871018, 661.8402599471863, 233.71830621867647, 280.67718217004165, 393.98322801111533, 285.787618484874, 362.9067862379968, 175.60046644723263, 244.30666175157606, 476.1788899207417, 712.4858567541891, 227.9547565952998, 328.86524374706653, 451.3926728647264, 249.56674511975973, 254.11972632919537, 382.8273572818629, 425.5912559031006, 320.23031794756326, 267.5901573939374, 460.83163400986547, 187.27438707094038, 1451.2317003649746, 1155.6029134994972, 651.2242153054586, 684.0188560756462, 1306.157814218386, 418.72151028697476, 1079.6048660881738, 3316.284890890317, 1729.5650733437153, 2749.683596971476, 742.7147186733321, 1979.9960770772989, 3038.7315814985354, 2882.789382741335, 1074.0767396060446, 1592.0658294240818, 2525.3699456513777, 4456.343024628412, 914.2273882630665, 4091.339296034217, 1389.235168759297, 2346.9081141098754, 3245.2901380801295, 4104.405902907862, 7122.738796747191, 3355.416152739191, 5532.653046253988, 2824.9504816515278, 2583.9034738951395, 2623.2162865179926, 1937.237616605589, 5488.951160244525, 2524.276965766151, 4144.989477675034, 2692.165859404556, 4442.005286183273, 4557.576240186302, 2522.9630227043763, 3205.7764921202365, 5091.4718776829, 5358.546924149673, 3706.1481118258466, 321.12672285963885, 854.733684775727, 2425.7154585415315, 201.35803432784783, 569.0037592396076, 250.25483059710902, 1600.0162946608984, 455.71022556362766, 643.4836972756725, 729.5224115615182, 298.2972217751689, 5091.4718776829, 542.8873711563324, 3355.416152739191, 388.43710572604806, 175.0612502393565, 198.48243394380177, 274.25851016970984, 1606.6786885787062, 367.9697611370587, 608.9621887007401, 2678.720711567761, 184.44876938243408, 669.443976337871, 4144.989477675034, 1301.7112994923364, 150.78332578137642, 183.8998932061746, 216.70345774722642, 319.14179492092416, 425.8583575058146, 3352.025814878973, 1846.7567757239046, 2184.460823624798, 344.3174201245295, 1144.7551983207445, 2164.0869089407497, 669.7119435891823, 754.3127090113368, 2686.0379468017063, 1099.121301952698, 1598.5036593357415, 1937.237616605589, 1380.007877986467, 1577.7841922778648, 4456.343024628412, 1301.6959119462638, 5532.653046253988, 2298.795344912379, 2346.9081141098754, 2937.222757946268, 2583.9034738951395, 2522.9630227043763, 1863.2739104892255, 2144.4046220947266, 269.994483482995, 215.08027232084672, 184.83792681434878, 191.3341170357619, 148.55071948795975, 206.35345677253775, 230.06411851095876, 269.82065996039177, 216.923286416019, 205.0302901388833, 253.95334992097463, 219.02998946095346, 172.88428894782095, 339.2071456821265, 305.4192190775406, 224.80394628593848, 175.72935047111696, 238.65930950560613, 460.83163400986547, 306.6285711365865, 188.8343107023918, 481.2891890525449, 609.3856012114422, 143.23917793242768, 224.581335579028, 228.9598729048158, 161.06848835239185, 191.50875037616592, 525.6190459479368, 129.1414945130001, 709.4168218158078, 462.45882952362126, 346.7198385648453, 528.3693426303714, 2205.0636935963366, 989.6888237215505, 301.35618304547273, 459.59112849580725, 5532.653046253988, 1446.172214093351, 1721.4476185833657, 1118.50366148986, 1979.9960770772989, 4104.405902907862, 1619.3407044780297, 3038.7315814985354, 736.5077601854673, 1585.796027274732, 2882.789382741335, 5358.546924149673, 2103.181449408615, 4456.343024628412, 2298.795344912379, 4091.339296034217, 2103.7524617800113, 1859.7711970826235, 3245.2901380801295, 2525.3699456513777, 2164.5696206232446, 2554.175930894527, 2407.711664971938, 3119.9797608793397, 2583.9034738951395, 2824.9504816515278, 2522.9630227043763, 7122.738796747191, 7031.082722575461, 2749.683596971476, 4442.005286183273, 336.0874481985072, 188.68555906272002, 149.62883170991026, 226.800968445669, 169.0196858740328, 248.206663376342, 248.70163141598042, 268.20398494178096, 341.8144863976268, 304.5229947424805, 422.1961421794949, 158.27322368752075, 196.74704235176748, 243.08547392947017, 224.6978855486461, 152.77831482303918, 127.05703396715448, 181.33558894246116, 133.5825838030151, 289.1228257343146, 409.07183822620556, 251.72521947344413, 164.61938744747468, 457.9066127689996, 375.5613856400375, 390.1072575161108, 206.09506062047484, 165.25407803788872, 297.46444181264206, 169.53110616327982, 248.74497461180977, 299.44664198702, 873.7703614416855, 957.0688462918907, 1538.9689099584907, 1146.527401505545, 335.05274082235144, 1319.8240764828747, 4091.339296034217, 1149.2013589934716, 2072.4256890493207, 1113.0994211812142, 7031.082722575461, 1534.4447499724283, 954.5473821259155, 4104.405902907862, 4465.313481925188, 7122.738796747191, 1331.8004839984317, 2346.9081141098754, 4033.5629168633504, 1382.5012898042714, 1389.4387722710474, 4540.353558574033, 1235.4868605308359, 1391.2140032936738, 2524.276965766151, 2488.4057998070557, 2232.8540532158613, 1703.713760076442, 1915.5524062900365, 3245.2901380801295, 4442.005286183273, 5358.546924149673, 4456.343024628412, 2583.9034738951395, 3378.1802707255615, 2259.1930708322884, 4144.989477675034, 4557.576240186302, 297.88416124561223, 301.3832933925024, 198.29763318967707, 449.04853853220794, 132.44047810915424, 135.20288359718774, 320.92596578150324, 189.87599497717028, 245.94429791214662, 188.9566513446209, 269.5318542340581, 184.75085861435423, 247.43140201661717, 148.83891578732747, 218.665432906275, 139.38924932338358, 187.48538582307413, 129.61718358268374, 208.60860997156536, 554.0005176441173, 596.0349574291768, 178.26177389608364, 136.44860196637362, 183.4388385258452, 199.15833832310236, 266.99104103940687, 236.28439842794913, 227.81308955645864, 205.91121619095057, 145.81110648384475, 179.7206267907272, 1414.2395997928434, 889.0124445087152, 1822.3559148628894, 2783.988586971274, 434.19313816744284, 625.012385664264, 403.2354608483555, 1195.4712740338164, 903.6574468942601, 1704.7148723652492, 948.04012645968, 5532.653046253988, 1081.8843793446288, 4557.576240186302, 4104.405902907862, 4091.339296034217, 2549.7739022148417, 795.5753051030433, 669.7119435891823, 4465.313481925188, 2789.6716009122924, 2351.284255684959, 3378.1802707255615, 4442.005286183273, 2882.789382741335, 7031.082722575461, 2222.274581692864, 3038.7315814985354, 4456.343024628412, 4144.989477675034, 3706.1481118258466, 7122.738796747191, 5488.951160244525, 2692.165859404556, 2824.9504816515278, 2768.449485584135, 2525.3699456513777, 5358.546924149673, 1704.7148723652492, 386.04498825675915, 403.7928982252618, 299.46133635278835, 260.75811465238934, 131.94450016041787, 131.43538933035467, 189.8781835628812, 168.75734878779087, 158.64622626355478, 226.13924206109914, 219.56650020943906, 236.54919564933743, 443.6913766617409, 182.5628108364651, 269.6765609029598, 989.6888237215505, 153.31748993741212, 219.47964049175178, 129.0043745502915, 486.3057712738991, 179.9207277927934, 161.40446782124155, 170.9978351247592, 168.8571378909147, 273.17392625006414, 142.65178985036076, 264.36074252659023, 261.1892250310792, 320.213564348252, 1822.3559148628894, 617.0227789054134, 1053.81601852326, 405.84319243491933, 269.5318542340581, 1033.7242328643986, 833.1519016557874, 1414.2395997928434, 1065.6593110208253, 716.2679130989451, 1427.070198684694, 1538.9689099584907, 4104.405902907862, 1343.0280697584205, 2768.449485584135, 988.5540272995132, 2609.561548923618, 5358.546924149673, 2346.9081141098754, 2755.3088654278376, 1914.223614361881, 1146.527401505545, 5532.653046253988, 2099.8535898511022, 7122.738796747191, 2232.8540532158613, 4456.343024628412, 4442.005286183273, 1918.5486814108472, 1863.2739104892255, 5091.4718776829, 3378.1802707255615, 2783.988586971274, 4144.989477675034, 322.5924023332988, 216.14222644491437, 138.6005049029768, 140.92754363387508, 142.99967672994194, 214.60372153405322, 151.6095303023236, 120.490947517467, 480.10905412166363, 156.76294302687185, 575.7432559789008, 224.80394628593848, 162.05165024538144, 516.8398807655317, 550.4024206595137, 149.4933341479286, 124.7607195167229, 124.18747159794682, 143.78515488645235, 96.16342761129762, 172.88428894782095, 116.87492466397003, 118.99646551298852, 226.800968445669, 170.2515885835239, 218.44544647726934, 301.6218968092109, 140.9744761135769, 274.634125994844, 819.8109411091999, 1704.7148723652492, 516.2934537453777, 272.23584989945914, 505.3083949251709, 776.1287699902543, 403.2354608483555, 3352.025814878973, 1427.070198684694, 561.5794125501708, 669.7119435891823, 3355.416152739191, 1380.007877986467, 1323.0125457452496, 2755.3088654278376, 1261.0803674686404, 4144.989477675034, 2108.853709480593, 2783.988586971274, 5091.4718776829, 2425.7154585415315, 2617.948369994158, 5358.546924149673, 2768.449485584135, 2609.561548923618, 1932.3754980594802, 2678.720711567761, 1119.2942411974955, 1033.7242328643986, 4104.405902907862, 2702.547965100177, 2205.0636935963366, 2407.711664971938, 3452.918708169475, 5532.653046253988, 7122.738796747191, 7031.082722575461, 4442.005286183273, 295.5825543557348, 128.14635589181995, 222.48403033094118, 113.24776381823443, 129.61718358268374, 153.31748993741212, 1010.521013415059, 172.44222714436728, 167.78873218954433, 165.45815909660448, 148.34617569700626, 384.37592095215797, 263.1252719914417, 125.85586263370578, 419.9959765504035, 257.4668698680301, 174.81971689495768, 153.80869786930467, 318.15045882166606, 188.86488438356324, 223.49567370254545, 216.923286416019, 891.7647167842458, 211.13871281654679, 196.03040962764052, 193.11577484062167, 169.4142905522672, 403.2354608483555, 151.6095303023236, 200.64355450138837, 780.4158067120285, 251.54101341502005, 1904.7045837309215, 641.4725058230747, 337.167011994614, 767.0238183294585, 622.9527553143298, 872.7448494592078, 1029.225925979687, 1568.2657714656448, 4442.005286183273, 2159.495789301496, 1606.6786885787062, 3706.1481118258466, 2548.1049728528637, 7031.082722575461, 2783.988586971274, 5488.951160244525, 1399.927267788246, 2686.0379468017063, 4540.353558574033, 2184.460823624798, 2407.711664971938, 2896.6539494797503, 2298.795344912379, 2252.377701041611, 2408.180870687694, 4033.5629168633504, 2768.449485584135, 4557.576240186302, 5358.546924149673, 4465.313481925188, 4456.343024628412, 5091.4718776829, 3615.5352985499203, 227.81308955645864, 132.44047810915424, 129.17548946949645, 112.00287787049136, 118.55307905239225, 210.93040942229726, 209.20083393850246, 189.8781835628812, 152.3653005391458, 195.4862891400188, 138.34174625718, 273.17392625006414, 252.24601592620706, 184.85807010727427, 109.65569678635974, 161.42386862591235, 100.76266215778233, 247.80278450917274, 293.1481268757344, 197.05648035914223, 353.5891256295791, 116.06884720707315, 125.55788493979918, 213.14724529272237, 183.47248387633266, 277.32994966502406, 230.06411851095876, 150.29686482031892, 122.94058182050237, 217.3377403840838, 361.4109928882624, 268.3528037920401, 511.2726212172738, 4144.989477675034, 340.037812624463, 609.3856012114422, 554.0005176441173, 1107.0659901114363, 2425.7154585415315, 2043.3727087349357, 1863.2739104892255, 2548.1049728528637, 1380.007877986467, 966.1617429708637, 2346.9081141098754, 5532.653046253988, 1029.225925979687, 2583.9034738951395, 3352.025814878973, 4456.343024628412, 2783.988586971274, 2678.720711567761, 1190.1957137334578, 1600.0162946608984, 2178.0398395634693, 4442.005286183273, 1598.5036593357415, 4104.405902907862, 5358.546924149673, 2686.0379468017063, 2824.9504816515278, 3355.416152739191, 5488.951160244525, 2298.795344912379, 7122.738796747191, 5091.4718776829, 2896.6539494797503, 2184.460823624798], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.8597, -7.6892, -7.6816, -7.4028, -7.1945, -8.1694, -7.654, -7.1963, -7.2748, -7.0164, -8.0374, -7.6578, -7.6026, -8.3277, -7.447, -7.5537, -8.2404, -8.2177, -8.1792, -7.6007, -8.2068, -7.6155, -7.635, -8.7561, -7.102, -7.2663, -8.067, -8.4473, -8.1491, -8.0265, -6.5216, -7.4845, -7.1567, -7.0813, -7.1749, -6.764, -6.2344, -6.7578, -5.5502, -5.9782, -5.9627, -6.5608, -6.5258, -6.622, -5.8199, -6.0997, -6.7142, -6.2582, -6.622, -5.6378, -6.4072, -6.7006, -6.5256, -6.7195, -6.2639, -6.5102, -6.5468, -6.0853, -5.9549, -6.279, -6.5565, -6.5531, -6.5536, -6.2248, -6.4734, -6.6555, -6.5177, -6.4975, -6.2622, -6.5833, -6.5225, -6.586, -7.6354, -7.6981, -6.9468, -7.5539, -7.4692, -7.3395, -7.1108, -7.8969, -8.2558, -7.0619, -8.1121, -7.9378, -7.6257, -7.9492, -7.7242, -8.4586, -8.1297, -7.4646, -7.064, -8.2156, -7.8542, -7.5677, -8.1614, -8.1441, -7.7486, -7.648, -7.9347, -8.1164, -7.581, -8.4869, -6.4429, -6.6798, -7.2534, -7.2141, -6.6325, -7.6889, -6.8856, -5.9951, -6.5312, -6.1619, -7.2196, -6.4664, -6.1435, -6.1843, -6.949, -6.6578, -6.3212, -5.927, -7.0719, -6.0474, -6.799, -6.4678, -6.2855, -6.1659, -5.8597, -6.3152, -6.0309, -6.4329, -6.4959, -6.49, -6.65, -6.1767, -6.5459, -6.3787, -6.5591, -6.3827, -6.3814, -6.6003, -6.5515, -6.4643, -6.4877, -6.5703, -7.148, -6.2207, -5.2369, -7.7299, -6.7044, -7.5343, -5.6803, -6.9491, -6.6081, -6.4935, -7.4135, -4.5939, -6.8604, -5.0481, -7.2095, -8.0311, -7.9176, -7.6042, -5.8418, -7.3189, -6.8193, -5.3442, -8.022, -6.7358, -4.9128, -6.0777, -8.2463, -8.0548, -7.9214, -7.5381, -7.263, -5.3373, -5.8938, -5.8218, -7.4734, -6.4985, -6.0952, -7.0023, -6.9223, -6.1278, -6.7067, -6.5078, -6.4008, -6.6085, -6.5898, -6.1842, -6.7093, -6.1963, -6.5429, -6.5493, -6.5148, -6.5442, -6.5501, -6.6246, -6.7039, -7.2617, -7.5383, -7.7591, -7.734, -8.0058, -7.7491, -7.6475, -7.5481, -7.8022, -7.8606, -7.6554, -7.8338, -8.0791, -7.4196, -7.5295, -7.8452, -8.0997, -7.8091, -7.1533, -7.5665, -8.0599, -7.1374, -6.9015, -8.3646, -7.9173, -7.902, -8.2553, -8.0975, -7.0914, -8.4969, -6.8084, -7.2359, -7.5301, -7.1347, -5.9614, -6.6514, -7.6711, -7.323, -5.4547, -6.4969, -6.4071, -6.7297, -6.3389, -5.8843, -6.4985, -6.093, -7.0231, -6.5533, -6.262, -5.9662, -6.4977, -6.1227, -6.4673, -6.2047, -6.5592, -6.6211, -6.3687, -6.5332, -6.6125, -6.5495, -6.5851, -6.4951, -6.5777, -6.5619, -6.6012, -6.3572, -6.3701, -6.6189, -6.6425, -6.6917, -7.6845, -7.9303, -7.5294, -7.8614, -7.5213, -7.6039, -7.5298, -7.2995, -7.4322, -7.1099, -8.1413, -7.9457, -7.7469, -7.8489, -8.2751, -8.4735, -8.1266, -8.4365, -7.6918, -7.3502, -7.8486, -8.2874, -7.27, -7.4697, -7.4334, -8.0739, -8.3087, -7.7226, -8.2871, -7.9064, -7.7254, -6.7221, -6.6858, -6.2602, -6.5727, -7.6413, -6.5567, -5.6631, -6.7223, -6.2919, -6.7647, -5.5142, -6.5755, -6.9168, -5.971, -5.9533, -5.6601, -6.7296, -6.4126, -6.1723, -6.7867, -6.7892, -6.2944, -6.8733, -6.8262, -6.5965, -6.6136, -6.662, -6.7742, -6.7458, -6.5804, -6.5015, -6.4514, -6.5134, -6.6721, -6.6915, -6.7472, -6.7141, -6.7131, -6.8146, -6.9108, -7.3747, -6.6021, -7.9927, -7.9807, -7.1424, -7.7494, -7.5305, -7.7986, -7.4594, -7.873, -7.5858, -8.0947, -7.7611, -8.2364, -7.9514, -8.3317, -7.8666, -6.8939, -6.8317, -8.08, -8.3526, -8.0691, -7.9872, -7.6967, -7.8389, -7.881, -7.988, -8.3533, -8.1465, -6.1405, -6.6358, -5.9823, -5.819, -7.3827, -7.1321, -7.4787, -6.7122, -6.9216, -6.5017, -6.9036, -5.776, -6.8337, -5.9676, -6.0715, -6.1801, -6.4759, -7.0911, -7.1807, -6.2409, -6.4732, -6.5828, -6.4146, -6.332, -6.5307, -6.1761, -6.6432, -6.5265, -6.3811, -6.4208, -6.4663, -6.2725, -6.4056, -6.6151, -6.6283, -6.6405, -6.6589, -6.6329, -4.9945, -6.5715, -6.6275, -6.9653, -7.1523, -7.8665, -7.9112, -7.5702, -7.7484, -7.8531, -7.5047, -7.5542, -7.4984, -6.8972, -7.8054, -7.4481, -6.1966, -8.074, -7.7154, -8.2653, -6.9819, -7.9767, -8.0893, -8.067, -8.0923, -7.6133, -8.2704, -7.6643, -7.6777, -7.4844, -5.8561, -6.9327, -6.5192, -7.3488, -7.6823, -6.6413, -6.8656, -6.5765, -6.768, -7.0295, -6.6265, -6.6307, -6.0933, -6.7169, -6.3639, -6.9099, -6.4508, -6.1149, -6.5347, -6.4624, -6.6704, -6.8749, -6.2702, -6.6612, -6.2207, -6.6468, -6.4278, -6.4924, -6.7419, -6.7533, -6.6421, -6.7015, -6.7333, -6.729, -6.442, -7.0403, -7.7794, -7.7988, -7.7889, -7.431, -7.822, -8.0537, -6.6784, -7.8212, -6.5515, -7.5107, -7.8816, -6.7454, -6.7053, -8.0359, -8.2337, -8.2654, -8.1261, -8.5445, -7.965, -8.3955, -8.3784, -7.7358, -8.0244, -7.7774, -7.4754, -8.2691, -7.6034, -6.5348, -5.8409, -7.0109, -7.6391, -7.1218, -6.7938, -7.3641, -5.8022, -6.4333, -7.1265, -7.0196, -5.9445, -6.5431, -6.5997, -6.1331, -6.6417, -5.9491, -6.3816, -6.234, -5.902, -6.3327, -6.3, -5.9833, -6.3398, -6.3772, -6.5481, -6.4484, -6.8219, -6.8552, -6.3613, -6.5959, -6.6514, -6.6318, -6.5659, -6.568, -6.588, -6.5991, -6.6377, -6.4379, -7.781, -7.246, -7.9243, -7.8054, -7.64, -5.7933, -7.6523, -7.6867, -7.7209, -7.8368, -6.9093, -7.3136, -8.0797, -6.8845, -7.3852, -7.7758, -7.928, -7.2187, -7.7616, -7.5955, -7.6312, -6.2584, -7.7234, -7.803, -7.8271, -7.9615, -7.1255, -8.1065, -7.8307, -6.532, -7.6206, -5.9618, -6.8728, -7.3972, -6.7983, -6.9567, -6.7697, -6.8068, -6.6049, -6.0765, -6.4591, -6.6196, -6.2147, -6.4167, -5.9729, -6.4358, -6.1429, -6.7528, -6.4717, -6.2557, -6.5665, -6.5542, -6.5149, -6.6042, -6.6466, -6.6365, -6.5253, -6.6152, -6.5669, -6.6088, -6.6974, -6.7272, -6.7276, -6.7444, -6.9176, -7.589, -7.7127, -7.8922, -7.9103, -7.3612, -7.4095, -7.5392, -7.768, -7.5636, -7.9325, -7.2603, -7.3529, -7.6733, -8.2014, -7.8327, -8.3552, -7.4763, -7.3091, -7.7136, -7.1565, -8.3173, -8.2572, -7.7362, -7.9239, -7.5209, -7.7222, -8.1485, -8.3647, -7.7978, -7.3047, -7.6045, -7.0116, -5.2564, -7.4165, -6.9565, -7.0533, -6.5516, -6.1158, -6.3108, -6.372, -6.2641, -6.6283, -6.8812, -6.4662, -6.0625, -6.874, -6.4474, -6.3626, -6.2491, -6.479, -6.5095, -6.8381, -6.759, -6.6768, -6.472, -6.8027, -6.5307, -6.4636, -6.6824, -6.678, -6.6686, -6.5775, -6.77, -6.6101, -6.7338, -6.7981, -6.8489], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6121, 0.5989, 0.5908, 0.5805, 0.5729, 0.5707, 0.5665, 0.5621, 0.5592, 0.5538, 0.5524, 0.5455, 0.5437, 0.5301, 0.5281, 0.5238, 0.5223, 0.5177, 0.5168, 0.5145, 0.5127, 0.5058, 0.4962, 0.4942, 0.493, 0.4922, 0.4915, 0.4911, 0.4823, 0.4818, 0.4734, 0.478, 0.4683, 0.4629, 0.4627, 0.4417, 0.3982, 0.4302, 0.3494, 0.3755, 0.3743, 0.4091, 0.406, 0.413, 0.3274, 0.3557, 0.4215, 0.3526, 0.3966, 0.2489, 0.3597, 0.406, 0.3646, 0.396, 0.3009, 0.3456, 0.352, 0.248, 0.2164, 0.2611, 0.3384, 0.3358, 0.3055, 0.1341, 0.2117, 0.3356, 0.1945, 0.1537, -0.1228, 0.2031, -0.0814, -0.2303, 1.418, 1.3674, 1.3052, 1.2708, 1.2669, 1.2619, 1.2596, 1.2573, 1.2084, 1.2008, 1.1916, 1.1827, 1.1557, 1.1533, 1.1394, 1.131, 1.1296, 1.1274, 1.125, 1.113, 1.1079, 1.0777, 1.0767, 1.0759, 1.0616, 1.0562, 1.054, 1.0519, 1.0437, 1.0383, 1.0347, 1.0256, 1.0255, 1.0157, 0.9505, 1.0316, 0.8878, 0.6561, 0.771, 0.6766, 0.9278, 0.7005, 0.5951, 0.607, 0.8295, 0.7272, 0.6024, 0.4287, 0.8678, 0.3937, 0.7222, 0.5291, 0.3873, 0.272, 0.027, 0.3243, 0.1084, 0.3787, 0.4048, 0.3956, 0.5387, -0.0294, 0.3781, 0.0495, 0.3006, -0.0238, -0.0482, 0.3242, 0.1335, -0.2419, -0.3164, -0.0303, 1.8379, 1.7863, 1.727, 1.7227, 1.7094, 1.701, 1.6997, 1.6868, 1.6828, 1.6719, 1.6461, 1.6286, 1.6005, 1.5913, 1.5861, 1.5616, 1.5495, 1.5395, 1.534, 1.5309, 1.5267, 1.5205, 1.5183, 1.5155, 1.5153, 1.5087, 1.4956, 1.4886, 1.4578, 1.454, 1.4407, 1.3031, 1.3427, 1.2468, 1.4428, 1.2163, 0.9828, 1.2487, 1.2096, 0.7341, 1.0488, 0.8731, 0.788, 0.9194, 0.8042, 0.1715, 0.877, -0.0569, 0.4747, 0.4477, 0.2577, 0.3565, 0.3745, 0.6031, 0.3833, 1.8977, 1.8484, 1.7792, 1.7697, 1.7511, 1.6791, 1.6719, 1.6119, 1.576, 1.574, 1.5652, 1.5347, 1.526, 1.5115, 1.5065, 1.4974, 1.4891, 1.4736, 1.4714, 1.4657, 1.457, 1.4439, 1.4438, 1.4287, 1.4263, 1.4222, 1.4206, 1.4054, 1.4018, 1.3999, 1.3849, 1.3853, 1.3791, 1.3533, 1.0978, 1.209, 1.3784, 1.3044, 0.6846, 0.9841, 0.8998, 1.0083, 0.828, 0.5537, 0.8695, 0.6455, 1.1327, 0.8356, 0.5292, 0.2051, 0.6089, 0.233, 0.5503, 0.2365, 0.5471, 0.6084, 0.3041, 0.3904, 0.4653, 0.3627, 0.3863, 0.217, 0.323, 0.2496, 0.3233, -0.4705, -0.4704, 0.2196, -0.2836, 2.2487, 1.8332, 1.8193, 1.8043, 1.7663, 1.7222, 1.6376, 1.6362, 1.624, 1.6068, 1.6024, 1.5522, 1.5302, 1.5174, 1.4941, 1.4537, 1.4396, 1.4309, 1.4266, 1.3991, 1.3937, 1.3808, 1.3668, 1.3611, 1.3597, 1.3579, 1.3555, 1.3416, 1.3399, 1.3376, 1.3349, 1.3304, 1.2629, 1.2081, 1.1587, 1.1406, 1.3022, 1.0158, 0.778, 0.9887, 0.8294, 0.9781, 0.3855, 0.8463, 0.9797, 0.467, 0.4003, 0.2266, 0.8339, 0.5843, 0.2831, 0.7394, 0.7319, 0.0426, 0.7652, 0.6936, 0.3276, 0.3248, 0.3847, 0.543, 0.4542, 0.0924, -0.1426, -0.2801, -0.1577, 0.2286, -0.0588, 0.2878, -0.286, -0.3799, 2.2465, 2.1386, 2.0933, 2.0485, 1.8789, 1.8703, 1.8442, 1.762, 1.7222, 1.7176, 1.7017, 1.6657, 1.6608, 1.6602, 1.6091, 1.5841, 1.5727, 1.5614, 1.5507, 1.5467, 1.5357, 1.4945, 1.4892, 1.4768, 1.4765, 1.4739, 1.4539, 1.4483, 1.4423, 1.4222, 1.4198, 1.3629, 1.3319, 1.2676, 1.0071, 1.3015, 1.1879, 1.2795, 0.9593, 1.0297, 0.8149, 0.9998, 0.3633, 0.9376, 0.3656, 0.3665, 0.2611, 0.4381, 0.9875, 1.0703, 0.1128, 0.3509, 0.4122, 0.218, 0.0269, 0.2605, -0.2765, 0.4082, 0.2121, -0.0254, 0.0073, 0.0737, -0.3857, -0.2584, 0.2445, 0.1832, 0.1912, 0.2647, -0.4615, 2.3221, 2.2303, 2.1294, 2.0904, 2.0419, 2.0089, 1.9681, 1.9412, 1.8809, 1.838, 1.8319, 1.8119, 1.7932, 1.7654, 1.7453, 1.7124, 1.6638, 1.6513, 1.6512, 1.6326, 1.589, 1.5885, 1.5846, 1.5491, 1.5364, 1.5343, 1.5269, 1.5162, 1.5148, 1.5044, 1.3937, 1.4002, 1.2784, 1.403, 1.4788, 1.1755, 1.167, 0.9269, 1.0184, 1.1542, 0.8678, 0.7882, 0.3446, 0.8382, 0.4678, 0.9516, 0.44, 0.0564, 0.4622, 0.3741, 0.5303, 0.8384, -0.1309, 0.4469, -0.334, 0.3999, -0.0721, -0.1335, 0.4565, 0.4743, -0.4196, -0.0688, 0.0928, -0.3009, 2.5394, 2.3415, 2.0468, 2.0107, 2.006, 1.9579, 1.9144, 1.9125, 1.9054, 1.8818, 1.8506, 1.8318, 1.7883, 1.7646, 1.7418, 1.7146, 1.6976, 1.6706, 1.6633, 1.6472, 1.6401, 1.6012, 1.6002, 1.5979, 1.5961, 1.5938, 1.5732, 1.5401, 1.5389, 1.5139, 1.4757, 1.5002, 1.512, 1.4108, 1.3096, 1.3941, 0.8382, 1.0611, 1.3005, 1.2313, 0.695, 0.9848, 0.9704, 0.7033, 0.9763, 0.479, 0.7222, 0.5921, 0.3204, 0.6312, 0.5876, 0.188, 0.4919, 0.5136, 0.6431, 0.4163, 0.9154, 0.9616, 0.0767, 0.2599, 0.4079, 0.3395, 0.0449, -0.4287, -0.7012, -0.6995, -0.2787, 2.6309, 2.1236, 2.1069, 2.1039, 2.0878, 2.0853, 2.0462, 1.9554, 1.9484, 1.9282, 1.9214, 1.8969, 1.8715, 1.8429, 1.833, 1.8216, 1.8182, 1.7941, 1.7766, 1.7551, 1.7529, 1.747, 1.7062, 1.6819, 1.6765, 1.6674, 1.6639, 1.6328, 1.63, 1.6255, 1.566, 1.6095, 1.2439, 1.4212, 1.5399, 1.3169, 1.3666, 1.2164, 1.0144, 0.7952, 0.2824, 0.621, 0.7563, 0.3253, 0.4979, -0.0732, 0.3903, 0.0043, 0.7608, 0.3903, 0.0813, 0.5022, 0.4172, 0.2716, 0.4134, 0.3914, 0.3346, -0.07, 0.2165, -0.2337, -0.4375, -0.3437, -0.3715, -0.5052, -0.1797, 2.4117, 2.2826, 2.1839, 2.147, 2.0721, 2.045, 2.005, 1.9722, 1.9635, 1.9187, 1.8955, 1.8874, 1.8745, 1.8649, 1.859, 1.841, 1.7898, 1.7688, 1.7679, 1.7607, 1.7332, 1.6863, 1.6678, 1.6595, 1.6218, 1.6117, 1.5973, 1.5967, 1.5814, 1.5785, 1.5631, 1.561, 1.5092, 1.1717, 1.5122, 1.3888, 1.3873, 1.1967, 0.8481, 0.8246, 0.8556, 0.6506, 0.8996, 1.0033, 0.5307, 0.0768, 0.9472, 0.4533, 0.2778, 0.1065, 0.3471, 0.3551, 0.8378, 0.621, 0.3948, -0.1131, 0.5782, -0.0927, -0.2923, 0.1796, 0.1336, -0.0292, -0.4303, 0.2476, -0.7234, -0.5113, -0.0116, 0.2197]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"Freq\": [0.22188875859615179, 0.11834067125128095, 0.0739629195320506, 0.06656662757884553, 0.11094437929807589, 0.3254368459410226, 0.05177404367243542, 0.022188875859615178, 0.014792583906410119, 0.007396291953205059, 0.3896933456785042, 0.351533463163992, 0.10118150666726743, 0.07458522491472856, 0.03006536198113089, 0.016189041066762788, 0.0219708414477495, 0.008094520533381394, 0.004047260266690697, 0.002312720152394684, 0.29981869338207534, 0.12857896203748703, 0.3827536155315449, 0.034904265796719215, 0.021181221124504823, 0.035500919912902454, 0.03341263050626113, 0.04982061870130008, 0.008353157626565282, 0.005668214103740727, 0.5554017983708058, 0.12432711808966738, 0.07585434288208874, 0.06031345312088031, 0.05476313534902016, 0.04958283876195069, 0.038482203218230385, 0.028121610044091434, 0.011840677913301656, 0.0018501059239533837, 0.2833373240029069, 0.10231625588993862, 0.1574096244460594, 0.04722288733381782, 0.25185539911369503, 0.05509336855612079, 0.04722288733381782, 0.03935240611151485, 0.01574096244460594, 0.00787048122230297, 0.7127297554005612, 0.05325265684113599, 0.040414962781219275, 0.1259995898473307, 0.026626328420567995, 0.019018806014691424, 0.010460343308080284, 0.006181111954774713, 0.0038037612029382852, 0.0009509403007345713, 0.5055773696782597, 0.11243325894170429, 0.216676015576397, 0.017497891292251995, 0.040952511535057856, 0.04318628489151556, 0.017497891292251995, 0.025688393599263566, 0.016008709054613525, 0.005212137831734636, 0.2562635561877756, 0.5011376209894278, 0.06833694831674016, 0.03986321985143176, 0.03416847415837008, 0.03416847415837008, 0.03416847415837008, 0.011389491386123359, 0.011389491386123359, 0.005694745693061679, 0.18478970124149072, 0.19262926432446306, 0.4756001603669882, 0.0294916896930864, 0.020158876499071714, 0.017545688804747602, 0.028745064637565224, 0.03285150244293168, 0.011946000888338793, 0.006346312971929984, 0.3161438140749492, 0.12467643371969826, 0.12467643371969826, 0.28497470564502464, 0.026716378654221058, 0.031169108429924566, 0.048980027532738606, 0.031169108429924566, 0.00890545955140702, 0.00445272977570351, 0.31788707155207874, 0.11479255361602843, 0.14128314291203498, 0.07064157145601749, 0.061811375024015305, 0.09713216075202405, 0.061811375024015305, 0.035320785728008744, 0.08830196432002187, 0.008830196432002186, 0.8647504618284516, 0.0402930322715766, 0.017047052114897793, 0.013947588094007285, 0.007748660052226269, 0.03719356825068609, 0.009298392062671523, 0.0061989280417810155, 0.0030994640208905078, 0.0015497320104452539, 0.24065465445677248, 0.5993945120320855, 0.026905489318148474, 0.019431742285329453, 0.022421241098457063, 0.05082147982316934, 0.011957995252510433, 0.011957995252510433, 0.013452744659074237, 0.0014947494065638042, 0.2756632002814228, 0.19498128800393322, 0.09076715131217582, 0.10085239034686201, 0.22523700510799183, 0.06387318055301261, 0.023532224414267805, 0.010085239034686201, 0.006723492689790801, 0.0033617463448954005, 0.3253642030613398, 0.1682918291696585, 0.05609727638988617, 0.0953653698628065, 0.05048754875089755, 0.2243891055595447, 0.02243891055595447, 0.028048638194943087, 0.02243891055595447, 0.005609727638988617, 0.4243723726761311, 0.1027776840075005, 0.242024868791856, 0.043100319099919564, 0.019892454969193642, 0.023207864130725918, 0.029838682453790465, 0.1027776840075005, 0.003315409161532274, 0.003315409161532274, 0.4213931767641238, 0.13266081490722414, 0.08583935082232151, 0.07023219612735396, 0.05462504143238642, 0.03901788673741887, 0.07023219612735396, 0.031214309389935094, 0.09364292816980528, 0.0078035773474837734, 0.24157026158906023, 0.17715152516531082, 0.08052342052968674, 0.08052342052968674, 0.14494215695343612, 0.08857576258265541, 0.06441873642374939, 0.11273278874156144, 0.016104684105937347, 0.008052342052968673, 0.3482053384833165, 0.2053518662850328, 0.10714010414871276, 0.07142673609914184, 0.07142673609914184, 0.03571336804957092, 0.08035507811153457, 0.02678502603717819, 0.00892834201239273, 0.03571336804957092, 0.675563135803707, 0.06836745285149008, 0.05832477616144069, 0.056779748978356165, 0.06566365528109216, 0.024720434929352345, 0.02742423249975026, 0.011587703873133912, 0.00965641989427826, 0.0023175407746267823, 0.07374924892562328, 0.17562321142457746, 0.5687442078162473, 0.031249681748145457, 0.06749931257599419, 0.033749656287997094, 0.016874828143998547, 0.016874828143998547, 0.006874929984592, 0.008124917254517819, 0.3893133957932195, 0.0913694704412658, 0.11917757014078148, 0.03972585671359383, 0.23438255461020358, 0.03178068537087506, 0.05958878507039074, 0.011917757014078148, 0.019862928356796913, 0.003972585671359383, 0.22414765561313102, 0.1297696953549706, 0.18875592051632087, 0.04129035761294519, 0.22414765561313102, 0.029493112580675135, 0.12387107283883557, 0.017695867548405082, 0.011797245032270054, 0.005898622516135027, 0.5189397704457186, 0.09609995748994789, 0.07384523049227575, 0.020231569997883767, 0.10722732098878396, 0.03843998299597915, 0.11531994898793746, 0.018208412998095388, 0.009104206499047694, 0.0020231569997883766, 0.5686208115767372, 0.054154363007308304, 0.045822922544645484, 0.029160041619319853, 0.045822922544645484, 0.03124290173498556, 0.06456866358563682, 0.14580020809659927, 0.014580020809659927, 0.0041657202313314075, 0.22405188383389824, 0.04716881764924173, 0.300701212513916, 0.30954536582314884, 0.05601297095847456, 0.020636357721543257, 0.023584408824620866, 0.011792204412310433, 0.0058961022061552164, 0.0029480511030776082, 0.2634073690529391, 0.21307475076256857, 0.20971924287654387, 0.03858834068928407, 0.010066523658074105, 0.2315300441357044, 0.016777539430123507, 0.005033261829037052, 0.010066523658074105, 0.005033261829037052, 0.20053782055044747, 0.13160294473623116, 0.44494328934630534, 0.0376008413532089, 0.04073424479930964, 0.053267858583712614, 0.025067227568805934, 0.04386764824541039, 0.012533613784402967, 0.009400210338302226, 0.7779804223337156, 0.048042615721803156, 0.04261844943063183, 0.03796916403819926, 0.01782226067099149, 0.036419402240721745, 0.012398094379820169, 0.01472273707603645, 0.010848332582342647, 0.001549761797477521, 0.2598093473556969, 0.18403162104361862, 0.07577772631207826, 0.03247616841946211, 0.07577772631207826, 0.2652220420922739, 0.03247616841946211, 0.0595396421023472, 0.016238084209731055, 0.005412694736577018, 0.27655636158970853, 0.17894823396981138, 0.26028834031972564, 0.07320609571492284, 0.056938074444939986, 0.04880406380994856, 0.056938074444939986, 0.016268021269982853, 0.016268021269982853, 0.02440203190497428, 0.30310773121093204, 0.4675847946587246, 0.03524508502452698, 0.04699344669936931, 0.018797378679747723, 0.030545740354590047, 0.07753918705395935, 0.014098034009810792, 0.0023496723349684654, 0.004699344669936931, 0.19883292659929735, 0.17544081758761532, 0.2573131991285025, 0.040936190770443574, 0.029240136264602555, 0.046784218023364084, 0.21052898110513837, 0.023392109011682042, 0.011696054505841021, 0.0058480272529205105, 0.37471709064405007, 0.16922707319408714, 0.12692030489556536, 0.09065736063968954, 0.030219120213229846, 0.06648206446910566, 0.03626294425587581, 0.030219120213229846, 0.07252588851175162, 0.006043824042645969, 0.21313686270785692, 0.18268873946387737, 0.16238999063455764, 0.14716592901256786, 0.07104562090261897, 0.0761203081099489, 0.08626968252460875, 0.025373436036649634, 0.01522406162198978, 0.025373436036649634, 0.07832740618070598, 0.14634857470605592, 0.5845697998117951, 0.027208467410139974, 0.03751470506549602, 0.04163720012763844, 0.025559469385283005, 0.04040045160899572, 0.00824499012428484, 0.009893988149141808, 0.5573291966267498, 0.16137693292674368, 0.1344807774389531, 0.027577070816595443, 0.035067139433448524, 0.021108375192949596, 0.044940411701118496, 0.00817098394565791, 0.006809153288048257, 0.0030641189796217156, 0.6416753837061085, 0.1405047822942686, 0.05752951715985801, 0.04397689052123761, 0.03346669027087894, 0.031807184968190724, 0.023233074237634967, 0.016041884592652714, 0.009127279164785165, 0.002212673736917616, 0.1307821912467264, 0.17867426128073888, 0.5157607542124422, 0.04052405925954902, 0.016578024242542785, 0.0313140457914697, 0.025788037710622106, 0.03315604848508557, 0.025788037710622106, 0.0018420026936158647, 0.2674189358091969, 0.09131378295923796, 0.14349308750737394, 0.03913447841110198, 0.05217930454813598, 0.05217930454813598, 0.2348068704666119, 0.032612065342584984, 0.08479136989072096, 0.006522413068516997, 0.2872759786262702, 0.07677202877081359, 0.08915461405642867, 0.08420157994218264, 0.049530341142460375, 0.01981213645698415, 0.3739540756255758, 0.0074295511713690565, 0.004953034114246037, 0.0074295511713690565, 0.7586047700299879, 0.1365488586053978, 0.03593391015931521, 0.007985313368736714, 0.012776501389978743, 0.0071867820318630435, 0.027150065453704828, 0.0023955940106210145, 0.007985313368736714, 0.0023955940106210145, 0.28465374607375943, 0.2696719699646142, 0.14232687303687971, 0.026218108191004157, 0.01872722013643154, 0.21723575358260586, 0.01872722013643154, 0.007490888054572616, 0.007490888054572616, 0.003745444027286308, 0.3193372159095959, 0.23530110645970226, 0.10924694228486176, 0.058825276614925565, 0.050421665669936194, 0.06722888755991493, 0.03361444377995747, 0.10924694228486176, 0.008403610944989367, 0.008403610944989367, 0.2550480148227666, 0.14574172275586664, 0.05920757486957082, 0.050098717197329154, 0.050098717197329154, 0.09108857672241664, 0.2732657301672499, 0.05920757486957082, 0.009108857672241665, 0.004554428836120832, 0.42250223470051584, 0.09438879711394503, 0.07191527399157717, 0.0494417508692093, 0.07191527399157717, 0.0988835017384186, 0.04045234162026216, 0.0494417508692093, 0.08989409248947146, 0.004494704624473573, 0.7544674530255515, 0.051753394419759166, 0.030728577936732004, 0.016981582543983475, 0.046901513692906745, 0.04043233939043685, 0.03153722472454074, 0.006469174302469896, 0.01859887611960095, 0.0024259403634262107, 0.4179413436759813, 0.14830176711083207, 0.06740989414128731, 0.14156077769670336, 0.03370494707064366, 0.04718692589890112, 0.04718692589890112, 0.020222968242386192, 0.07415088355541603, 0.006740989414128731, 0.6759498839280068, 0.11787129509798577, 0.05212981109984629, 0.04286228912654028, 0.04141423881821122, 0.02316880493326502, 0.018824654008277826, 0.02258958480993339, 0.0037649308016555654, 0.0014480503083290637, 0.25226831440908076, 0.5744933882761419, 0.025438821621083775, 0.04663783963865359, 0.03603833062986868, 0.012719410810541888, 0.03179852702635472, 0.008479607207027924, 0.006359705405270944, 0.004239803603513962, 0.21483127701729127, 0.08010657787085436, 0.08010657787085436, 0.1274422829763592, 0.21119006893225242, 0.06918295361573785, 0.09103020212597088, 0.10195382638108738, 0.01456483234015534, 0.00728241617007767, 0.7970026703654811, 0.0582604291202837, 0.025634588812924828, 0.025634588812924828, 0.04660834329622696, 0.018643337318490785, 0.013982502988868089, 0.009321668659245393, 0.004660834329622696, 0.002330417164811348, 0.43089635332432746, 0.09444303634505807, 0.07673496703035969, 0.07083227725879356, 0.15346993406071938, 0.06492958748722742, 0.02361075908626452, 0.01770806931469839, 0.059026897715661296, 0.00590268977156613, 0.31798935911176807, 0.07949733977794202, 0.05299822651862801, 0.07419751712607922, 0.3656877629785333, 0.03179893591117681, 0.04769840386676521, 0.010599645303725602, 0.005299822651862801, 0.005299822651862801, 0.4114889768091403, 0.05667213453060017, 0.09609622811710462, 0.03942409358650446, 0.04188809943566099, 0.09609622811710462, 0.18233643283758313, 0.059136140379756695, 0.009856023396626116, 0.007392017547469587, 0.13149718284446577, 0.6372555784001033, 0.053947562192601335, 0.03708894900741342, 0.040460671644451, 0.05057583955556375, 0.0202303358222255, 0.006743445274075167, 0.006743445274075167, 0.013486890548150334, 0.28892463791157663, 0.10902816524965156, 0.07086830741227351, 0.1253823900370993, 0.0763197156747561, 0.21805633049930312, 0.05451408262482578, 0.02725704131241289, 0.02180563304993031, 0.005451408262482578, 0.5588938937643354, 0.10645597976463532, 0.06653498735289708, 0.03992099241173824, 0.06653498735289708, 0.02661399494115883, 0.05322798988231766, 0.03992099241173824, 0.0066534987352897075, 0.01996049620586912, 0.1361955189507067, 0.22542706584944558, 0.4391131386858992, 0.058704965064959785, 0.044615773449369435, 0.03757117764157426, 0.023481986025983913, 0.01878558882078713, 0.007044595807795174, 0.007044595807795174, 0.13428038547849844, 0.06714019273924922, 0.16113646257419814, 0.11078131801976122, 0.016785048184812305, 0.4699813491747446, 0.013428038547849845, 0.0067140192739249226, 0.0067140192739249226, 0.010071028910887384, 0.8305766575853366, 0.021650102448906878, 0.021650102448906878, 0.010825051224453439, 0.03739563150265734, 0.05904573395156421, 0.010825051224453439, 0.0029522866975782106, 0.0009840955658594035, 0.001968191131718807, 0.2854559787313804, 0.11572539678299207, 0.08486529097419418, 0.06172021161759576, 0.0540051851653963, 0.2391658200181836, 0.0540051851653963, 0.01543005290439894, 0.08486529097419418, 0.00771502645219947, 0.12547726616275484, 0.06871374099388955, 0.4735273020665867, 0.028381762584432643, 0.11950215825024271, 0.0791701798407858, 0.08663906473142596, 0.0074688848906401695, 0.008962661868768203, 0.004481330934384102, 0.40804494961386356, 0.14716375231975407, 0.06689261469079731, 0.04682483028355811, 0.040135568814478384, 0.060203353221717576, 0.09364966056711622, 0.12040670644343515, 0.013378522938159462, 0.006689261469079731, 0.3046889133226304, 0.1426203424063376, 0.15720651378880396, 0.022689599928280985, 0.06644811407568002, 0.038896457019910256, 0.18151679942624788, 0.05834468552986539, 0.019448228509955128, 0.006482742836651709, 0.6852063723073049, 0.04315140476122127, 0.08108670565020701, 0.07302545421129754, 0.015174120355594295, 0.027977284405626978, 0.02513213683895305, 0.04457397854455824, 0.0018967650444492868, 0.0033193388277862517, 0.15213150241128465, 0.2260239464396229, 0.12170520192902771, 0.36511560578708313, 0.043466143546081325, 0.026079686127648796, 0.026079686127648796, 0.008693228709216266, 0.008693228709216266, 0.021733071773040662, 0.254119959651179, 0.46339522054038523, 0.05231881522230156, 0.07100410637312354, 0.022422349380986382, 0.02615940761115078, 0.06726704814295914, 0.02615940761115078, 0.007474116460328794, 0.007474116460328794, 0.2341628836285749, 0.14191689916883327, 0.12772520925194994, 0.06386260462597497, 0.07095844958441663, 0.06386260462597497, 0.11353351933506661, 0.16320443404415827, 0.007095844958441663, 0.007095844958441663, 0.6840029620825446, 0.14400062359632518, 0.03638313628098642, 0.017234117185730407, 0.02259584253240209, 0.02910650902478913, 0.035234195135271054, 0.019914979859066248, 0.008808548783817764, 0.0030638430552409612, 0.25860220832418107, 0.47018583331669284, 0.036570009257965, 0.03395786573953893, 0.07052787499750393, 0.028733578702686786, 0.07314001851593, 0.013060717592130356, 0.01567286111055643, 0.0026121435184260715, 0.7057183785853303, 0.024947216646116366, 0.07915943743479231, 0.06668582911173414, 0.06188828744901945, 0.022548445814759024, 0.0167913958195014, 0.01007483749170084, 0.011514099990515246, 0.0009595083325429372, 0.5820508867836325, 0.142923527359682, 0.051783886724522464, 0.06283111589242059, 0.05868840495445879, 0.03693917253015935, 0.02968942838872621, 0.016570843751847187, 0.014154262371369472, 0.004142710937961797, 0.502334092840339, 0.18916018183519015, 0.05415789438434905, 0.0631842101150739, 0.051018306304096935, 0.04513157865362421, 0.04984096077400239, 0.019229976991544228, 0.01766018295141817, 0.008241418710661813, 0.7665616992127672, 0.06938222679006067, 0.06938222679006067, 0.015666954436465316, 0.033572045220997104, 0.015666954436465316, 0.01342881808839884, 0.007833477218232658, 0.005595340870166184, 0.0011190681740332368, 0.609316180734016, 0.16693017025178458, 0.024990387136095592, 0.04282060717139975, 0.07384799794149596, 0.033835299437073245, 0.03186976337018932, 0.010670052934512723, 0.0036502812670701425, 0.0021059315002327746, 0.21299294111119177, 0.07691411762348592, 0.1893270587655038, 0.05916470586421994, 0.34315529401247563, 0.023665882345687974, 0.04733176469137595, 0.01774941175926598, 0.011832941172843987, 0.0059164705864219935, 0.3706353366242393, 0.07942185784805128, 0.15884371569610256, 0.058242695755237606, 0.03176874313922051, 0.15354892517289914, 0.058242695755237606, 0.03176874313922051, 0.06353748627844102, 0.005294790523203419, 0.44789601951716956, 0.20212256812957016, 0.03700835754485088, 0.034161560810631576, 0.056935934684385965, 0.025621170607973684, 0.16036954936102046, 0.01897864489479532, 0.00948932244739766, 0.008540390202657894, 0.4605180372079489, 0.06140240496105986, 0.08528111800147202, 0.08186987328141314, 0.054579915520942095, 0.10574858632182531, 0.06481364968111875, 0.04093493664070657, 0.017056223600294407, 0.023878713040412166, 0.47868065461796544, 0.33471654796594574, 0.050387437328206885, 0.043909052528866004, 0.02591353919736354, 0.02591353919736354, 0.020154974931282755, 0.010797307998901476, 0.007198205332600984, 0.0021594615997802954, 0.6646886307442977, 0.1279387931706679, 0.023723749727011263, 0.058462097541563465, 0.042363838798234396, 0.025841941666922982, 0.030078325546746422, 0.019487365847187823, 0.005930937431752816, 0.0016945535519293758, 0.40862945364249553, 0.09475465591710042, 0.06514382594300654, 0.035532995968912656, 0.11844331989637552, 0.035532995968912656, 0.20727580981865715, 0.011844331989637552, 0.011844331989637552, 0.005922165994818776, 0.34462304884132966, 0.2067738293047978, 0.12923364331549864, 0.060309033547232695, 0.060309033547232695, 0.06892460976826593, 0.060309033547232695, 0.03446230488413297, 0.017231152442066484, 0.025846728663099724, 0.2773305168180498, 0.22355451632701523, 0.24967428799408917, 0.06222651485391145, 0.050703086177261186, 0.04916662902037448, 0.03380205745150746, 0.03380205745150746, 0.013828114411980324, 0.00614582862754681, 0.23745209109356535, 0.1912808511587054, 0.1846849597394397, 0.03957534851559422, 0.03957534851559422, 0.05936302277339134, 0.03957534851559422, 0.1451096112238455, 0.05276713135412563, 0.006595891419265704, 0.17012247045077006, 0.3103988934540366, 0.04178446642650493, 0.029846047447503517, 0.21787614636677569, 0.17012247045077006, 0.04178446642650493, 0.0059692094895007035, 0.011938418979001407, 0.0029846047447503517, 0.4473361380397439, 0.10251453163410798, 0.04659751437913999, 0.07921577444453799, 0.07455602300662399, 0.05125726581705399, 0.027958508627483995, 0.15377179745116198, 0.013979254313741998, 0.0046597514379139995, 0.2662905339141932, 0.09890791259670034, 0.08369131065874644, 0.06847470872079255, 0.0760830096897695, 0.03804150484488475, 0.31954864069703187, 0.030433203875907797, 0.007608300968976949, 0.007608300968976949, 0.40488193460405464, 0.1096555239552648, 0.1096555239552648, 0.10122048365101366, 0.1096555239552648, 0.042175201521255694, 0.042175201521255694, 0.025305120912753415, 0.016870080608502275, 0.03374016121700455, 0.2920334975516013, 0.17984989788238862, 0.2920334975516013, 0.021368304698897656, 0.0623242220384515, 0.02671038087362207, 0.033833149106587954, 0.08013114262086621, 0.007122768232965885, 0.005342076174724414, 0.5273227317889402, 0.13400610675824554, 0.0208840685857006, 0.05917152765948504, 0.1583708534415629, 0.027845424780934137, 0.03828745907378444, 0.0104420342928503, 0.022624407634508986, 0.0017403390488083836, 0.37721512700207105, 0.2495319578978602, 0.12341958349264669, 0.08639370844485268, 0.05026543036791428, 0.04847023642620306, 0.04151385990207206, 0.010771163650267347, 0.007405175009558801, 0.004712384096991964, 0.833068458350488, 0.049272395126973005, 0.012774324662548558, 0.020073938755433448, 0.026461101086707725, 0.015511679947380392, 0.017336583470601612, 0.011861872900937947, 0.013686776424159169, 0.0009124517616106113, 0.6780605773039083, 0.09743247052301134, 0.02380029814302567, 0.05305483127716139, 0.07809472828180297, 0.023552378370702485, 0.026527415638580694, 0.008429272258988258, 0.010164710665250546, 0.0009916790892927363, 0.8423982520135022, 0.02301634568342902, 0.016571768892068895, 0.0073652306186972865, 0.02301634568342902, 0.07089034470496137, 0.008285884446034448, 0.0027619614820114822, 0.0055239229640229644, 0.0009206538273371608, 0.19729960641025954, 0.45344295508322807, 0.04153675924426517, 0.05884374226270899, 0.12374492858187332, 0.05884374226270899, 0.04586350499887612, 0.012114888112910675, 0.005192094905533146, 0.003461396603688764, 0.48956558569004804, 0.04351694095022649, 0.09791311713800961, 0.2523982575113137, 0.010879235237556623, 0.03263770571266987, 0.021758470475113246, 0.04134109390271517, 0.004351694095022649, 0.004351694095022649, 0.5769268193883044, 0.12724441516508714, 0.06506452463101434, 0.08525696330960499, 0.043590026353783, 0.049679809447326216, 0.02467964727383302, 0.01826934928062964, 0.006410297993203382, 0.002564119197281353, 0.4128899315659444, 0.1323124553427231, 0.10509925530769494, 0.06662542077541375, 0.07319412423214469, 0.04035060694849002, 0.12386697946978333, 0.03096674486744583, 0.008445475872939772, 0.006568703456730934, 0.36994464797958904, 0.09878103165947141, 0.06585402110631428, 0.0755384359748899, 0.0910334997646109, 0.07166467002745966, 0.10652856355433192, 0.09684414868575629, 0.021305712710866384, 0.0019368829737151257, 0.21359033995849, 0.4592192309107535, 0.0533975849896225, 0.0961156529813205, 0.02669879249481125, 0.0533975849896225, 0.0533975849896225, 0.01601927549688675, 0.0106795169979245, 0.01601927549688675, 0.2100215724103044, 0.1575161793077283, 0.1050107862051522, 0.24940061723723644, 0.03281587068911006, 0.08532126379168616, 0.09844761206733017, 0.02625269655128805, 0.006563174137822012, 0.03281587068911006, 0.7758365024809561, 0.04468168338895559, 0.03249576973742225, 0.012185913651533343, 0.0649915394748445, 0.03249576973742225, 0.022340841694477795, 0.006092956825766671, 0.004061971217177781, 0.0020309856085888906, 0.14541170970470751, 0.08202711829496322, 0.1491402150817513, 0.09694113980313834, 0.30200893554054636, 0.05965608603270052, 0.08202711829496322, 0.07084160216383187, 0.007457010754087565, 0.0037285053770437825, 0.32321000805171085, 0.11356027309924975, 0.12666338153377857, 0.04804473092660567, 0.2293043976042543, 0.05241243373811527, 0.08080250201292771, 0.015286959840283621, 0.004367702811509606, 0.004367702811509606, 0.307427381971287, 0.10024805933846315, 0.06683203955897543, 0.053465631647180344, 0.3608930136184673, 0.026732815823590172, 0.0467824276912828, 0.02004961186769263, 0.013366407911795086, 0.006683203955897543, 0.23971917149222957, 0.1444882677487411, 0.06567648534033686, 0.04268971547121896, 0.29226035976449904, 0.04925736400525265, 0.08537943094243793, 0.06567648534033686, 0.013135297068067374, 0.0032838242670168434, 0.7750124191711941, 0.050479736114598855, 0.06532671732477499, 0.02672456617831704, 0.029693962420352268, 0.011877584968140906, 0.01781637745221136, 0.005938792484070453, 0.005938792484070453, 0.005938792484070453, 0.35581171130043815, 0.09084554331075016, 0.1589797007938128, 0.264966167989688, 0.07381200393998451, 0.017033539370765655, 0.018926154856406283, 0.015140923885125028, 0.003785230971281257, 0.0018926154856406285, 0.13916935279715376, 0.5034655998249974, 0.24149975926564918, 0.03274573006991853, 0.020466081293699083, 0.0245592975524389, 0.020466081293699083, 0.01227964877621945, 0.004093216258739816, 0.004093216258739816, 0.14023481191139822, 0.35221766712630254, 0.03587402165175303, 0.296775997300866, 0.042396571042980856, 0.04565784573859477, 0.05544166982543651, 0.022828922869297386, 0.006522549391227824, 0.003261274695613912, 0.15248005581889498, 0.07624002790944749, 0.050826685272964994, 0.16772806140078447, 0.2693814319467145, 0.132149381709709, 0.09657070201863349, 0.010165337054592999, 0.0457440167456685, 0.005082668527296499, 0.2279257890974547, 0.5777653723633154, 0.026502998732262174, 0.03445389835194083, 0.08480959594323896, 0.02120239898580974, 0.013251499366131087, 0.007950899619678653, 0.005300599746452435, 0.0026502998732262175, 0.28964588056833085, 0.14138222248043794, 0.24898285197882436, 0.07131669629544216, 0.06756318596410309, 0.056928240025309086, 0.06130733541187132, 0.03941185847906013, 0.016265211435802597, 0.007507020662678121, 0.48734755029120613, 0.17461115438241073, 0.056292551263583165, 0.07922655363022815, 0.05160150532495123, 0.05160150532495123, 0.07036568907947896, 0.018242956428013064, 0.009382091877263861, 0.0010424546530293179, 0.6906951098726568, 0.06739563253221716, 0.059686981752388395, 0.04404943302759291, 0.061448959073492106, 0.030834603119315036, 0.02136397501838256, 0.011012358256898228, 0.011673099752312122, 0.001982224486241681, 0.45047366003038, 0.08639220877294959, 0.10490482493858164, 0.055537848496896164, 0.04936697644168548, 0.030854360276053424, 0.0802213367177389, 0.12958831315942437, 0.01234174411042137, 0.006170872055210685, 0.2754655916641046, 0.1948415160550984, 0.06718672967417186, 0.06718672967417186, 0.04031203780450311, 0.26202824572927025, 0.04031203780450311, 0.026874691869668742, 0.013437345934834371, 0.006718672967417186, 0.43736742274612067, 0.14401122456274704, 0.0533374905787952, 0.03200249434727712, 0.04266999246303616, 0.2400187076045784, 0.0266687452893976, 0.01600124717363856, 0.01066749811575904, 0.00533374905787952, 0.30687197850209746, 0.18763557721664395, 0.049912912166003805, 0.09243131882593297, 0.13494972548586215, 0.1275552199797875, 0.06562623636641242, 0.02957802202429855, 0.005545879129555979, 0.0009243131882593297, 0.4481433618890474, 0.1453662434301822, 0.11380100199962835, 0.10092570615295507, 0.05025518701443442, 0.04444053727722713, 0.045686533649485835, 0.030319245058295145, 0.016613284963449396, 0.0049839854890348185, 0.46218280971624254, 0.06137181571641909, 0.0651601994026178, 0.07879838067293315, 0.16214282176930475, 0.06743322961433702, 0.048491311183343475, 0.03864151359922684, 0.012122827795835869, 0.003788383686198709, 0.4929182773870519, 0.18753602451818735, 0.09552983294872174, 0.09866195861917162, 0.03641096091898001, 0.03680247662778624, 0.03445338237494882, 0.009787892720155915, 0.005481219923287313, 0.003132125670449893, 0.5480028519811626, 0.13164606167707626, 0.05746455073205709, 0.04492683057233555, 0.07522632095832929, 0.031344300399303866, 0.07574872596498435, 0.024553035312788032, 0.007836075099825967, 0.003134430039930387, 0.13074208257090267, 0.1910845822190116, 0.5397301357414187, 0.03352361091561607, 0.02346652764093125, 0.016761805457808036, 0.013409444366246429, 0.040228333098739286, 0.006704722183123214, 0.003352361091561607, 0.32536359985419655, 0.11029274571328697, 0.17646839314125914, 0.055146372856643484, 0.24815867785489568, 0.03308782371398609, 0.027573186428321742, 0.016543911856993044, 0.005514637285664348, 0.005514637285664348, 0.32844423187615857, 0.42031674428907007, 0.04517065193634815, 0.08115405263140514, 0.04440504766624055, 0.02143691956301268, 0.024499336643443063, 0.022202523833120276, 0.006124834160860766, 0.006124834160860766, 0.53243526396654, 0.16132469674674804, 0.1071246998160224, 0.05101176181715353, 0.02741882197672002, 0.039534115408293984, 0.03762117434015073, 0.0133905874770028, 0.024230586863147927, 0.005738823204429772, 0.43606060981971834, 0.07816180742051555, 0.04113779337921871, 0.09050314543428116, 0.2673956569649216, 0.024682676027531224, 0.028796455365453097, 0.016455117351687483, 0.012341338013765612, 0.004113779337921871, 0.2702746573747798, 0.4785190655160036, 0.0398765887930003, 0.04873805296922259, 0.031015124616778012, 0.033230490660833584, 0.07310707945383388, 0.011076830220277861, 0.011076830220277861, 0.002215366044055572, 0.14450815113456167, 0.11330752759414493, 0.4778621815926982, 0.047622004351162366, 0.029558485459342157, 0.05747483283760975, 0.0738962136483554, 0.03941131394578954, 0.013137104648596515, 0.0049264142432236925, 0.6149870294323354, 0.08346549150297057, 0.12665161645973147, 0.047338636971834054, 0.048169139374848687, 0.02449982088893166, 0.02325406728440971, 0.01328803844823412, 0.014949043254263385, 0.00332200961205853, 0.37869961364858423, 0.08149232192437889, 0.10546065190213738, 0.07190498993327549, 0.04314299395996529, 0.23488963378203326, 0.04314299395996529, 0.019174663982206797, 0.014380997986655097, 0.004793665995551699, 0.4602926316987708, 0.2134757577596915, 0.1106739828732457, 0.04723324792079942, 0.06251459283635218, 0.049548603211034686, 0.024079695018446763, 0.009261421160941063, 0.02037512655407034, 0.002778426348282319, 0.3338170083828489, 0.09163604151686049, 0.1309086307383721, 0.07199974690610467, 0.24872639840290703, 0.04581802075843024, 0.03272715768459303, 0.026181726147674424, 0.006545431536918606, 0.006545431536918606, 0.3339122949150386, 0.0816230054236761, 0.04081150271183805, 0.03339122949150386, 0.01855068305083548, 0.2745501091523651, 0.19663724033885607, 0.011130409830501287, 0.007420273220334192, 0.003710136610167096, 0.7386972300155747, 0.058276753753893955, 0.04935148516095524, 0.017850537185877428, 0.06510195914849415, 0.020475616183800577, 0.005250157995846302, 0.0036751105970924116, 0.037801137570093374, 0.0036751105970924116, 0.45592885578929815, 0.24130682752059007, 0.12198765372288914, 0.05413202133953205, 0.03278418193802646, 0.03964598745993897, 0.030115702012838256, 0.015248456715361142, 0.0068618055219125135, 0.002287268507304171, 0.08238141909791839, 0.18793261231712632, 0.5071606113215601, 0.015446516080859698, 0.14931632211497708, 0.018020935427669648, 0.020595354774479598, 0.007723258040429849, 0.0051488386936198996, 0.007723258040429849, 0.5108128137856762, 0.12904744769322346, 0.10718107461187171, 0.06488218897909291, 0.04767586261999644, 0.07061763109879172, 0.04194042050029762, 0.015055535564209403, 0.009678558576991758, 0.0032261861923305866, 0.5629132978379048, 0.1041625509216497, 0.06315081484448448, 0.03738237890219484, 0.060610264822005225, 0.05298861475456745, 0.06496549343196967, 0.043552286099644476, 0.006532842914946671, 0.0039922928924674105, 0.3575491363630272, 0.20305259595925002, 0.043511270562696436, 0.15828012914835948, 0.05864562554102563, 0.09017553174587811, 0.05990682178921973, 0.018287345598814442, 0.0037835887445822987, 0.0063059812409704975, 0.16533171126938248, 0.5070172478927729, 0.1405319545789751, 0.019288699648094623, 0.07715479859237849, 0.024799756690407373, 0.033066342253876495, 0.022044228169250998, 0.005511057042312749, 0.0027555285211563747, 0.21393275010823473, 0.5348318752705868, 0.047065205023811646, 0.055622515028141035, 0.02567193001298817, 0.02567193001298817, 0.055622515028141035, 0.01711462000865878, 0.012835965006494084, 0.00855731000432939, 0.27055814554837343, 0.12939737395791773, 0.22056370561008704, 0.12057482573351425, 0.035290192897613926, 0.12645652454978323, 0.0470535905301519, 0.011763397632537975, 0.014704247040672469, 0.020585945856941457, 0.16388717793236868, 0.06952789366827762, 0.5810545399420345, 0.044696503072464186, 0.029797668714976126, 0.044696503072464186, 0.01986511247665075, 0.014898834357488063, 0.02483139059581344, 0.004966278119162688, 0.6807969746633616, 0.0683843803490796, 0.04908779777532941, 0.0605980400123032, 0.0548429188938163, 0.04028584782940827, 0.032160970956250305, 0.008801949945921135, 0.0030468288274342393, 0.0020312192182894927, 0.4634550956787831, 0.13796776433204866, 0.056353030501822686, 0.061211050372669475, 0.0942455854944276, 0.06023944639850012, 0.07189869408853239, 0.01457405961254035, 0.03011972319925006, 0.010687643715862923, 0.3672494772859183, 0.24088984747304742, 0.04355374474401081, 0.12582192926047567, 0.05968476131586666, 0.08226818451646485, 0.042478343639220414, 0.02742272817215495, 0.006452406628742342, 0.003763903866766366, 0.24109958216819438, 0.18344533425840878, 0.35116678272323965, 0.020091631847349533, 0.07599878133562649, 0.02795357474413848, 0.037562616062436084, 0.04979230501299667, 0.007861942896788947, 0.0052412952645259645, 0.4434540438317167, 0.08119581084242701, 0.1561457900815904, 0.024983326413054466, 0.05933540023100435, 0.01561457900815904, 0.19986661130443573, 0.009368747404895425, 0.0031229158016318082, 0.0031229158016318082, 0.23255025346682878, 0.14728182719565822, 0.16278517742678014, 0.054261725808926714, 0.06201340092448767, 0.054261725808926714, 0.22479857835126782, 0.031006700462243835, 0.015503350231121918, 0.015503350231121918, 0.3982227004219873, 0.12743126413503594, 0.13539571814347567, 0.06371563206751797, 0.047786724050638475, 0.06371563206751797, 0.09557344810127695, 0.03982227004219873, 0.007964454008439746, 0.023893362025319238, 0.35414918821077196, 0.07221263273712053, 0.47015033228848685, 0.017669048435678427, 0.007682194972034099, 0.036874535865763676, 0.017669048435678427, 0.01613260944127161, 0.0038410974860170494, 0.00307287798881364, 0.43497490177692943, 0.10121531368270859, 0.1430398234689518, 0.06273676467936483, 0.04266099998196808, 0.12965598033735398, 0.049352921547767, 0.022585235284571337, 0.004182450978624322, 0.008364901957248644, 0.3025206985600044, 0.19871457650510094, 0.13049912486902152, 0.10973790045804081, 0.0800790084423541, 0.05931778403137341, 0.029658892015686705, 0.03262478121725538, 0.0504201164266674, 0.005931778403137341, 0.208231761365345, 0.08676323390222708, 0.1156843118696361, 0.31234764204801746, 0.04627372474785444, 0.03470529356089083, 0.06941058712178166, 0.1099000962761543, 0.01156843118696361, 0.005784215593481805, 0.4671157518403442, 0.12547122136811834, 0.17989247400971184, 0.03023402924532972, 0.02494307412739702, 0.06046805849065944, 0.03779253655666215, 0.05668880483499323, 0.013605313160398374, 0.003779253655666215, 0.276162175599052, 0.13054939210137004, 0.18578182722118045, 0.07029582651612233, 0.04016904372349847, 0.2159086100138043, 0.030126782792623853, 0.030126782792623853, 0.015063391396311927, 0.005021130465437309, 0.20397671185910143, 0.539405082471846, 0.08007974613727685, 0.07705786892454942, 0.015109386063637143, 0.030218772127274286, 0.016620324670000856, 0.010576570244546, 0.021153140489092, 0.004532815819091143, 0.30973778142217007, 0.10066477896220526, 0.13163855710442227, 0.27876400327995304, 0.054204111748879756, 0.054204111748879756, 0.03871722267777126, 0.023230333606662754, 0.007743444535554251, 0.007743444535554251, 0.42573558524451666, 0.16480087170755484, 0.07782263386190089, 0.09155603983753047, 0.05035582191064175, 0.036622415935012184, 0.03204461394313566, 0.10528944581316003, 0.009155603983753046, 0.009155603983753046, 0.46140657484277253, 0.12549244755339142, 0.2326046881418922, 0.033591412728938105, 0.01964780744522795, 0.0348590132092754, 0.048802618492985554, 0.03295761248876947, 0.004436601681180505, 0.005704202161517792, 0.14595643933999078, 0.4926029827724689, 0.17332327171623907, 0.06385594221124596, 0.03952986898791417, 0.024326073223331798, 0.030407591529164748, 0.012163036611665899, 0.012163036611665899, 0.0030407591529164747, 0.3931116369953548, 0.3026111162482228, 0.11029750966056717, 0.028281412733478763, 0.0480784016469139, 0.028281412733478763, 0.04242211910021815, 0.014140706366739381, 0.008484423820043628, 0.025453271460130888, 0.5718520669379309, 0.11854979602718878, 0.03174723351236581, 0.07313919619304528, 0.08157833421531974, 0.04741991841087551, 0.05184041927968594, 0.014467093752470494, 0.008439138022274455, 0.0016074548613856105, 0.32236787695739344, 0.15598445659228713, 0.10398963772819142, 0.072792746409734, 0.072792746409734, 0.062393782636914856, 0.08319171018255314, 0.11438860150101057, 0.010398963772819143, 0.010398963772819143, 0.1434028700326258, 0.3585071750815645, 0.19598392237792192, 0.03346066967427935, 0.1338426786971174, 0.03824076534203354, 0.023900478338770965, 0.01434028700326258, 0.023900478338770965, 0.03346066967427935, 0.23132916146185303, 0.06014558198008179, 0.14805066333558595, 0.13417091364787476, 0.12029116396016358, 0.023132916146185303, 0.03238608260465942, 0.226702578232616, 0.018506332916948243, 0.004626583229237061, 0.4342277414289364, 0.21802229695176722, 0.025435934644372844, 0.03452019701736314, 0.06904039403472628, 0.054505574237941806, 0.03452019701736314, 0.12354596827266809, 0.0036337049491961203, 0.0018168524745980602, 0.4850863634679375, 0.1526114401921601, 0.12535939730070295, 0.03815286004804003, 0.04360326862633146, 0.06540490293949719, 0.032702451469748595, 0.02180163431316573, 0.0054504085782914324, 0.02180163431316573, 0.8200735827156401, 0.027051038318745075, 0.018508605165457156, 0.04555964348420223, 0.019932344024338477, 0.03416973261315167, 0.019932344024338477, 0.007118694294406598, 0.007118694294406598, 0.0014237388588813197, 0.2545123975688712, 0.22202145319837696, 0.06498188874098838, 0.06137178381093347, 0.052346521485796195, 0.2328517679885417, 0.05776167888087856, 0.027075786975411825, 0.010830314790164731, 0.01805052465027455, 0.18324910828482308, 0.23540462371973425, 0.10572063939509023, 0.27346405390196676, 0.06766120921285775, 0.06343238363705414, 0.0465170813338397, 0.014096085252678699, 0.00563843410107148, 0.004228825575803609, 0.7130417639408803, 0.12376424794046632, 0.03912547192956677, 0.03114068173985927, 0.043517106533905905, 0.012775664303532008, 0.019562735964783386, 0.00678707166125138, 0.008783269208678255, 0.0011977185284561258, 0.17944545494109074, 0.18488319599991165, 0.46220798999977913, 0.03262644635292559, 0.03806418741174652, 0.03262644635292559, 0.04893966952938838, 0.010875482117641862, 0.005437741058820931, 0.005437741058820931, 0.2273683250421659, 0.09852627418493855, 0.07578944168072196, 0.05305260917650537, 0.045473665008433174, 0.14399993919337173, 0.33347354339517665, 0.022736832504216587, 0.007578944168072197, 0.007578944168072197, 0.33960914446884777, 0.09859620323289128, 0.13693917115679344, 0.032865401077630425, 0.043820534770173905, 0.05477566846271738, 0.2574456417747717, 0.016432700538815213, 0.005477566846271738, 0.005477566846271738, 0.3680542087570505, 0.09888023518846134, 0.3616453046244651, 0.034333414995993516, 0.020600048997596113, 0.043946771194871705, 0.020142270130982864, 0.029297847463247803, 0.01785337579791663, 0.005493346399358963, 0.2015291691320431, 0.08564989688111832, 0.48870823514520456, 0.04030583382640862, 0.035267604598107544, 0.0906881261094194, 0.02015291691320431, 0.02015291691320431, 0.010076458456602155, 0.005038229228301078, 0.5704918743468103, 0.07522969771606289, 0.037614848858031444, 0.03134570738169287, 0.1974779565046651, 0.03656999194530835, 0.03134570738169287, 0.010448569127230958, 0.005224284563615479, 0.0020897138254461914, 0.6548769510471061, 0.05539204770111948, 0.06700650931587034, 0.05003152695584985, 0.05807230807375429, 0.026802603726348136, 0.029482864098982948, 0.05360520745269627, 0.0026802603726348135, 0.0026802603726348135, 0.7150050521926512, 0.11322295780080846, 0.034423097060319055, 0.019492597130542116, 0.021151541567183997, 0.03898519426108423, 0.024054694331307292, 0.020736805458023526, 0.010783138838172234, 0.0016589444366418822, 0.13227456745709007, 0.1675477854456474, 0.07936474047425404, 0.0837738927228237, 0.3571413321341432, 0.022045761242848343, 0.017636608994278675, 0.10581965396567204, 0.017636608994278675, 0.017636608994278675, 0.1690361785360567, 0.07117312780465546, 0.11120801219477415, 0.30693411365757667, 0.040034884390118694, 0.12010465317035608, 0.03558656390232773, 0.13344961463372898, 0.004448320487790966, 0.004448320487790966, 0.17799099721266573, 0.23732132961688765, 0.10382808170738834, 0.029665166202110956, 0.029665166202110956, 0.12236881058370769, 0.24844576694267925, 0.018540728876319346, 0.029665166202110956, 0.0037081457752638695, 0.435692727555517, 0.0847180303580172, 0.07866674247530168, 0.06656416670987066, 0.22389765166047404, 0.048410303061724114, 0.03025643941357757, 0.018153863648146543, 0.012102575765431028, 0.006051287882715514, 0.7689237529834776, 0.04805773456146735, 0.024028867280733675, 0.024028867280733675, 0.04150440712126726, 0.04368884960133396, 0.02839775224086707, 0.01092221240033349, 0.006553327440200094, 0.0021844424800666977, 0.32436243488744115, 0.07397739743046904, 0.07966796646358204, 0.30160015875498913, 0.08535853549669505, 0.06259625936424303, 0.03983398323179102, 0.02276227613245201, 0.005690569033113002, 0.005690569033113002, 0.8022230374828692, 0.055239144990995685, 0.05900545033129085, 0.012554351134317202, 0.017576091588044084, 0.021342396928339242, 0.011298916020885482, 0.013809786247748921, 0.007532610680590321, 0.0012554351134317202, 0.5898987252969903, 0.1185022747749411, 0.04833399868773188, 0.08416460775354084, 0.04441502582115903, 0.03135178293258284, 0.04721429215442535, 0.026126485777152368, 0.006904856955390269, 0.0031725018443685016, 0.2964114872484001, 0.19270250353028376, 0.12753402051822416, 0.05886185562379576, 0.07217584677679718, 0.07217584677679718, 0.10651192922401138, 0.06236553750616456, 0.006306627388263832, 0.005605891011790072, 0.4832380327079477, 0.13301361975371684, 0.06986573966861895, 0.08330145883566105, 0.08643645997463754, 0.047472874390215435, 0.06673073852964245, 0.0210492933616993, 0.005822144972384912, 0.002687143833408421, 0.2323041051036819, 0.10429980229144901, 0.37453110822838515, 0.04266810093741096, 0.028445400624940644, 0.1090407023956058, 0.05214990114572451, 0.014222700312470322, 0.014222700312470322, 0.033186300729097416, 0.18918251403379954, 0.08902706542767037, 0.05564191589229398, 0.21700347197994654, 0.03338514953537639, 0.20587508880148775, 0.17805413085534075, 0.022256766356917593, 0.005564191589229398, 0.005564191589229398, 0.20958663818172563, 0.05923100644266159, 0.09112462529640245, 0.15491186300388415, 0.05467477517784147, 0.08656839403158233, 0.23236779450582626, 0.09568085656122258, 0.013668693794460368, 0.004556231264820122, 0.4619091868293604, 0.10714388354289288, 0.10952485873273494, 0.052381454176525406, 0.021428776708578574, 0.10000095797336668, 0.03571462784763096, 0.028571702278104766, 0.0666673053155778, 0.014285851139052383, 0.5645202667833447, 0.07553440189354611, 0.0437304432015267, 0.1470933089505898, 0.0437304432015267, 0.027828463855516992, 0.027828463855516992, 0.007950989673004855, 0.055656927711033984, 0.003975494836502428, 0.36777870253464656, 0.06062286305516153, 0.04041524203677435, 0.03233219362941948, 0.06466438725883895, 0.2626990732390333, 0.15357791973974252, 0.012124572611032305, 0.004041524203677435, 0.004041524203677435, 0.2659696218292605, 0.22488488349791133, 0.07135770341760647, 0.274619040425334, 0.04324709298036756, 0.03459767438429405, 0.051896511576441075, 0.025948255788220537, 0.006487063947055134, 0.004324709298036756, 0.762561989544593, 0.0412540507450226, 0.046782944143840065, 0.015310781719802203, 0.01998907613418621, 0.07527801012236082, 0.02551796953300367, 0.005528893398817462, 0.00595419289103419, 0.0017011979688669114, 0.34175749704168024, 0.04313444137419265, 0.033180339518609735, 0.023226237663026814, 0.016590169759304867, 0.4213903118863436, 0.08295084879652434, 0.01990820371116584, 0.0033180339518609735, 0.013272135807443894, 0.2584983904773236, 0.13656518742198226, 0.08779190619984574, 0.3316583123105284, 0.024386640611068263, 0.03901862497770922, 0.07315992183320479, 0.01950931248885461, 0.009754656244427305, 0.01950931248885461, 0.5461329636336758, 0.09102216060561263, 0.06501582900400903, 0.04551108030280632, 0.09102216060561263, 0.03900949740240542, 0.03250791450200451, 0.01950474870120271, 0.06501582900400903, 0.006501582900400903, 0.664727390690012, 0.07802323803265963, 0.05851742852449473, 0.050485624609368, 0.06042976279000109, 0.03901161901632982, 0.027537613423291637, 0.011474005593038182, 0.006884403355822909, 0.0030597348248101817, 0.4281534421998352, 0.05946575586108822, 0.09514520937774115, 0.15461096523882936, 0.06739452330923332, 0.03171506979258038, 0.06343013958516076, 0.047572604688870576, 0.01982191862036274, 0.027750686068507835, 0.5625072327486954, 0.07538756727559835, 0.06958852363901386, 0.04059330545609142, 0.04059330545609142, 0.0521913927292604, 0.05799043636584488, 0.023196174546337954, 0.07538756727559835, 0.0057990436365844885, 0.30886331905933645, 0.1449766599666273, 0.11345999475649093, 0.05672999737824547, 0.037819998252163645, 0.037819998252163645, 0.27734665384920004, 0.012606666084054549, 0.012606666084054549, 0.006303333042027274, 0.13159294146223038, 0.13570522088292508, 0.5537869619868862, 0.04523507362764169, 0.019190637296575264, 0.04797659324143816, 0.03152747555865936, 0.02604443633106643, 0.005483039227592933, 0.005483039227592933, 0.3029069846406094, 0.46529011042732776, 0.046841286284630315, 0.05308679112258102, 0.031227524189753542, 0.02810477177077819, 0.05308679112258102, 0.006245504837950709, 0.006245504837950709, 0.0031227524189753543, 0.530529932562748, 0.14283498184381677, 0.07141749092190838, 0.030607496109389308, 0.0663162415703435, 0.03570874546095419, 0.025506246757824425, 0.030607496109389308, 0.05611374286721373, 0.005101249351564885, 0.14877080434871795, 0.0803362343483077, 0.04165582521764103, 0.0654591539134359, 0.5564028082642052, 0.03272957695671795, 0.014877080434871796, 0.04463124130461539, 0.0029754160869743594, 0.008926248260923078, 0.14741466570767936, 0.45299298316422304, 0.04453151359919481, 0.1873394710035092, 0.029175819254644877, 0.08292074946056964, 0.03838923586137483, 0.00921341660672996, 0.00460670830336498, 0.0030711388689099867, 0.3593585204076514, 0.11978617346921715, 0.12834232871701837, 0.059893086734608574, 0.059893086734608574, 0.05133693148680735, 0.08556155247801225, 0.11123001822141593, 0.01711231049560245, 0.008556155247801225, 0.27995293683310535, 0.061359547799036795, 0.1265540673355134, 0.04985463258671739, 0.034514745636958194, 0.034514745636958194, 0.34514745636958194, 0.04985463258671739, 0.007669943474879599, 0.015339886949759199, 0.3202014516800244, 0.1983120773244864, 0.10834611053825599, 0.050303551321333136, 0.07061844704725613, 0.041597167438794706, 0.14413902205535842, 0.05610780724302542, 0.004836879934743571, 0.0038695039477948568, 0.09994023236256559, 0.6695995568291894, 0.039976092945026236, 0.06662682157504372, 0.05663279833878716, 0.019988046472513118, 0.026650728630017488, 0.009994023236256559, 0.003331341078752186, 0.009994023236256559, 0.4210675335988882, 0.16255902897885513, 0.0911916504027724, 0.07057440770301517, 0.04916419413019034, 0.06660955333767724, 0.0626446989723393, 0.0570939028608662, 0.01585941746135172, 0.003171883492270344, 0.4877086222682891, 0.10063828713472632, 0.13160391394541135, 0.09289688043205506, 0.038707033513356276, 0.038707033513356276, 0.038707033513356276, 0.023224220108013765, 0.015482813405342511, 0.038707033513356276, 0.7135791566876358, 0.035374009476822975, 0.05611049779082265, 0.02195628174423495, 0.020736488313999674, 0.035374009476822975, 0.0146375211628233, 0.097583474418822, 0.00243958686047055, 0.001219793430235275, 0.40257894379537307, 0.12314179457270234, 0.19418513759541522, 0.052098451549989454, 0.05683467441817031, 0.03788978294544688, 0.052098451549989454, 0.01894489147272344, 0.05683467441817031, 0.00473622286818086, 0.24234147181574472, 0.0875121981556856, 0.1009756132565603, 0.3971707454758039, 0.04039024530262412, 0.033658537752186767, 0.05385366040349883, 0.026926830201749415, 0.013463415100874707, 0.006731707550437354, 0.39929193360430765, 0.1828924590984766, 0.1493854436911221, 0.027922512839462076, 0.020941884629596556, 0.027922512839462076, 0.14100868983928347, 0.016753507703677246, 0.029318638481435177, 0.0027922512839462076, 0.24555660100338433, 0.17255328719156737, 0.04645665424388352, 0.2721032605713178, 0.10950497071772544, 0.03981998935190016, 0.0497749866898752, 0.03981998935190016, 0.02322832712194176, 0.00331833244599168, 0.28771419774855767, 0.5720633171608749, 0.018507930849322424, 0.010095235008721322, 0.020190470017442643, 0.05720633171608749, 0.021873009185562862, 0.005047617504360661, 0.0016825391681202203, 0.0033650783362404405, 0.1991927027203747, 0.20468010499917288, 0.07188496985225644, 0.03621685504006813, 0.0817622939540932, 0.17669435337730208, 0.17943805451670117, 0.035119374584308485, 0.011523544785476222, 0.0032924413672789205, 0.34465976283694233, 0.1282454931486297, 0.14427617979220841, 0.112214806505051, 0.04007671660894679, 0.04007671660894679, 0.04007671660894679, 0.12023014982684035, 0.02404602996536807, 0.008015343321789357, 0.3407588447979861, 0.12391230719926768, 0.08673861503948738, 0.07434738431956062, 0.05576053823967046, 0.06195615359963384, 0.21684653759871847, 0.03717369215978031, 0.006195615359963384, 0.006195615359963384, 0.4266656443872626, 0.14048746827385478, 0.04943077587413408, 0.05463401543983241, 0.06764211435407821, 0.14048746827385478, 0.020812958262793297, 0.02341457804564246, 0.07284535391977655, 0.002601619782849162, 0.22548912370653795, 0.10611252880307669, 0.46424231351346046, 0.039792198301153756, 0.039792198301153756, 0.06632033050192293, 0.02652813220076917, 0.019896099150576878, 0.006632033050192293, 0.006632033050192293, 0.255668152104054, 0.2167621289577849, 0.0555800330660987, 0.0555800330660987, 0.05002202975948883, 0.10560206282558753, 0.2167621289577849, 0.038906023146269085, 0.00555800330660987, 0.00555800330660987, 0.2878093555994107, 0.18795713018737026, 0.06461026350190853, 0.15271516827723833, 0.04111562222848724, 0.06461026350190853, 0.058736603183553206, 0.10572588573039576, 0.023494641273421282, 0.005873660318355321, 0.31757795313001763, 0.16871328760032187, 0.17863759863563494, 0.09924311035313052, 0.06947017724719136, 0.04962155517656526, 0.04962155517656526, 0.029772933105939155, 0.009924311035313051, 0.029772933105939155, 0.42005164259731026, 0.18110660321966648, 0.09814459635556776, 0.1359203249712467, 0.03126890454790649, 0.07157506474549694, 0.03904094440663469, 0.014098118813506972, 0.0039763924858609405, 0.0046993729378356575, 0.8371626495096677, 0.01882891772253578, 0.026070809154280308, 0.030415944013327027, 0.03620945715872265, 0.023174052581582495, 0.02172567429523359, 0.002896756572697812, 0.001448378286348906, 0.001448378286348906, 0.1771978988030799, 0.18113562988759277, 0.04331504192964175, 0.3268316800145696, 0.07087915952123196, 0.12206966361989949, 0.03543957976061598, 0.019688655422564434, 0.015750924338051545, 0.003937731084512886, 0.543223126614812, 0.15871210288580292, 0.07068879476048527, 0.05155329299411187, 0.05110304589372661, 0.05110304589372661, 0.03894637418332469, 0.016434019164061862, 0.014407907212328208, 0.0038271003532746803, 0.7952816919408723, 0.05475710010084694, 0.0208598476574655, 0.014341145264507532, 0.013037404785915939, 0.04432717627211419, 0.011733664307324344, 0.0065187023929579695, 0.04041595483633941, 0.0013037404785915937, 0.33241670167110576, 0.19500570493666505, 0.08072329181099158, 0.20543624264257968, 0.07165325902323971, 0.04761767213569728, 0.02448908852693003, 0.0326521180359067, 0.005895521312038711, 0.004535016393875931, 0.6086568504417615, 0.15490689849022482, 0.03335106029817871, 0.04849068635458879, 0.040152921280044114, 0.07174866261516079, 0.019527923464065167, 0.013384307093348037, 0.008557179944927433, 0.0010970743519137735, 0.36712794010823147, 0.11842836777684887, 0.047371347110739544, 0.021317106199832795, 0.2913337847310482, 0.03552851033305466, 0.06158275124396141, 0.04500277975520257, 0.009474269422147909, 0.0023685673555369773, 0.1951761463117056, 0.09216651353608321, 0.47709724653972485, 0.0704802750570048, 0.027107798098848, 0.0759018346767744, 0.021686238479078402, 0.021686238479078402, 0.0054215596197696005, 0.0054215596197696005, 0.6737226949116101, 0.075806247918068, 0.04408993781351048, 0.04280990736086017, 0.08647316835682055, 0.03768978555025895, 0.017067072702004055, 0.010666920438752534, 0.010098018015352398, 0.0014222560585003378, 0.36355242216796, 0.14899689433113114, 0.10131788814516918, 0.047679006185961964, 0.12515739123815017, 0.029799378866226228, 0.047679006185961964, 0.04171913041271672, 0.0774783850521882, 0.0059598757732452455, 0.5423892514381301, 0.08639828783970213, 0.043199143919851066, 0.03999920733319543, 0.03519930245321198, 0.16319676591943735, 0.0367992707465398, 0.03839923903986762, 0.004799904879983452, 0.007999841466639086, 0.27173757917031066, 0.1782598519357238, 0.2608680760034982, 0.06231848482305791, 0.039130211400524736, 0.04202874557834138, 0.06159385127860375, 0.05797068355633294, 0.015217304433537396, 0.010869503166812426, 0.3076740319566066, 0.24343014603862334, 0.14861236260545527, 0.09481778343316807, 0.07391916994177593, 0.05572963597704573, 0.03715309065136382, 0.019350568047585323, 0.012384363550454606, 0.006966204497130716, 0.5870652569279036, 0.18560245901812042, 0.04304729301596742, 0.04023986086275216, 0.04585472516918269, 0.04304729301596742, 0.02776238462623986, 0.014037160766076332, 0.009981980989209837, 0.0031193690591280743, 0.2862756624170087, 0.281423532545534, 0.04852129871474724, 0.05337342858622196, 0.22805010395931202, 0.02911277922884834, 0.02426064935737362, 0.033964909100323064, 0.009704259742949448, 0.009704259742949448, 0.5597305641063175, 0.07816926843553744, 0.06321095163614447, 0.07768674208716993, 0.13510737754290422, 0.045840003094913935, 0.022196212024905695, 0.005307789832042666, 0.011098106012452848, 0.0019301053934700602, 0.16979344190297174, 0.5772977024701039, 0.14553723591683293, 0.041235550176436, 0.016979344190297174, 0.019404964788911058, 0.009702482394455529, 0.009702482394455529, 0.007276861795841647, 0.0024256205986138823, 0.11897811866861042, 0.18815144347594207, 0.36800208797500433, 0.06640639181503838, 0.04427092787669225, 0.02490239693063939, 0.1272789176454902, 0.013834664961466328, 0.02490239693063939, 0.01936853094605286, 0.2198979620610519, 0.1418696529426141, 0.120589205001222, 0.042560895882784236, 0.1418696529426141, 0.03546741323565353, 0.17733706617826764, 0.09930875705982987, 0.014186965294261411, 0.007093482647130706, 0.2814617644502598, 0.10856382343081447, 0.04020882349289425, 0.0482505881914731, 0.3015661761967069, 0.036187941143604824, 0.13268911752655102, 0.016083529397157702, 0.016083529397157702, 0.012062647047868275, 0.37517596696855693, 0.12461675227930867, 0.3486617643559381, 0.026514202612618866, 0.02783991274324981, 0.03314275326577358, 0.034468463396404525, 0.007954260783785659, 0.013257101306309433, 0.007954260783785659, 0.45014801750902356, 0.1739748409802562, 0.0451574040795747, 0.11835993279804316, 0.07652991638748975, 0.07177650543174505, 0.03137251230791505, 0.023291713683149057, 0.005228752051319176, 0.0038027287645957643, 0.12355518228373619, 0.11353719453100082, 0.2070384135565309, 0.06678658501823578, 0.0901618897746183, 0.023375304756382522, 0.3606475590984732, 0.013357317003647156, 0.003339329250911789, 0.003339329250911789, 0.7687546387770207, 0.04442551932631024, 0.019315443185352277, 0.019315443185352277, 0.10044030456383185, 0.015452354548281822, 0.019315443185352277, 0.007726177274140911, 0.0038630886370704556, 0.0019315443185352278, 0.1907026748837791, 0.044458292304193896, 0.6200761821374412, 0.022229146152096948, 0.009359640485093452, 0.06551748339565416, 0.01637937084891354, 0.01403946072764018, 0.015209415788276861, 0.0011699550606366815, 0.18578643870853334, 0.2982361252952772, 0.04400205127307368, 0.06111396010149123, 0.23712216519378596, 0.03177925925277544, 0.09778233616238596, 0.02933470084871579, 0.009778233616238596, 0.004889116808119298, 0.1655513030164691, 0.24161541521322513, 0.08501283127872736, 0.10291026944266997, 0.19239746026238297, 0.08501283127872736, 0.03579487632788521, 0.03132051678689955, 0.0626410335737991, 0.004474359540985651, 0.40403893217561615, 0.1154396949073189, 0.08657977118048918, 0.06493482838536688, 0.06493482838536688, 0.04328988559024459, 0.028859923726829724, 0.16594456142927091, 0.007214980931707431, 0.007214980931707431, 0.5100916796006223, 0.1152412345452351, 0.10605866605557493, 0.06795100682348525, 0.07346054791728134, 0.04269894347691978, 0.055095410937961005, 0.014692109583456268, 0.00872344006517716, 0.006427797942762117, 0.7549604579180197, 0.06113338342165428, 0.04787554123382564, 0.03756388619884781, 0.03682733941063511, 0.022096403646381064, 0.019150216493530256, 0.004419280729276213, 0.013257842187828639, 0.0029461871528508087, 0.17056018405848627, 0.24365740579783754, 0.2629819586714591, 0.10250415002529717, 0.05461286681675669, 0.061334450424972896, 0.04789128320854048, 0.021845146726702677, 0.02520593853081078, 0.010082375412324313, 0.44844524406473885, 0.23729567243354996, 0.051103742477342146, 0.07051524155788295, 0.08160752674676343, 0.05783834419916243, 0.02337302950514098, 0.018223039953160765, 0.009111519976580383, 0.0027730712972201164, 0.1412413507351223, 0.1291349492435404, 0.3551211104197361, 0.23002162834005632, 0.02824827014702446, 0.048425605966327646, 0.01614186865544255, 0.012106401491581912, 0.012106401491581912, 0.024212802983163823, 0.6663824893193041, 0.05501887758236749, 0.081566447884349, 0.07579523694913563, 0.0630985728916662, 0.026162822906300624, 0.010772927079064963, 0.008849190100660504, 0.009618684892022288, 0.0026932317697662407, 0.3222960993200001, 0.10367566831272729, 0.08113747954909092, 0.05634547190909092, 0.05634547190909092, 0.0676145662909091, 0.26144298965818186, 0.04507637752727273, 0.00676145662909091, 0.002253818876363637, 0.1613412724476462, 0.47615351136988265, 0.10231397764972686, 0.09050851869014298, 0.06689760077097524, 0.03935152986527956, 0.031481223892223645, 0.011805458959583869, 0.007870305973055911, 0.011805458959583869, 0.4833310220376326, 0.11855289219790989, 0.10031398570592374, 0.07295562596794454, 0.05471671947595841, 0.03647781298397227, 0.04559726622996534, 0.03647781298397227, 0.009119453245993068, 0.027358359737979204, 0.5050262369108602, 0.19215283978645178, 0.08571873893819411, 0.04000207817115725, 0.03285884992630774, 0.0771468650443747, 0.021429684734548527, 0.01714374778763882, 0.02285833038351843, 0.0050002597713946564, 0.19446272000092021, 0.17332546782690714, 0.10568626087006533, 0.04227450434802613, 0.131050963478881, 0.04227450434802613, 0.2663293773925646, 0.029592153043618293, 0.008454900869605226, 0.004227450434802613, 0.4484555934400631, 0.06840848035526385, 0.0494061247010239, 0.022802826785087955, 0.0494061247010239, 0.05320659583187189, 0.16722072975731167, 0.0494061247010239, 0.07220895148611185, 0.01520188452339197, 0.2486729011862914, 0.21064057512250567, 0.03218119897704948, 0.05558570732399455, 0.29840748142354967, 0.03218119897704948, 0.07899021567093963, 0.038032326063785746, 0.0029255635433681343, 0.0029255635433681343, 0.21469155442524163, 0.10870458451910969, 0.48101778649706034, 0.0516346776465771, 0.048917063033599356, 0.03804660458168839, 0.016305687677866453, 0.027176146129777423, 0.008152843838933227, 0.005435229225955484, 0.28673768913905423, 0.07033188601523972, 0.05410145078095363, 0.40576088085715223, 0.06492174093714435, 0.04869130570285827, 0.037871015546667545, 0.021640580312381454, 0.005410145078095363, 0.005410145078095363, 0.3082229590546247, 0.17874640004654815, 0.17530896927642223, 0.08364414873973086, 0.06072794360555803, 0.06301956411897532, 0.06187375386226667, 0.02864525641771605, 0.03666592821467655, 0.0045832410268345685, 0.2838569149948406, 0.35732576358174056, 0.033394931175863604, 0.033394931175863604, 0.22374603887828615, 0.03005543805827724, 0.01335797247034544, 0.010018479352759081, 0.00667898623517272, 0.00667898623517272, 0.19168359235536134, 0.11036328044702622, 0.44145312178810486, 0.026138671684822, 0.06679882763898955, 0.03194726539256022, 0.08422460876220422, 0.04356445280803666, 0.002904296853869111, 0.002904296853869111, 0.34573562796278073, 0.05226236236646686, 0.05226236236646686, 0.0321614537639796, 0.22513017634785723, 0.1527669053789031, 0.08442381613044646, 0.048242180645969406, 0.00402018172049745, 0.00402018172049745, 0.36403357933569347, 0.3724128688856199, 0.09682734591026118, 0.09496528156583307, 0.021413739960923144, 0.017689611272066946, 0.023275804305351245, 0.0027930965166421493, 0.0027930965166421493, 0.003724128688856199, 0.2743917920749613, 0.1875010579178902, 0.07774434108790569, 0.06402475148415764, 0.05945155494957494, 0.24695261286746514, 0.04573196534582688, 0.01829278613833075, 0.01829278613833075, 0.004573196534582688, 0.6915527907502321, 0.04837286360170017, 0.026873813112055653, 0.041878358766286726, 0.08778778949938179, 0.055763162207515475, 0.025306174013852406, 0.012989009670826899, 0.007614247048415768, 0.0022394844260046377, 0.5131697351330904, 0.3360413810235047, 0.0496210637399194, 0.03266196600602289, 0.01570286827212639, 0.010677950425045945, 0.02449647450451717, 0.011306065155931001, 0.005024917847080445, 0.0012562294617701113, 0.254550101136472, 0.1303793200942905, 0.11796224199007237, 0.2855927963970173, 0.05587685146898165, 0.09933662483374515, 0.031042695260545358, 0.012417078104218144, 0.006208539052109072, 0.006208539052109072, 0.5161786663187176, 0.1551984854187681, 0.07319237213576471, 0.04138626277833816, 0.04483511800986634, 0.05020000392557684, 0.06936031076740007, 0.03602137686262766, 0.010729771831421004, 0.0034488552315281797, 0.5360401219987875, 0.1303979002975487, 0.07115896498231881, 0.040817071284274246, 0.0375661541023409, 0.06032257437587433, 0.07115896498231881, 0.035398875981052, 0.013364881747948204, 0.003973343222362979, 0.4468521119520011, 0.21952585051008533, 0.07354673164297275, 0.06908935396764107, 0.059060254198144785, 0.06351763187347646, 0.036773365821486374, 0.016715166282493806, 0.010400547909107258, 0.0040859295357207085, 0.31738832175760234, 0.31023590887292396, 0.041126374086900584, 0.18775083822280703, 0.03665611603397661, 0.05543119985625731, 0.03576206442339181, 0.003576206442339181, 0.005364309663508772, 0.007152412884678362, 0.3264519992617446, 0.2945307856242555, 0.08325842319881188, 0.13064661664003288, 0.05034995553129731, 0.06153883453825226, 0.030275790254113415, 0.014150641097031269, 0.005594439503477479, 0.003290846766751458, 0.8401616039152772, 0.03896401641346213, 0.026787761284255213, 0.01704675718088968, 0.03409351436177936, 0.014611506155048297, 0.014611506155048297, 0.0073057530775241485, 0.004870502051682766, 0.002435251025841383, 0.2666939788171747, 0.2755468909770809, 0.04979763089947246, 0.16377887495826496, 0.04537117481951935, 0.13943336651852287, 0.0331984205996483, 0.022132280399765537, 0.0022132280399765536, 0.0022132280399765536, 0.2953794767092705, 0.16574070637575733, 0.039383930227902736, 0.2904564854307827, 0.026255953485268487, 0.1017418197554154, 0.03774293313507345, 0.016409970928292807, 0.008204985464146403, 0.018050968021122087, 0.41306052755915845, 0.06884342125985975, 0.058252125681419784, 0.2965562761963189, 0.037069534524539864, 0.058252125681419784, 0.037069534524539864, 0.02118259115687992, 0.01059129557843996, 0.00529564778921998, 0.3543161738947922, 0.26084326061591745, 0.14975241603840664, 0.044534215227107855, 0.044534215227107855, 0.061662759545226264, 0.041108506363484176, 0.02691628392847178, 0.006851417727247362, 0.009787739610353376, 0.3328784718901623, 0.13239484677449637, 0.09078503778822608, 0.05295793870979855, 0.07187148824901232, 0.049175228801955795, 0.2042663350235087, 0.03026167926274203, 0.03026167926274203, 0.0037827099078427536, 0.21484882742808178, 0.08184717235355496, 0.29158055150953954, 0.09719351716984652, 0.046039034448874666, 0.15346344816291557, 0.030692689632583113, 0.0358081379046803, 0.02046179308838874, 0.030692689632583113, 0.13053943768215445, 0.14452580600524245, 0.5594547329235191, 0.05439143236756436, 0.02952677757096351, 0.02952677757096351, 0.02486465479660085, 0.018648491097450638, 0.004662122774362659, 0.004662122774362659, 0.24416209758965268, 0.278747426423705, 0.2286761294550024, 0.0856890236783982, 0.03510152777187396, 0.036650124585338985, 0.05936287784949273, 0.02271275326415374, 0.004129591502573407, 0.004645790440395083, 0.16326445058906622, 0.13693147468760392, 0.12113168914672653, 0.16326445058906622, 0.03159957108175475, 0.2896627349160852, 0.052665951802924584, 0.015799785540877374, 0.026332975901462292, 0.010533190360584916, 0.12152335478691824, 0.1526831893476665, 0.07789958640187067, 0.13398728861121753, 0.0934795036822448, 0.3147143290635575, 0.04362376838504757, 0.04985573529719722, 0.006231966912149653, 0.006231966912149653, 0.26825511953378917, 0.20927704360792063, 0.04946548303459942, 0.27776771242505827, 0.057075557347614714, 0.08371081744316825, 0.02473274151729971, 0.01522014862603059, 0.007610074313015295, 0.0038050371565076474, 0.37554306446237107, 0.45754237578534745, 0.024806514349807997, 0.03858791121081244, 0.03514256199556133, 0.020672095291506664, 0.021361165134556884, 0.013781396861004443, 0.006890698430502221, 0.006201628587451999, 0.48609425649107607, 0.10476169320928364, 0.04714276194417764, 0.0722855683144057, 0.15714253981392545, 0.043999911147899126, 0.04819037887627047, 0.03142850796278509, 0.0062857015925570185, 0.0031428507962785093, 0.38407844439140937, 0.17310577775387465, 0.09737199998655449, 0.07032422221251158, 0.09737199998655449, 0.037866888883660084, 0.07032422221251158, 0.027047777774042915, 0.02163822221923433, 0.027047777774042915, 0.5372661704225282, 0.14783834219680309, 0.04326975869174724, 0.03966394546743497, 0.02524069257018589, 0.061298824813308596, 0.07932789093486994, 0.03245231901881043, 0.01081743967293681, 0.02163487934587362, 0.5025956010892734, 0.10275287844491812, 0.040952234162829684, 0.0536101974495225, 0.07296943541740562, 0.083393640477035, 0.10275287844491812, 0.029038856951824687, 0.006701274681190313, 0.0059566886055025, 0.17127194993373357, 0.04359649634676854, 0.6539474452015281, 0.02179824817338427, 0.015570177266703051, 0.02179824817338427, 0.02179824817338427, 0.034254389986746715, 0.006228070906681221, 0.006228070906681221, 0.35770225400939193, 0.3342167524835228, 0.06864992753715603, 0.024388790046094906, 0.0704565045776075, 0.08581240942144504, 0.024388790046094906, 0.0072263081618058975, 0.013549327803386059, 0.014452616323611795, 0.5300369537091971, 0.1314377351516068, 0.04809859148663873, 0.04428880206195447, 0.07476711745942852, 0.0580992887264349, 0.06952865700048767, 0.02904964436321745, 0.00952447356171064, 0.0042860131027697874, 0.48955288501121397, 0.13299692542059408, 0.09573708639225643, 0.09211460204227916, 0.05537226077822399, 0.041399821142597375, 0.04036482561403244, 0.040882323378314905, 0.008279964228519475, 0.0036224843499772703, 0.2914296479346974, 0.17994313832209502, 0.34423904722487747, 0.025426747806382995, 0.01564722941931261, 0.05280939929018006, 0.013691325741898535, 0.04889759193535191, 0.005867711032242229, 0.019559036774140764, 0.3125738714384851, 0.1339602306164936, 0.08292776181021032, 0.051032468806283274, 0.15309740641884984, 0.05741152740706868, 0.051032468806283274, 0.140339289217279, 0.012758117201570818, 0.012758117201570818, 0.5326283362916819, 0.12147663810161166, 0.054628547311967375, 0.03018946035661355, 0.11788265472582433, 0.045284190534920325, 0.06612929411448683, 0.023001493605038895, 0.0035939833757873273, 0.0050315767261022585, 0.3032098178241413, 0.1840255106142446, 0.1939060749425262, 0.16364684668716384, 0.04075732785416156, 0.05990092124020714, 0.02717155190277437, 0.014203311221904786, 0.008027958516728792, 0.005557817434658394, 0.27819283591263744, 0.1738705224453984, 0.06954820897815936, 0.04172892538689562, 0.11127713436505499, 0.06954820897815936, 0.10432231346723905, 0.11127713436505499, 0.03477410448907968, 0.006954820897815937, 0.7179554598237388, 0.053558946139748695, 0.028328698784660468, 0.038509324910397824, 0.07834655757632661, 0.02523024735508823, 0.0358535093993359, 0.011065897962757995, 0.009295354288716716, 0.0017705436740412792, 0.8574487087456714, 0.021359932246333452, 0.02746277003100015, 0.010679966123166726, 0.021359932246333452, 0.0366170267080002, 0.00915425667700005, 0.0122056755693334, 0.001525709446166675, 0.001525709446166675, 0.2784042120340681, 0.11372721079823045, 0.296600565761785, 0.10826830467991538, 0.023655259846031933, 0.04549088431929218, 0.08461304483388346, 0.04185161357374881, 0.005458906118315061, 0.0018196353727716872, 0.2513278875209882, 0.11868261355157776, 0.15358926459615946, 0.2862345385655699, 0.06283197188024706, 0.027925320835665356, 0.048869311462414376, 0.034906651044581696, 0.013962660417832678, 0.006981330208916339, 0.21037186987212747, 0.11203235673663593, 0.48236153594940473, 0.01742725549236559, 0.028008089184158983, 0.06099539422327956, 0.021161667383586786, 0.03858892287595238, 0.023028873329197386, 0.006224019818701996, 0.2906366530501579, 0.08845463353700457, 0.14531832652507895, 0.08213644542721853, 0.2780002768305858, 0.03790912865871625, 0.03790912865871625, 0.018954564329358124, 0.018954564329358124, 0.006318188109786041, 0.7303968502706939, 0.0655087570511145, 0.0299173851099578, 0.03404392098719336, 0.025790849232722242, 0.05622405132733449, 0.024759215263413355, 0.016506143508942236, 0.0149586925549789, 0.0030949019079266693, 0.20465594724529995, 0.12766445845436178, 0.5299057060151816, 0.031228690606528497, 0.01198081840879395, 0.02631851912751458, 0.02926462201492293, 0.0298538425924046, 0.006481426352298367, 0.002553289169087236, 0.27979202262234626, 0.15783139737670815, 0.07891569868835407, 0.06456738983592605, 0.05739323540971205, 0.24392125049127622, 0.08608985311456807, 0.014348308852428012, 0.007174154426214006, 0.007174154426214006, 0.3711992122803327, 0.1719483049060696, 0.09352593611445002, 0.16846286629310875, 0.06970877225921741, 0.03833982474256958, 0.04705342127497175, 0.03194985395214131, 0.005228157919441306, 0.0034854386129608704, 0.4284996823896027, 0.17802402263529385, 0.05175116937072496, 0.1210977363274964, 0.028980654847605977, 0.06624149679452795, 0.10557238551627891, 0.004140093549657997, 0.0031050701622434974, 0.01138525726155949, 0.21389220422094746, 0.05269807930081314, 0.2665902835217606, 0.061997740353897816, 0.021699209123864235, 0.02789898315925402, 0.0650976273715927, 0.2727900575571504, 0.015499435088474454, 0.0030998870176948906, 0.6589601354439575, 0.15777148943723174, 0.043542016137988894, 0.028056361862971925, 0.029331651038561557, 0.038440859435630366, 0.01748968012237211, 0.012570707587954952, 0.010931050076482568, 0.002732762519120642, 0.8255702476411951, 0.03352569533568305, 0.02723962746024248, 0.052383898962004766, 0.02723962746024248, 0.014667491709361335, 0.012572135750881144, 0.0041907119169603815, 0.0020953559584801907, 0.0020953559584801907, 0.36776226025030445, 0.20154202962869794, 0.0228552817104709, 0.29088540358781145, 0.03532179900709139, 0.016622023062160655, 0.03532179900709139, 0.018699775944930736, 0.004155505765540164, 0.002077752882770082, 0.2603679054137602, 0.0929885376477715, 0.05114369570627432, 0.437046126944526, 0.04649426882388575, 0.02789656129433145, 0.032545988176720025, 0.037195415059108596, 0.009298853764777149, 0.0046494268823885744, 0.8081356429057418, 0.03835220000230639, 0.02739442857307599, 0.06574662857538238, 0.019176100001153194, 0.016436657143845596, 0.013697214286537996, 0.005478885714615199, 0.0027394428573075994, 0.0027394428573075994, 0.24577018788234747, 0.24787980322897707, 0.2542086492688658, 0.043247114605906634, 0.022150961139610716, 0.13501538218429388, 0.0263701918328699, 0.008438461386518367, 0.007383653713203572, 0.009493269059833163, 0.5126068563872981, 0.1296360968855908, 0.06927119680909433, 0.011875062310130457, 0.04453148366298921, 0.03166683282701455, 0.09401090995519945, 0.01484382788766307, 0.0841150246967574, 0.006927119680909433, 0.5606860089767045, 0.09419524950808636, 0.09643799354399317, 0.01121372017953409, 0.026912928430881815, 0.02018469632316136, 0.10316622565171363, 0.016820580269301135, 0.05943271695153068, 0.01009234816158068, 0.1382977387797155, 0.07375879401584826, 0.2581557790554689, 0.33191457307131716, 0.046099246259905156, 0.027659547755943096, 0.03687939700792413, 0.013829773877971548, 0.05992902013787671, 0.004609924625990516, 0.3252814224011899, 0.15902647317391505, 0.20962580554743349, 0.07228476053359775, 0.07228476053359775, 0.0289139042134391, 0.0578278084268782, 0.021685428160079324, 0.007228476053359775, 0.0289139042134391, 0.3445705106423797, 0.39458881057433803, 0.08058503877926622, 0.1167093665079028, 0.016672766643986113, 0.012967707389766978, 0.024082885152424387, 0.00463132406777392, 0.0027787944406643525, 0.0027787944406643525, 0.4862377625820595, 0.3196731438366719, 0.05637012206448708, 0.08546437861389976, 0.014547128274706342, 0.012001380826632732, 0.019274944963985904, 0.0029094256549412685, 0.0014547128274706343, 0.0021820692412059515, 0.2921974299387404, 0.06391818779909947, 0.06848377264189229, 0.31959093899549734, 0.07761494232747793, 0.05935260295630665, 0.07761494232747793, 0.03652467874234255, 0.004565584842792819, 0.004565584842792819, 0.10080245264125302, 0.5019122121095723, 0.046201124127240964, 0.15540378115526507, 0.044101073030548193, 0.058801430707397594, 0.04200102193385542, 0.03990097083716265, 0.010500255483463856, 0.0021000510966927713, 0.7802365700363068, 0.07418208475727195, 0.023844241529123126, 0.022519561444171842, 0.03841572246358726, 0.007948080509707708, 0.022519561444171842, 0.0172208411043667, 0.010597440679610277, 0.0026493601699025694, 0.18655292513803626, 0.4514120163833964, 0.04836557318393533, 0.04375932811879863, 0.04836557318393533, 0.18194668007289957, 0.018424980260546793, 0.009212490130273396, 0.0069093675977050465, 0.002303122532568349, 0.7400240163756694, 0.06581558497050423, 0.020868356210159877, 0.020868356210159877, 0.035315679740270556, 0.03371042157025826, 0.027289388890209067, 0.00802629085006149, 0.04173671242031975, 0.0064210326800491924, 0.8262216506710083, 0.034016444904112875, 0.023433550933944423, 0.014362498959514323, 0.0120947359659068, 0.03779604989345875, 0.02267762993607525, 0.003779604989345875, 0.019653945944598548, 0.005291446985084225, 0.25650769895110437, 0.275681862493961, 0.16276734385269412, 0.03877441960888787, 0.10567094574729881, 0.05539202801269696, 0.07073135884698227, 0.01917416354285664, 0.008095757940317248, 0.007243572893968063, 0.30749640404225903, 0.06223141510379052, 0.13544484463766174, 0.04026738624362916, 0.08419544396395189, 0.10249880134741969, 0.20865827417153293, 0.01464268590677424, 0.018303357383467802, 0.02928537181354848, 0.2620546528034782, 0.13539490394846374, 0.19654098960260866, 0.2838925405371014, 0.026205465280347822, 0.048043353013971, 0.021837887733623183, 0.008735155093449274, 0.008735155093449274, 0.004367577546724637, 0.36692277411769614, 0.21318554273106516, 0.04044434296383636, 0.11914026330913241, 0.09380163880166867, 0.07187398297790197, 0.06285928002813121, 0.023389499545351147, 0.004141890544489266, 0.0038982499242251915, 0.5049756954650294, 0.05188106460257151, 0.05188106460257151, 0.034587376401714345, 0.23865289717182897, 0.017293688200857173, 0.08646844100428586, 0.010376212920514303, 0.003458737640171434, 0.003458737640171434, 0.18530827108398495, 0.14824661686718796, 0.07041714301191428, 0.344673384216212, 0.08153563927695337, 0.08153563927695337, 0.06300481216855489, 0.011118496265039097, 0.011118496265039097, 0.007412330843359398, 0.35882512328191907, 0.13835576853816942, 0.10123592819866056, 0.0562421823325892, 0.038244683986160655, 0.1889737326374997, 0.06861546244575882, 0.038244683986160655, 0.007873905526562489, 0.003374530939955352, 0.27385979275907374, 0.16326256876021703, 0.0631984137136324, 0.05793187923749636, 0.047398810285224295, 0.026332672380680166, 0.31072553409202597, 0.0157996034284081, 0.005266534476136033, 0.0315992068568162, 0.2727278130758228, 0.32727337569098736, 0.04646473852402907, 0.1570710182714461, 0.05858597466073231, 0.07020215929173958, 0.042424326478461324, 0.016666699687966947, 0.004545463551263713, 0.004040412045567745, 0.6711964858598204, 0.10175249923453726, 0.03663089972443342, 0.06549160859822943, 0.06216152680509913, 0.029970736138172794, 0.01813044531815391, 0.00888021811501416, 0.00444010905750708, 0.00111002726437677, 0.4329279426112303, 0.23717229889576802, 0.06973573564547209, 0.08778914944201563, 0.044602551732636976, 0.059824057482663874, 0.03539885058145791, 0.018407402302358114, 0.009203701151179057, 0.004955839081404108, 0.1464418675292928, 0.17080863626151452, 0.4731013216226412, 0.027020575227810206, 0.044149689881154176, 0.050181068280218954, 0.033051953626874984, 0.03498199471457571, 0.0065138886709899604, 0.013992797885830285, 0.32272793463360966, 0.154324599615065, 0.3979950200599045, 0.02436704204448395, 0.01570320487311188, 0.029781940276591493, 0.020576613282008667, 0.02436704204448395, 0.007580857524950562, 0.002165959292843018, 0.3008702606082256, 0.17927502575101525, 0.20733546456421764, 0.05767979089380491, 0.07015109703300597, 0.056120877626404775, 0.05300305109160451, 0.02338369901100199, 0.045208484754603845, 0.007794566337000664, 0.7788108986217026, 0.05273198792751111, 0.04867568116385641, 0.028394147345582908, 0.028394147345582908, 0.024337840581928206, 0.016225227054618804, 0.012168920290964103, 0.008112613527309402, 0.004056306763654701, 0.7920663161673923, 0.059643547904171104, 0.031014644910168976, 0.04055761257483635, 0.016700193413167908, 0.028628902994002132, 0.014314451497001066, 0.009542967664667376, 0.004771483832333688, 0.002385741916166844, 0.3216462894107454, 0.15659095668681025, 0.08887594838981122, 0.11003688848262343, 0.038089692167061956, 0.21160940092812197, 0.033857504148499515, 0.012696564055687318, 0.016928752074249757, 0.004232188018562439, 0.4037009820788413, 0.06977547838399727, 0.0498396274171409, 0.12958303128456633, 0.14453491950970862, 0.03987170193371272, 0.0996792548342818, 0.00996792548342818, 0.05482359015885499, 0.00498396274171409, 0.5352617067755256, 0.11428560766288251, 0.08245923590866207, 0.043399597846664244, 0.12296552723221536, 0.0347196782773314, 0.026763085338776284, 0.028933065231109497, 0.00867991956933285, 0.0028933065231109495, 0.58253291993124, 0.07324578953948793, 0.026322705615753478, 0.024033774692644477, 0.20829271400291882, 0.012589120077099489, 0.028611636538862475, 0.019455912846426483, 0.024033774692644477, 0.001144465461554499, 0.5129969719565953, 0.09626030137400643, 0.07102131991618768, 0.05399968125858898, 0.10154287888843362, 0.04284757317257604, 0.06867350768755337, 0.03756499565814885, 0.012912967257488668, 0.0023478122286343032, 0.271922328380126, 0.4488180366274122, 0.1344992161880193, 0.02777701203883007, 0.04970623206948539, 0.032162856044961136, 0.017543376024524257, 0.011695584016349504, 0.002923896004087376, 0.002923896004087376, 0.2672316903474189, 0.1469774296910804, 0.06680792258685472, 0.07126178409264504, 0.02672316903474189, 0.3852590202508623, 0.015588515270266104, 0.006680792258685473, 0.004453861505790315, 0.006680792258685473, 0.12546878861995017, 0.22471132213644282, 0.5105178976388947, 0.01907364007524183, 0.01639140943966095, 0.030100588243741015, 0.01728548631818791, 0.04321371579546977, 0.009238794411445261, 0.004172358766459151, 0.33887314141472324, 0.23838572720830337, 0.16704401322625637, 0.11875785315304165, 0.020445491202172004, 0.026100627066602558, 0.03958595105101388, 0.028710689773262816, 0.01653039714218162, 0.005655135864430554, 0.15799513805280443, 0.03949878451320111, 0.5617604908544158, 0.10971884587000308, 0.013166261504400369, 0.0570537998524016, 0.019749392256600554, 0.026332523008800738, 0.010971884587000307, 0.0065831307522001845, 0.38748999593432293, 0.19052485949679313, 0.18998816975173174, 0.03005462572343779, 0.046155318075279464, 0.03112800521356057, 0.07191642583822615, 0.03112800521356057, 0.01180717439135056, 0.010197105156166394, 0.13887935479409794, 0.46220785267410724, 0.021699899186577803, 0.2994586087747737, 0.023869889105235586, 0.017359919349262242, 0.008679959674631121, 0.015189929430604463, 0.010849949593288902, 0.0021699899186577803, 0.15071124297732857, 0.2987069680631737, 0.2077371186984799, 0.21316815448144671, 0.035301732589284165, 0.05431035782966795, 0.01086207156593359, 0.009504312620191892, 0.013577589457416987, 0.006788794728708494, 0.13473951670751613, 0.5010625777560757, 0.18245976220809476, 0.04070256233872883, 0.030877805912139112, 0.05473792866242843, 0.016842439588439517, 0.023860122750289314, 0.011228293058959678, 0.0028070732647399194, 0.2766615232588653, 0.5152503598307308, 0.07614537337399961, 0.02791997023713319, 0.02030543289973323, 0.015229074674799923, 0.04822540313686642, 0.010152716449866615, 0.0076145373373999615, 0.002538179112466654, 0.39486894030363834, 0.3872122018489972, 0.0951623207933976, 0.06234772741636395, 0.021876395584689106, 0.0054690988961722765, 0.01859493624698574, 0.0032814593377033657, 0.0032814593377033657, 0.008750558233875641, 0.713859859810606, 0.024316394251456167, 0.045159017895561454, 0.019105738340429845, 0.013895082429403523, 0.015631967733078962, 0.013895082429403523, 0.1372139389903598, 0.013895082429403523, 0.0034737706073508807, 0.27247219964089686, 0.47682634937156954, 0.06811804991022422, 0.06411110579785809, 0.024041664674196783, 0.0520902734607597, 0.024041664674196783, 0.012020832337098391, 0.00801388822473226, 0.00400694411236613, 0.4860485025298171, 0.05447095286972088, 0.05447095286972088, 0.29749520413462943, 0.020950366488354185, 0.02933051308369586, 0.02933051308369586, 0.016760293190683347, 0.004190073297670837, 0.004190073297670837, 0.5422431187603277, 0.10290745319539066, 0.04947473711316858, 0.05343271608222207, 0.05541170556674881, 0.04155877917506161, 0.04947473711316858, 0.08905452680370345, 0.015831915876213947, 0.0019789894845267434, 0.5984379864521348, 0.057816467950833596, 0.026280212704924363, 0.0585673311709743, 0.13515537962532528, 0.025529349484783668, 0.05931819439111499, 0.026280212704924363, 0.009010358641688353, 0.0022525896604220883, 0.26822808981726803, 0.0721043252196957, 0.1528611694657549, 0.2711122628260559, 0.18458707256242102, 0.0201892110615148, 0.01730503805272697, 0.008652519026363485, 0.0028841730087878284, 0.0028841730087878284, 0.4992459037696441, 0.1524094228034338, 0.08976494826768658, 0.05118511943774469, 0.06493634555534775, 0.04698335590181042, 0.042781592365876156, 0.03896180733320864, 0.010313419588202288, 0.0034378065294007627, 0.08511121915270067, 0.12542705980397992, 0.36284256586151337, 0.04628855778480212, 0.12692023908736064, 0.1448383904879292, 0.01791815140056856, 0.07465896416903567, 0.014931792833807135, 0.0014931792833807135, 0.09694166305012697, 0.41065565597623227, 0.2356220976912808, 0.0848239551688611, 0.030967475696568336, 0.022889003775724424, 0.09694166305012697, 0.01346411986807319, 0.002692823973614638, 0.005385647947229276, 0.2429523827821964, 0.09481068596378397, 0.08295935021831097, 0.18369570405483143, 0.03555400723641899, 0.041479675109155484, 0.2903577257640884, 0.017777003618209494, 0.011851335745472997, 0.0059256678727364984, 0.6264491072467481, 0.10078238649540171, 0.0266385162542912, 0.06792821644844256, 0.04350957654867563, 0.051057156154058134, 0.05061318088315328, 0.01598310975257472, 0.01598310975257472, 0.0008879505418097067, 0.15128773610375967, 0.07564386805187984, 0.14624481156696767, 0.15128773610375967, 0.025214622683959947, 0.40343396294335915, 0.020171698147167957, 0.010085849073583978, 0.005042924536791989, 0.010085849073583978, 0.44580231190804154, 0.126267706841006, 0.05282628551511475, 0.10694101701840303, 0.063133853420503, 0.02190358179895002, 0.08761432719580008, 0.07988365126675889, 0.009019121917214714, 0.007730675929041183, 0.2149399966061396, 0.45615043724191845, 0.07642310990440519, 0.04776444369025324, 0.09314066519599383, 0.028658666214151945, 0.05731733242830389, 0.016717555291588634, 0.009552888738050649, 0.0023882221845126623, 0.2904782535212964, 0.15768819476870377, 0.14108943742462968, 0.09959254406444448, 0.05809565070425928, 0.03319751468814816, 0.04979627203222224, 0.1493888160966667, 0.01659875734407408, 0.00829937867203704, 0.6529478724502925, 0.043980944776444576, 0.03383149598188044, 0.020298897589128263, 0.027065196785504352, 0.02368204718731631, 0.03383149598188044, 0.010149448794564132, 0.14885858232027394, 0.003383149598188044, 0.47430694629016196, 0.1481197460257673, 0.06879878913765147, 0.06313300650278607, 0.12626601300557214, 0.05180144123305523, 0.02751951565506059, 0.021853733020195176, 0.014569155346796784, 0.00404698759633244, 0.22651685065101262, 0.13591011039060757, 0.09815730194877215, 0.052853931818569615, 0.03775280844183544, 0.32467415259978477, 0.052853931818569615, 0.015101123376734176, 0.015101123376734176, 0.045303370130202525, 0.3456618100588, 0.21116794214501236, 0.1571190045721818, 0.06284760182887272, 0.03519465702416873, 0.13323691587721018, 0.02011123258523927, 0.026395992768126545, 0.0050278081463098175, 0.0037708561097323633, 0.7883360346227052, 0.0721438966792825, 0.018363900972908274, 0.031480973096414185, 0.04984487406932246, 0.009181950486454137, 0.019675608185258864, 0.003935121637051773, 0.005246828849402364, 0.002623414424701182, 0.39760133295085115, 0.2032952902392178, 0.03388254837320297, 0.183242353446914, 0.05255252400741685, 0.06914805790449585, 0.038031431847472714, 0.012446650422809253, 0.004840364053314709, 0.004148883474269751, 0.8752603860024906, 0.029796098246893294, 0.029796098246893294, 0.014898049123446647, 0.011173536842584986, 0.011173536842584986, 0.009311280702154154, 0.0037245122808616618, 0.0074490245617233235, 0.005586768421292493, 0.2874131480790272, 0.10515115173622945, 0.11917130530106004, 0.049070537476907074, 0.08412092138898355, 0.11216122851864474, 0.2032922266900436, 0.014020153564830592, 0.007010076782415296, 0.007010076782415296, 0.3557633688999382, 0.2506514644522292, 0.057497110125242536, 0.08175370345932924, 0.15632026815300315, 0.03503730148256967, 0.037732478519690416, 0.01527266987701755, 0.005390354074241488, 0.0035935693828276585, 0.8489298072568403, 0.06626908320443707, 0.014853415200994514, 0.007997992800535508, 0.023993978401606525, 0.015995985601071017, 0.011425704000765011, 0.005712852000382506, 0.004570281600306004, 0.001142570400076501, 0.5243393065259115, 0.11263585103149211, 0.0427239434947039, 0.07767989726309801, 0.04660793835785881, 0.08156389212625291, 0.027187964042084303, 0.015535979452619602, 0.06602791267363331, 0.007767989726309801, 0.20144503503593605, 0.10878031891940547, 0.17324273013090502, 0.04431790770790593, 0.33036985745893516, 0.024173404204312327, 0.06446241121149954, 0.028202304905031048, 0.012086702102156163, 0.012086702102156163, 0.3840722163899668, 0.22473575510124993, 0.151409274159925, 0.09472988618906303, 0.05033763826782847, 0.03487962336668429, 0.039635935643959425, 0.01109806198030864, 0.005152671633714725, 0.003963593564395943, 0.12592849883964913, 0.1333360575949226, 0.07777936693037152, 0.45556486344931885, 0.07777936693037152, 0.02963023502109391, 0.02963023502109391, 0.0481491319092776, 0.011111338132910216, 0.0037037793776367386, 0.3790355440130422, 0.12251653947896313, 0.1301738231963983, 0.03062913486974078, 0.03062913486974078, 0.026800493011023184, 0.20291801851203267, 0.06508691159819915, 0.01531456743487039, 0.0038286418587175977, 0.46190014951538, 0.23942389337788542, 0.04683710655526201, 0.09274979653377544, 0.06440102151348527, 0.03759294078777609, 0.03451155219861411, 0.013866248651228886, 0.0052383606015753564, 0.0030813885891619744, 0.5229677018538508, 0.16908673045804717, 0.048046502643816685, 0.10902860215327632, 0.07437968197744699, 0.03280097776645177, 0.017093467286742475, 0.017555452889086866, 0.006005812830477086, 0.002309928011721956, 0.3563122636708688, 0.10253590321463851, 0.08202872257171082, 0.11278949353610236, 0.2281423846525707, 0.04101436128585541, 0.0487045540269533, 0.012816987901829814, 0.010253590321463852, 0.002563397580365963, 0.27077370312901744, 0.5308589706082052, 0.035628118832765454, 0.032065306949488906, 0.024939683182935816, 0.021376871299659272, 0.06413061389897781, 0.01425124753310618, 0.00712562376655309, 0.003562811883276545, 0.22044341995639827, 0.5143679798982627, 0.04548832475290758, 0.055985630465117016, 0.03149191713662832, 0.06298383427325664, 0.041989222848837764, 0.010497305712209441, 0.006998203808139627, 0.0034991019040698135, 0.39320971634667645, 0.29698619059416653, 0.02336291366007443, 0.1013712863894755, 0.05622938541916219, 0.06494098034325775, 0.04632984573268997, 0.012275429211225548, 0.0031678526996711093, 0.002771871112212221, 0.7074814866190308, 0.042922516970610655, 0.055651263382584845, 0.019537145655588298, 0.05535524602416684, 0.06186762790936294, 0.04173844753693863, 0.011248659619884171, 0.002368138867344036, 0.001776104150508027, 0.2114793082049118, 0.1093858490715061, 0.48494393088367704, 0.029169559752401625, 0.05469292453575305, 0.03646194969050203, 0.03646194969050203, 0.029169559752401625, 0.007292389938100406, 0.007292389938100406, 0.2325022771693846, 0.49571240226680113, 0.052642025019483306, 0.052642025019483306, 0.021934177091451377, 0.0350946833463222, 0.03948151876461248, 0.021934177091451377, 0.0350946833463222, 0.013160506254870826, 0.3050326966314516, 0.11903714990495672, 0.06943833744455809, 0.09919762492079727, 0.027279346853219248, 0.17855572485743507, 0.05207875308341856, 0.0867979218056976, 0.054558693706438496, 0.004959881246039863, 0.4762206287290024, 0.07064811525100585, 0.03139916233378038, 0.04884314140810281, 0.18403397923410167, 0.04186554977837384, 0.10291947653850235, 0.03576015710236099, 0.00523319372229673, 0.002616596861148365, 0.39777491165548595, 0.08915644571588478, 0.06858188131991137, 0.048007316923937955, 0.0754400694519025, 0.2057456439597341, 0.02743275252796455, 0.06858188131991137, 0.02057456439597341, 0.006858188131991137, 0.5297102792064762, 0.1057981128306413, 0.0345463225569441, 0.05829691931484317, 0.12235155905584369, 0.061175779527921845, 0.061895494581191514, 0.012954870958854038, 0.009356295692505694, 0.0035985752663483437, 0.46461530527314304, 0.11150767326555433, 0.08672819031765336, 0.055753836632777165, 0.08053331958067812, 0.0309743536848762, 0.11150767326555433, 0.01858461221092572, 0.00619487073697524, 0.02477948294790096, 0.08681803766670593, 0.09620377146851197, 0.04399562719596584, 0.03578311011938555, 0.07097961187615823, 0.11262880562167256, 0.4546214810249804, 0.09444394638067334, 0.002346433450451512, 0.002346433450451512, 0.4079382306041743, 0.29832217544182815, 0.03676994255445789, 0.11620689392210748, 0.032607307548292844, 0.06452084259555818, 0.02358826503493525, 0.014569222521577654, 0.002775090004110029, 0.002775090004110029, 0.1958004162520492, 0.07592261038344764, 0.5714175413070006, 0.03995926862286718, 0.02397556117372031, 0.03995926862286718, 0.02397556117372031, 0.015983707449146872, 0.007991853724573436, 0.003995926862286718, 0.2915816948675952, 0.12149237286149801, 0.0668208050738239, 0.0364477118584494, 0.23083550843684622, 0.0668208050738239, 0.1397162287907227, 0.024298474572299604, 0.012149237286149802, 0.006074618643074901, 0.33140741636885523, 0.20195139434977114, 0.21748611699206125, 0.05696064968839699, 0.04660416792687026, 0.025891204403816814, 0.04660416792687026, 0.015534722642290088, 0.05696064968839699, 0.005178240880763363, 0.233133450084167, 0.1398800700505002, 0.025903716676018557, 0.05957854835484268, 0.05439780501963897, 0.033674831678824124, 0.4144594668162969, 0.031084460011222267, 0.0025903716676018555, 0.005180743335203711, 0.6448459699497854, 0.119168426225608, 0.08464299432846924, 0.04529142678979494, 0.041579014757844535, 0.02264571339489747, 0.021531989785312348, 0.00853854767348593, 0.009652271283071053, 0.002227447219170243, 0.7774588771233625, 0.03741292718551392, 0.08303844814345773, 0.0419754792813083, 0.013687656287383141, 0.019162718802336397, 0.005475062514953256, 0.008212593772429885, 0.010950125029906513, 0.0018250208383177521, 0.10306269764313086, 0.2849380464251265, 0.10104186043444202, 0.22936502318618338, 0.022229209295577243, 0.012125023252133042, 0.2354275348122499, 0.005052093021722101, 0.0020208372086888402, 0.005052093021722101, 0.3893342667922502, 0.11123836194064292, 0.16685754291096436, 0.047673583688846964, 0.10329276465916842, 0.05561918097032146, 0.031782389125897974, 0.023836791844423482, 0.07151037553327044, 0.007945597281474493, 0.23420374265545238, 0.07997200968722765, 0.4969689173420575, 0.03427371843738328, 0.03427371843738328, 0.03427371843738328, 0.03427371843738328, 0.028561432031152727, 0.005712286406230546, 0.011424572812461092, 0.31924780989347357, 0.17607000424427935, 0.2205712141082181, 0.03289219859508515, 0.05224055070984113, 0.04256637465246314, 0.01934835211475597, 0.12576428874591383, 0.007739340845902389, 0.0038696704229511944, 0.24184930827017573, 0.1245890375937269, 0.16856163909739522, 0.07328766917278053, 0.08061643609005859, 0.2198630075183416, 0.05130136842094637, 0.02931506766911221, 0.007328766917278053, 0.007328766917278053, 0.54891631294282, 0.11728981045786752, 0.0797570711113499, 0.042224331764832305, 0.08444866352966461, 0.032841146928202905, 0.051607516601461706, 0.0187663696732588, 0.0093831848366294, 0.0234579620915735, 0.23573751953015412, 0.29545769114445986, 0.09115184088499292, 0.08486550703085549, 0.025145335416549775, 0.022002168489481052, 0.15087201249929863, 0.01885900156241233, 0.06286333854137444, 0.012572667708274888, 0.8057526288834495, 0.027198400974968756, 0.07819540280303518, 0.012465933780194014, 0.010199400365613284, 0.020398800731226567, 0.01586573390206511, 0.013599200487484378, 0.013599200487484378, 0.00453306682916146, 0.5665233423364429, 0.0936203828437342, 0.027606010325716496, 0.0468101914218671, 0.03360731691826356, 0.056412281969942406, 0.14283109690262014, 0.02640574900720708, 0.0024005226370188257, 0.0036007839555282388, 0.4379983839856564, 0.24099687868853636, 0.013687449499551762, 0.08676865307751563, 0.12807542031723435, 0.06452654764074402, 0.013687449499551762, 0.011487680829980942, 0.0019553499285073946, 0.0009776749642536973, 0.180867691908094, 0.542603075724282, 0.06531333318903396, 0.050241025530026115, 0.06531333318903396, 0.04019282042402089, 0.020096410212010446, 0.020096410212010446, 0.010048205106005223, 0.0050241025530026115, 0.12477949195780601, 0.13180932249064015, 0.574688646059191, 0.03163423739775364, 0.028119322131336565, 0.047451356096630454, 0.01933203396529389, 0.021089491598502423, 0.008787288166042677, 0.012302203432459748, 0.3454616620319284, 0.1110412485102627, 0.10692860967654927, 0.03907006892027762, 0.1357170815125433, 0.01850687475171045, 0.21796985818681197, 0.0123379165011403, 0.010281597084283584, 0.0020563194168567167, 0.7974998203249543, 0.050904243850528996, 0.04848023223859905, 0.019392092895439618, 0.016968081283509667, 0.016968081283509667, 0.026664127731229476, 0.012120058059649762, 0.0048480232238599045, 0.0048480232238599045, 0.5539331090179119, 0.3133023953563476, 0.025329548806480456, 0.015680196880202186, 0.02593263330187285, 0.024123379815695675, 0.015680196880202186, 0.014172485641721208, 0.00964935192627827, 0.002713880229265763, 0.13633029802395943, 0.5711134106409111, 0.12527649007607083, 0.058953642388739215, 0.03684602649296201, 0.014738410597184804, 0.03684602649296201, 0.011053807947888603, 0.007369205298592402, 0.003684602649296201, 0.3269224094948151, 0.13958484899778623, 0.19468413149691235, 0.0257129984995922, 0.1028519939983688, 0.04775271149924266, 0.04775271149924266, 0.09917870849842705, 0.011019856499825228, 0.0036732854999417426, 0.7996332706330606, 0.034874971304868684, 0.04234817944162626, 0.03238390192594949, 0.012455346894595959, 0.04234817944162626, 0.017437485652434342, 0.009964277515676767, 0.004982138757838384, 0.002491069378919192, 0.28603287485481826, 0.2139470453275943, 0.2777152791401386, 0.06885120897151523, 0.033732471509534304, 0.06238196786009769, 0.036967092065243075, 0.009703861667126307, 0.007855507063864153, 0.0018483546032621537, 0.1615110361590341, 0.11536502582788148, 0.44761630021218013, 0.06460441446361363, 0.041531409298037336, 0.05537521239738311, 0.09229202066230519, 0.018458404132461036, 0.004614601033115259, 0.004614601033115259, 0.3949311306326858, 0.21506150678017544, 0.10427224571160021, 0.06777695971254014, 0.13685732249647528, 0.02932656910638756, 0.020854449142320042, 0.018899344535227538, 0.00977552303546252, 0.001955104607092504, 0.535813058860887, 0.12311109446412026, 0.1524898783703308, 0.0405707015847669, 0.03031144371275688, 0.04476767071422555, 0.03450841284221553, 0.02844612409966415, 0.005129628936005011, 0.004196969129458645, 0.23879093034817053, 0.2078365504882225, 0.07959697678272351, 0.03095437985994803, 0.07959697678272351, 0.044220542657068616, 0.2785894187395323, 0.017688217062827447, 0.013266162797120585, 0.008844108531413724, 0.48743015914310645, 0.09806074682834787, 0.07579054058894286, 0.04382201872915179, 0.048850774976759374, 0.13613561556023385, 0.048850774976759374, 0.03915245935637332, 0.016163859367310088, 0.006106346872094922, 0.29681517571135646, 0.15450652982234994, 0.05285749704448814, 0.03659365180003025, 0.02032980655557236, 0.28055133046689856, 0.05285749704448814, 0.048791535733373664, 0.05285749704448814, 0.008131922622228943, 0.3379963818142117, 0.1229077752051679, 0.04389563400184568, 0.07462257780313765, 0.07901214120332221, 0.21069904320885924, 0.05267476080221481, 0.030726943801291973, 0.008779126800369135, 0.048285197402030244, 0.3185233044452663, 0.17231588601137357, 0.06266032218595402, 0.27674975632129695, 0.04177354812396935, 0.057438628670457854, 0.036551854608473176, 0.015665080546488505, 0.010443387030992337, 0.005221693515496169, 0.724035454977118, 0.0842015539256689, 0.044548496553696915, 0.04356940871735193, 0.04112168912648946, 0.02056084456324473, 0.023498108072279693, 0.007832702690759898, 0.009301334445277379, 0.0014686317545174808, 0.3069262386813826, 0.11229008732245703, 0.09731807567946277, 0.08234606403646849, 0.24703819210940547, 0.07486005821497135, 0.044916034928982815, 0.022458017464491407, 0.0074860058214971355, 0.0074860058214971355, 0.31112125559519815, 0.12939815857709377, 0.08131578271238134, 0.04313271952569793, 0.07283065755978503, 0.19445078474699887, 0.11242790827190116, 0.04313271952569793, 0.009192218915312673, 0.0035354688135817974, 0.22291848520233679, 0.11630529662730614, 0.11630529662730614, 0.36830010598646945, 0.06784475636592859, 0.03392237818296429, 0.03876843220910205, 0.019384216104551023, 0.009692108052275512, 0.004846054026137756, 0.16405879221188097, 0.14818213490105378, 0.21168876414436255, 0.06879884834691782, 0.037045533725263445, 0.2751953933876713, 0.058214410139699704, 0.021168876414436256, 0.010584438207218128, 0.005292219103609064, 0.5318874677941854, 0.14984646935318421, 0.08324803852954678, 0.05489870648975517, 0.039599066976216846, 0.0746982399778636, 0.03419919420673273, 0.016649607705909356, 0.010349756141511221, 0.004949883372027106, 0.6168129095288084, 0.1575760013844375, 0.04506026066986483, 0.04344132914879184, 0.03264845234163859, 0.05369456211558743, 0.021855575534485337, 0.012411808328226241, 0.015110027530014555, 0.0016189315210729878, 0.7063299259524428, 0.13281789606380706, 0.02525717367770757, 0.02743451623613064, 0.03832122902824597, 0.021773425584230666, 0.014370460885592238, 0.020467020049176825, 0.012628586838853786, 0.0013064055350538398, 0.5528431362789118, 0.11380529150972876, 0.05638060313326012, 0.046983835944383434, 0.09292358664555835, 0.04802792118759196, 0.04802792118759196, 0.025058045837004498, 0.014617193404919291, 0.0020881704864170415, 0.5440599015061629, 0.07825519131253028, 0.07080231594943216, 0.08943450435717747, 0.04844368986013779, 0.03353793913394155, 0.014905750726196244, 0.09316094203872652, 0.003726437681549061, 0.022358626089294367, 0.4484788711220314, 0.1563269207911081, 0.061505673753878595, 0.10507219266287593, 0.061505673753878595, 0.07816346039555405, 0.024345995860910276, 0.010250945625646433, 0.05125472812823216, 0.0025627364064116083, 0.3496652651171329, 0.21368432868269233, 0.07770339224825176, 0.03399523410861014, 0.03885169612412588, 0.2088278666671766, 0.024282310077578674, 0.024282310077578674, 0.024282310077578674, 0.004856462015515735, 0.81766249743686, 0.0336209908485551, 0.03227615121461289, 0.018827754875190856, 0.016138075607306446, 0.026896792678844077, 0.026896792678844077, 0.018827754875190856, 0.0053793585357688155, 0.0013448396339422039, 0.3636371856854135, 0.15384650163613647, 0.1048953420246385, 0.041958136809855405, 0.06993022801642568, 0.03496511400821284, 0.041958136809855405, 0.16083952443777905, 0.020979068404927703, 0.006993022801642567, 0.249223529021043, 0.09345882338289113, 0.1335126048327016, 0.1335126048327016, 0.2625747895043132, 0.03560336128872043, 0.04450420161090054, 0.02670252096654032, 0.008900840322180107, 0.008900840322180107, 0.2521124906041065, 0.17680616224184093, 0.05238701103461953, 0.30777368982838976, 0.04583863465529209, 0.05566119922428325, 0.04583863465529209, 0.03929025827596465, 0.009822564568991162, 0.013096752758654882, 0.24024750037340556, 0.10296321444574524, 0.2917291075962782, 0.03432107148191508, 0.08580267870478771, 0.0572017858031918, 0.10296321444574524, 0.01144035716063836, 0.06864214296383016, 0.00572017858031918, 0.6395575833003339, 0.07821927277773867, 0.059814738006506045, 0.0322079358496571, 0.06901700539212235, 0.05061247062088973, 0.027606802156848943, 0.013803401078424472, 0.009202267385616315, 0.023005668464040785, 0.3008829030903261, 0.1597608334992882, 0.14112206959103793, 0.09319381954125146, 0.22899052801564643, 0.026626805583214702, 0.026626805583214702, 0.00798804167496441, 0.013313402791607351, 0.0026626805583214704, 0.2038319177165387, 0.10452918857258393, 0.1567937828588759, 0.4024373760044482, 0.05226459428629197, 0.031358756571775184, 0.02090583771451679, 0.010452918857258395, 0.010452918857258395, 0.005226459428629197, 0.5659325318007801, 0.14824843868378024, 0.05176929604830421, 0.052161487685033786, 0.045886421497360545, 0.07726175243572674, 0.03529724730566196, 0.012550132375346475, 0.008236024371321125, 0.002353149820377464, 0.5191787792656258, 0.024042071129947627, 0.04743435655368045, 0.022742499717518027, 0.18778806909607743, 0.0818729989830649, 0.09811764163843491, 0.013645499830510817, 0.0032489285310740037, 0.0038987142372888047], \"Term\": [\"abel\", \"abel\", \"abel\", \"abel\", \"abel\", \"abel\", \"abel\", \"abel\", \"abel\", \"abel\", \"acceler\", \"acceler\", \"acceler\", \"acceler\", \"acceler\", \"acceler\", \"acceler\", \"acceler\", \"acceler\", \"acceler\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"activ\", \"activ\", \"activ\", \"activ\", \"activ\", \"activ\", \"activ\", \"activ\", \"activ\", \"activ\", \"acut\", \"acut\", \"acut\", \"acut\", \"acut\", \"acut\", \"acut\", \"acut\", \"acut\", \"acut\", \"admm\", \"admm\", \"admm\", \"admm\", \"admm\", \"admm\", \"admm\", \"admm\", \"admm\", \"admm\", \"adversari\", \"adversari\", \"adversari\", \"adversari\", \"adversari\", \"adversari\", \"adversari\", \"adversari\", \"adversari\", \"adversari\", \"advis\", \"advis\", \"advis\", \"advis\", \"advis\", \"advis\", \"advis\", \"advis\", \"advis\", \"advis\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"ancestr\", \"ancestr\", \"ancestr\", \"ancestr\", \"ancestr\", \"ancestr\", \"ancestr\", \"ancestr\", \"ancestr\", \"ancestr\", \"anchor\", \"anchor\", \"anchor\", \"anchor\", \"anchor\", \"anchor\", \"anchor\", \"anchor\", \"anchor\", \"anchor\", \"angular\", \"angular\", \"angular\", \"angular\", \"angular\", \"angular\", \"angular\", \"angular\", \"angular\", \"angular\", \"anisotrop\", \"anisotrop\", \"anisotrop\", \"anisotrop\", \"anisotrop\", \"anisotrop\", \"anisotrop\", \"anisotrop\", \"anisotrop\", \"anisotrop\", \"anomali\", \"anomali\", \"anomali\", \"anomali\", \"anomali\", \"anomali\", \"anomali\", \"anomali\", \"anomali\", \"anomali\", \"approv\", \"approv\", \"approv\", \"approv\", \"approv\", \"approv\", \"approv\", \"approv\", \"approv\", \"approv\", \"arc\", \"arc\", \"arc\", \"arc\", \"arc\", \"arc\", \"arc\", \"arc\", \"arc\", \"arc\", \"arcco\", \"arcco\", \"arcco\", \"arcco\", \"arcco\", \"arcco\", \"arcco\", \"arcco\", \"arcco\", \"arcco\", \"architectur\", \"architectur\", \"architectur\", \"architectur\", \"architectur\", \"architectur\", \"architectur\", \"architectur\", \"architectur\", \"architectur\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"assembl\", \"assembl\", \"assembl\", \"assembl\", \"assembl\", \"assembl\", \"assembl\", \"assembl\", \"assembl\", \"assembl\", \"assort\", \"assort\", \"assort\", \"assort\", \"assort\", \"assort\", \"assort\", \"assort\", \"assort\", \"assort\", \"asynchron\", \"asynchron\", \"asynchron\", \"asynchron\", \"asynchron\", \"asynchron\", \"asynchron\", \"asynchron\", \"asynchron\", \"asynchron\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auer\", \"auer\", \"auer\", \"auer\", \"auer\", \"auer\", \"auer\", \"auer\", \"auer\", \"auer\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"auto\", \"autocorrel\", \"autocorrel\", \"autocorrel\", \"autocorrel\", \"autocorrel\", \"autocorrel\", \"autocorrel\", \"autocorrel\", \"autocorrel\", \"autocorrel\", \"azuma\", \"azuma\", \"azuma\", \"azuma\", \"azuma\", \"azuma\", \"azuma\", \"azuma\", \"azuma\", \"azuma\", \"backtrack\", \"backtrack\", \"backtrack\", \"backtrack\", \"backtrack\", \"backtrack\", \"backtrack\", \"backtrack\", \"backtrack\", \"backtrack\", \"backup\", \"backup\", \"backup\", \"backup\", \"backup\", \"backup\", \"backup\", \"backup\", \"backup\", \"backup\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"banach\", \"banach\", \"banach\", \"banach\", \"banach\", \"banach\", \"banach\", \"banach\", \"banach\", \"banach\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"batch\", \"batch\", \"batch\", \"batch\", \"batch\", \"batch\", \"batch\", \"batch\", \"batch\", \"batch\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bellman\", \"bellman\", \"bellman\", \"bellman\", \"bellman\", \"bellman\", \"bellman\", \"bellman\", \"bellman\", \"bellman\", \"bet\", \"bet\", \"bet\", \"bet\", \"bet\", \"bet\", \"bet\", \"bet\", \"bet\", \"bet\", \"beth\", \"beth\", \"beth\", \"beth\", \"beth\", \"beth\", \"beth\", \"beth\", \"beth\", \"beth\", \"bfgs\", \"bfgs\", \"bfgs\", \"bfgs\", \"bfgs\", \"bfgs\", \"bfgs\", \"bfgs\", \"bfgs\", \"bfgs\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bilater\", \"bilater\", \"bilater\", \"bilater\", \"bilater\", \"bilater\", \"bilater\", \"bilater\", \"bilater\", \"bilater\", \"bilm\", \"bilm\", \"bilm\", \"bilm\", \"bilm\", \"bilm\", \"bilm\", \"bilm\", \"bilm\", \"bilm\", \"binar\", \"binar\", \"binar\", \"binar\", \"binar\", \"binar\", \"binar\", \"binar\", \"binar\", \"binar\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"blackbox\", \"blackbox\", \"blackbox\", \"blackbox\", \"blackbox\", \"blackbox\", \"blackbox\", \"blackbox\", \"blackbox\", \"blackbox\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"blockmodel\", \"blockmodel\", \"blockmodel\", \"blockmodel\", \"blockmodel\", \"blockmodel\", \"blockmodel\", \"blockmodel\", \"blockmodel\", \"blockmodel\", \"boolean\", \"boolean\", \"boolean\", \"boolean\", \"boolean\", \"boolean\", \"boolean\", \"boolean\", \"boolean\", \"boolean\", \"bouchard\", \"bouchard\", \"bouchard\", \"bouchard\", \"bouchard\", \"bouchard\", \"bouchard\", \"bouchard\", \"bouchard\", \"bouchard\", \"bounc\", \"bounc\", \"bounc\", \"bounc\", \"bounc\", \"bounc\", \"bounc\", \"bounc\", \"bounc\", \"bounc\", \"bptt\", \"bptt\", \"bptt\", \"bptt\", \"bptt\", \"bptt\", \"bptt\", \"bptt\", \"bptt\", \"bptt\", \"branch\", \"branch\", \"branch\", \"branch\", \"branch\", \"branch\", \"branch\", \"branch\", \"branch\", \"branch\", \"breakdown\", \"breakdown\", \"breakdown\", \"breakdown\", \"breakdown\", \"breakdown\", \"breakdown\", \"breakdown\", \"breakdown\", \"breakdown\", \"breiman\", \"breiman\", \"breiman\", \"breiman\", \"breiman\", \"breiman\", \"breiman\", \"breiman\", \"breiman\", \"breiman\", \"broeck\", \"broeck\", \"broeck\", \"broeck\", \"broeck\", \"broeck\", \"broeck\", \"broeck\", \"broeck\", \"broeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"buyer\", \"buyer\", \"buyer\", \"buyer\", \"buyer\", \"buyer\", \"buyer\", \"buyer\", \"buyer\", \"buyer\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"caption\", \"caption\", \"caption\", \"caption\", \"caption\", \"caption\", \"caption\", \"caption\", \"caption\", \"caption\", \"caron\", \"caron\", \"caron\", \"caron\", \"caron\", \"caron\", \"caron\", \"caron\", \"caron\", \"caron\", \"cascad\", \"cascad\", \"cascad\", \"cascad\", \"cascad\", \"cascad\", \"cascad\", \"cascad\", \"cascad\", \"cascad\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"censor\", \"censor\", \"censor\", \"censor\", \"censor\", \"censor\", \"censor\", \"censor\", \"censor\", \"censor\", \"certif\", \"certif\", \"certif\", \"certif\", \"certif\", \"certif\", \"certif\", \"certif\", \"certif\", \"certif\", \"certifi\", \"certifi\", \"certifi\", \"certifi\", \"certifi\", \"certifi\", \"certifi\", \"certifi\", \"certifi\", \"certifi\", \"chain\", \"chain\", \"chain\", \"chain\", \"chain\", \"chain\", \"chain\", \"chain\", \"chain\", \"chain\", \"chair\", \"chair\", \"chair\", \"chair\", \"chair\", \"chair\", \"chair\", \"chair\", \"chair\", \"chair\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"cifar\", \"classif\", \"classif\", \"classif\", \"classif\", \"classif\", \"classif\", \"classif\", \"classif\", \"classif\", \"classif\", \"classifi\", \"classifi\", \"classifi\", \"classifi\", \"classifi\", \"classifi\", \"classifi\", \"classifi\", \"classifi\", \"classifi\", \"clip\", \"clip\", \"clip\", \"clip\", \"clip\", \"clip\", \"clip\", \"clip\", \"clip\", \"clip\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"communiti\", \"communiti\", \"communiti\", \"communiti\", \"communiti\", \"communiti\", \"communiti\", \"communiti\", \"communiti\", \"communiti\", \"compil\", \"compil\", \"compil\", \"compil\", \"compil\", \"compil\", \"compil\", \"compil\", \"compil\", \"compil\", \"composit\", \"composit\", \"composit\", \"composit\", \"composit\", \"composit\", \"composit\", \"composit\", \"composit\", \"composit\", \"compress\", \"compress\", \"compress\", \"compress\", \"compress\", \"compress\", \"compress\", \"compress\", \"compress\", \"compress\", \"cond\", \"cond\", \"cond\", \"cond\", \"cond\", \"cond\", \"cond\", \"cond\", \"cond\", \"cond\", \"condens\", \"condens\", \"condens\", \"condens\", \"condens\", \"condens\", \"condens\", \"condens\", \"condens\", \"condens\", \"confid\", \"confid\", \"confid\", \"confid\", \"confid\", \"confid\", \"confid\", \"confid\", \"confid\", \"confid\", \"congest\", \"congest\", \"congest\", \"congest\", \"congest\", \"congest\", \"congest\", \"congest\", \"congest\", \"congest\", \"conic\", \"conic\", \"conic\", \"conic\", \"conic\", \"conic\", \"conic\", \"conic\", \"conic\", \"conic\", \"connectom\", \"connectom\", \"connectom\", \"connectom\", \"connectom\", \"connectom\", \"connectom\", \"connectom\", \"connectom\", \"connectom\", \"contagion\", \"contagion\", \"contagion\", \"contagion\", \"contagion\", \"contagion\", \"contagion\", \"contagion\", \"contagion\", \"contagion\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contextu\", \"contextu\", \"contextu\", \"contextu\", \"contextu\", \"contextu\", \"contextu\", \"contextu\", \"contextu\", \"contextu\", \"conv\", \"conv\", \"conv\", \"conv\", \"conv\", \"conv\", \"conv\", \"conv\", \"conv\", \"conv\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convnet\", \"convnet\", \"convnet\", \"convnet\", \"convnet\", \"convnet\", \"convnet\", \"convnet\", \"convnet\", \"convnet\", \"convolut\", \"convolut\", \"convolut\", \"convolut\", \"convolut\", \"convolut\", \"convolut\", \"convolut\", \"convolut\", \"convolut\", \"coreset\", \"coreset\", \"coreset\", \"coreset\", \"coreset\", \"coreset\", \"coreset\", \"coreset\", \"coreset\", \"coreset\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"counterfactu\", \"counterfactu\", \"counterfactu\", \"counterfactu\", \"counterfactu\", \"counterfactu\", \"counterfactu\", \"counterfactu\", \"counterfactu\", \"counterfactu\", \"covari\", \"covari\", \"covari\", \"covari\", \"covari\", \"covari\", \"covari\", \"covari\", \"covari\", \"covari\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"coverag\", \"coverag\", \"coverag\", \"coverag\", \"coverag\", \"coverag\", \"coverag\", \"coverag\", \"coverag\", \"coverag\", \"covertyp\", \"covertyp\", \"covertyp\", \"covertyp\", \"covertyp\", \"covertyp\", \"covertyp\", \"covertyp\", \"covertyp\", \"covertyp\", \"covtyp\", \"covtyp\", \"covtyp\", \"covtyp\", \"covtyp\", \"covtyp\", \"covtyp\", \"covtyp\", \"covtyp\", \"covtyp\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"crowd\", \"crowd\", \"crowd\", \"crowd\", \"crowd\", \"crowd\", \"crowd\", \"crowd\", \"crowd\", \"crowd\", \"crowdsourc\", \"crowdsourc\", \"crowdsourc\", \"crowdsourc\", \"crowdsourc\", \"crowdsourc\", \"crowdsourc\", \"crowdsourc\", \"crowdsourc\", \"crowdsourc\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cue\", \"cue\", \"cue\", \"cue\", \"cue\", \"cue\", \"cue\", \"cue\", \"cue\", \"cue\", \"cuturi\", \"cuturi\", \"cuturi\", \"cuturi\", \"cuturi\", \"cuturi\", \"cuturi\", \"cuturi\", \"cuturi\", \"cuturi\", \"cyclic\", \"cyclic\", \"cyclic\", \"cyclic\", \"cyclic\", \"cyclic\", \"cyclic\", \"cyclic\", \"cyclic\", \"cyclic\", \"dann\", \"dann\", \"dann\", \"dann\", \"dann\", \"dann\", \"dann\", \"dann\", \"dann\", \"dann\", \"dantzig\", \"dantzig\", \"dantzig\", \"dantzig\", \"dantzig\", \"dantzig\", \"dantzig\", \"dantzig\", \"dantzig\", \"dantzig\", \"dcnn\", \"dcnn\", \"dcnn\", \"dcnn\", \"dcnn\", \"dcnn\", \"dcnn\", \"dcnn\", \"dcnn\", \"dcnn\", \"deblur\", \"deblur\", \"deblur\", \"deblur\", \"deblur\", \"deblur\", \"deblur\", \"deblur\", \"deblur\", \"deblur\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decod\", \"decod\", \"decod\", \"decod\", \"decod\", \"decod\", \"decod\", \"decod\", \"decod\", \"decod\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"defend\", \"defend\", \"defend\", \"defend\", \"defend\", \"defend\", \"defend\", \"defend\", \"defend\", \"defend\", \"deliber\", \"deliber\", \"deliber\", \"deliber\", \"deliber\", \"deliber\", \"deliber\", \"deliber\", \"deliber\", \"deliber\", \"demix\", \"demix\", \"demix\", \"demix\", \"demix\", \"demix\", \"demix\", \"demix\", \"demix\", \"demix\", \"denois\", \"denois\", \"denois\", \"denois\", \"denois\", \"denois\", \"denois\", \"denois\", \"denois\", \"denois\", \"densiti\", \"densiti\", \"densiti\", \"densiti\", \"densiti\", \"densiti\", \"densiti\", \"densiti\", \"densiti\", \"densiti\", \"depth\", \"depth\", \"depth\", \"depth\", \"depth\", \"depth\", \"depth\", \"depth\", \"depth\", \"depth\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"detect\", \"detect\", \"detect\", \"detect\", \"detect\", \"detect\", \"detect\", \"detect\", \"detect\", \"detect\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialogu\", \"dialogu\", \"dialogu\", \"dialogu\", \"dialogu\", \"dialogu\", \"dialogu\", \"dialogu\", \"dialogu\", \"dialogu\", \"dictionari\", \"dictionari\", \"dictionari\", \"dictionari\", \"dictionari\", \"dictionari\", \"dictionari\", \"dictionari\", \"dictionari\", \"dictionari\", \"differenti\", \"differenti\", \"differenti\", \"differenti\", \"differenti\", \"differenti\", \"differenti\", \"differenti\", \"differenti\", \"differenti\", \"dilat\", \"dilat\", \"dilat\", \"dilat\", \"dilat\", \"dilat\", \"dilat\", \"dilat\", \"dilat\", \"dilat\", \"disagr\", \"disagr\", \"disagr\", \"disagr\", \"disagr\", \"disagr\", \"disagr\", \"disagr\", \"disagr\", \"disagr\", \"discount\", \"discount\", \"discount\", \"discount\", \"discount\", \"discount\", \"discount\", \"discount\", \"discount\", \"discount\", \"discrimin\", \"discrimin\", \"discrimin\", \"discrimin\", \"discrimin\", \"discrimin\", \"discrimin\", \"discrimin\", \"discrimin\", \"discrimin\", \"dispers\", \"dispers\", \"dispers\", \"dispers\", \"dispers\", \"dispers\", \"dispers\", \"dispers\", \"dispers\", \"dispers\", \"diverg\", \"diverg\", \"diverg\", \"diverg\", \"diverg\", \"diverg\", \"diverg\", \"diverg\", \"diverg\", \"diverg\", \"dorsal\", \"dorsal\", \"dorsal\", \"dorsal\", \"dorsal\", \"dorsal\", \"dorsal\", \"dorsal\", \"dorsal\", \"dorsal\", \"dpps\", \"dpps\", \"dpps\", \"dpps\", \"dpps\", \"dpps\", \"dpps\", \"dpps\", \"dpps\", \"dpps\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"duel\", \"duel\", \"duel\", \"duel\", \"duel\", \"duel\", \"duel\", \"duel\", \"duel\", \"duel\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"edg\", \"edg\", \"edg\", \"edg\", \"edg\", \"edg\", \"edg\", \"edg\", \"edg\", \"edg\", \"eigenvalu\", \"eigenvalu\", \"eigenvalu\", \"eigenvalu\", \"eigenvalu\", \"eigenvalu\", \"eigenvalu\", \"eigenvalu\", \"eigenvalu\", \"eigenvalu\", \"elicit\", \"elicit\", \"elicit\", \"elicit\", \"elicit\", \"elicit\", \"elicit\", \"elicit\", \"elicit\", \"elicit\", \"elkan\", \"elkan\", \"elkan\", \"elkan\", \"elkan\", \"elkan\", \"elkan\", \"elkan\", \"elkan\", \"elkan\", \"ellipsoid\", \"ellipsoid\", \"ellipsoid\", \"ellipsoid\", \"ellipsoid\", \"ellipsoid\", \"ellipsoid\", \"ellipsoid\", \"ellipsoid\", \"ellipsoid\", \"elud\", \"elud\", \"elud\", \"elud\", \"elud\", \"elud\", \"elud\", \"elud\", \"elud\", \"elud\", \"emb\", \"emb\", \"emb\", \"emb\", \"emb\", \"emb\", \"emb\", \"emb\", \"emb\", \"emb\", \"ensembl\", \"ensembl\", \"ensembl\", \"ensembl\", \"ensembl\", \"ensembl\", \"ensembl\", \"ensembl\", \"ensembl\", \"ensembl\", \"entri\", \"entri\", \"entri\", \"entri\", \"entri\", \"entri\", \"entri\", \"entri\", \"entri\", \"entri\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"enyi\", \"enyi\", \"enyi\", \"enyi\", \"enyi\", \"enyi\", \"enyi\", \"enyi\", \"enyi\", \"enyi\", \"epidem\", \"epidem\", \"epidem\", \"epidem\", \"epidem\", \"epidem\", \"epidem\", \"epidem\", \"epidem\", \"epidem\", \"epidemiolog\", \"epidemiolog\", \"epidemiolog\", \"epidemiolog\", \"epidemiolog\", \"epidemiolog\", \"epidemiolog\", \"epidemiolog\", \"epidemiolog\", \"epidemiolog\", \"episod\", \"episod\", \"episod\", \"episod\", \"episod\", \"episod\", \"episod\", \"episod\", \"episod\", \"episod\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"exclus\", \"exclus\", \"exclus\", \"exclus\", \"exclus\", \"exclus\", \"exclus\", \"exclus\", \"exclus\", \"exclus\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"exposur\", \"exposur\", \"exposur\", \"exposur\", \"exposur\", \"exposur\", \"exposur\", \"exposur\", \"exposur\", \"exposur\", \"extrapol\", \"extrapol\", \"extrapol\", \"extrapol\", \"extrapol\", \"extrapol\", \"extrapol\", \"extrapol\", \"extrapol\", \"extrapol\", \"fade\", \"fade\", \"fade\", \"fade\", \"fade\", \"fade\", \"fade\", \"fade\", \"fade\", \"fade\", \"feder\", \"feder\", \"feder\", \"feder\", \"feder\", \"feder\", \"feder\", \"feder\", \"feder\", \"feder\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"fenchel\", \"fenchel\", \"fenchel\", \"fenchel\", \"fenchel\", \"fenchel\", \"fenchel\", \"fenchel\", \"fenchel\", \"fenchel\", \"fidel\", \"fidel\", \"fidel\", \"fidel\", \"fidel\", \"fidel\", \"fidel\", \"fidel\", \"fidel\", \"fidel\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"finley\", \"finley\", \"finley\", \"finley\", \"finley\", \"finley\", \"finley\", \"finley\", \"finley\", \"finley\", \"fitc\", \"fitc\", \"fitc\", \"fitc\", \"fitc\", \"fitc\", \"fitc\", \"fitc\", \"fitc\", \"fitc\", \"fixat\", \"fixat\", \"fixat\", \"fixat\", \"fixat\", \"fixat\", \"fixat\", \"fixat\", \"fixat\", \"fixat\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"font\", \"font\", \"font\", \"font\", \"font\", \"font\", \"font\", \"font\", \"font\", \"font\", \"foreground\", \"foreground\", \"foreground\", \"foreground\", \"foreground\", \"foreground\", \"foreground\", \"foreground\", \"foreground\", \"foreground\", \"forest\", \"forest\", \"forest\", \"forest\", \"forest\", \"forest\", \"forest\", \"forest\", \"forest\", \"forest\", \"fourier\", \"fourier\", \"fourier\", \"fourier\", \"fourier\", \"fourier\", \"fourier\", \"fourier\", \"fourier\", \"fourier\", \"frame\", \"frame\", \"frame\", \"frame\", \"frame\", \"frame\", \"frame\", \"frame\", \"frame\", \"frame\", \"frazier\", \"frazier\", \"frazier\", \"frazier\", \"frazier\", \"frazier\", \"frazier\", \"frazier\", \"frazier\", \"frazier\", \"fujishig\", \"fujishig\", \"fujishig\", \"fujishig\", \"fujishig\", \"fujishig\", \"fujishig\", \"fujishig\", \"fujishig\", \"fujishig\", \"fuzzi\", \"fuzzi\", \"fuzzi\", \"fuzzi\", \"fuzzi\", \"fuzzi\", \"fuzzi\", \"fuzzi\", \"fuzzi\", \"fuzzi\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"garivi\", \"garivi\", \"garivi\", \"garivi\", \"garivi\", \"garivi\", \"garivi\", \"garivi\", \"garivi\", \"garivi\", \"gate\", \"gate\", \"gate\", \"gate\", \"gate\", \"gate\", \"gate\", \"gate\", \"gate\", \"gate\", \"gene\", \"gene\", \"gene\", \"gene\", \"gene\", \"gene\", \"gene\", \"gene\", \"gene\", \"gene\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"glasso\", \"glasso\", \"glasso\", \"glasso\", \"glasso\", \"glasso\", \"glasso\", \"glasso\", \"glasso\", \"glasso\", \"glimps\", \"glimps\", \"glimps\", \"glimps\", \"glimps\", \"glimps\", \"glimps\", \"glimps\", \"glimps\", \"glimps\", \"glms\", \"glms\", \"glms\", \"glms\", \"glms\", \"glms\", \"glms\", \"glms\", \"glms\", \"glms\", \"glove\", \"glove\", \"glove\", \"glove\", \"glove\", \"glove\", \"glove\", \"glove\", \"glove\", \"glove\", \"gpus\", \"gpus\", \"gpus\", \"gpus\", \"gpus\", \"gpus\", \"gpus\", \"gpus\", \"gpus\", \"gpus\", \"grade\", \"grade\", \"grade\", \"grade\", \"grade\", \"grade\", \"grade\", \"grade\", \"grade\", \"grade\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"greedi\", \"greedi\", \"greedi\", \"greedi\", \"greedi\", \"greedi\", \"greedi\", \"greedi\", \"greedi\", \"greedi\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"gumbel\", \"gumbel\", \"gumbel\", \"gumbel\", \"gumbel\", \"gumbel\", \"gumbel\", \"gumbel\", \"gumbel\", \"gumbel\", \"haar\", \"haar\", \"haar\", \"haar\", \"haar\", \"haar\", \"haar\", \"haar\", \"haar\", \"haar\", \"halfspac\", \"halfspac\", \"halfspac\", \"halfspac\", \"halfspac\", \"halfspac\", \"halfspac\", \"halfspac\", \"halfspac\", \"halfspac\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"handwrit\", \"handwrit\", \"handwrit\", \"handwrit\", \"handwrit\", \"handwrit\", \"handwrit\", \"handwrit\", \"handwrit\", \"handwrit\", \"hankel\", \"hankel\", \"hankel\", \"hankel\", \"hankel\", \"hankel\", \"hankel\", \"hankel\", \"hankel\", \"hankel\", \"harmon\", \"harmon\", \"harmon\", \"harmon\", \"harmon\", \"harmon\", \"harmon\", \"harmon\", \"harmon\", \"harmon\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hawk\", \"hawk\", \"hawk\", \"hawk\", \"hawk\", \"hawk\", \"hawk\", \"hawk\", \"hawk\", \"hawk\", \"hazard\", \"hazard\", \"hazard\", \"hazard\", \"hazard\", \"hazard\", \"hazard\", \"hazard\", \"hazard\", \"hazard\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hide\", \"hide\", \"hide\", \"hide\", \"hide\", \"hide\", \"hide\", \"hide\", \"hide\", \"hide\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"honor\", \"honor\", \"honor\", \"honor\", \"honor\", \"honor\", \"honor\", \"honor\", \"honor\", \"honor\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"household\", \"household\", \"household\", \"household\", \"household\", \"household\", \"household\", \"household\", \"household\", \"household\", \"howard\", \"howard\", \"howard\", \"howard\", \"howard\", \"howard\", \"howard\", \"howard\", \"howard\", \"howard\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"incoher\", \"incoher\", \"incoher\", \"incoher\", \"incoher\", \"incoher\", \"incoher\", \"incoher\", \"incoher\", \"incoher\", \"infant\", \"infant\", \"infant\", \"infant\", \"infant\", \"infant\", \"infant\", \"infant\", \"infant\", \"infant\", \"infect\", \"infect\", \"infect\", \"infect\", \"infect\", \"infect\", \"infect\", \"infect\", \"infect\", \"infect\", \"influenc\", \"influenc\", \"influenc\", \"influenc\", \"influenc\", \"influenc\", \"influenc\", \"influenc\", \"influenc\", \"influenc\", \"inlier\", \"inlier\", \"inlier\", \"inlier\", \"inlier\", \"inlier\", \"inlier\", \"inlier\", \"inlier\", \"inlier\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact\", \"interrupt\", \"interrupt\", \"interrupt\", \"interrupt\", \"interrupt\", \"interrupt\", \"interrupt\", \"interrupt\", \"interrupt\", \"interrupt\", \"intervent\", \"intervent\", \"intervent\", \"intervent\", \"intervent\", \"intervent\", \"intervent\", \"intervent\", \"intervent\", \"intervent\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invit\", \"invit\", \"invit\", \"invit\", \"invit\", \"invit\", \"invit\", \"invit\", \"invit\", \"invit\", \"ise\", \"ise\", \"ise\", \"ise\", \"ise\", \"ise\", \"ise\", \"ise\", \"ise\", \"ise\", \"isometri\", \"isometri\", \"isometri\", \"isometri\", \"isometri\", \"isometri\", \"isometri\", \"isometri\", \"isometri\", \"isometri\", \"isoton\", \"isoton\", \"isoton\", \"isoton\", \"isoton\", \"isoton\", \"isoton\", \"isoton\", \"isoton\", \"isoton\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"itti\", \"itti\", \"itti\", \"itti\", \"itti\", \"itti\", \"itti\", \"itti\", \"itti\", \"itti\", \"iyer\", \"iyer\", \"iyer\", \"iyer\", \"iyer\", \"iyer\", \"iyer\", \"iyer\", \"iyer\", \"iyer\", \"jacobian\", \"jacobian\", \"jacobian\", \"jacobian\", \"jacobian\", \"jacobian\", \"jacobian\", \"jacobian\", \"jacobian\", \"jacobian\", \"jaksch\", \"jaksch\", \"jaksch\", \"jaksch\", \"jaksch\", \"jaksch\", \"jaksch\", \"jaksch\", \"jaksch\", \"jaksch\", \"jegelka\", \"jegelka\", \"jegelka\", \"jegelka\", \"jegelka\", \"jegelka\", \"jegelka\", \"jegelka\", \"jegelka\", \"jegelka\", \"junction\", \"junction\", \"junction\", \"junction\", \"junction\", \"junction\", \"junction\", \"junction\", \"junction\", \"junction\", \"kaplan\", \"kaplan\", \"kaplan\", \"kaplan\", \"kaplan\", \"kaplan\", \"kaplan\", \"kaplan\", \"kaplan\", \"kaplan\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kitti\", \"kitti\", \"kitti\", \"kitti\", \"kitti\", \"kitti\", \"kitti\", \"kitti\", \"kitti\", \"kitti\", \"krylov\", \"krylov\", \"krylov\", \"krylov\", \"krylov\", \"krylov\", \"krylov\", \"krylov\", \"krylov\", \"krylov\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"langevin\", \"langevin\", \"langevin\", \"langevin\", \"langevin\", \"langevin\", \"langevin\", \"langevin\", \"langevin\", \"langevin\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"lattic\", \"lattic\", \"lattic\", \"lattic\", \"lattic\", \"lattic\", \"lattic\", \"lattic\", \"lattic\", \"lattic\", \"lattimor\", \"lattimor\", \"lattimor\", \"lattimor\", \"lattimor\", \"lattimor\", \"lattimor\", \"lattimor\", \"lattimor\", \"lattimor\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layout\", \"layout\", \"layout\", \"layout\", \"layout\", \"layout\", \"layout\", \"layout\", \"layout\", \"layout\", \"leaf\", \"leaf\", \"leaf\", \"leaf\", \"leaf\", \"leaf\", \"leaf\", \"leaf\", \"leaf\", \"leaf\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"liter\", \"liter\", \"liter\", \"liter\", \"liter\", \"liter\", \"liter\", \"liter\", \"liter\", \"liter\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lyapunov\", \"lyapunov\", \"lyapunov\", \"lyapunov\", \"lyapunov\", \"lyapunov\", \"lyapunov\", \"lyapunov\", \"lyapunov\", \"lyapunov\", \"maker\", \"maker\", \"maker\", \"maker\", \"maker\", \"maker\", \"maker\", \"maker\", \"maker\", \"maker\", \"malici\", \"malici\", \"malici\", \"malici\", \"malici\", \"malici\", \"malici\", \"malici\", \"malici\", \"malici\", \"mallow\", \"mallow\", \"mallow\", \"mallow\", \"mallow\", \"mallow\", \"mallow\", \"mallow\", \"mallow\", \"mallow\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"matric\", \"matric\", \"matric\", \"matric\", \"matric\", \"matric\", \"matric\", \"matric\", \"matric\", \"matric\", \"matroid\", \"matroid\", \"matroid\", \"matroid\", \"matroid\", \"matroid\", \"matroid\", \"matroid\", \"matroid\", \"matroid\", \"maxout\", \"maxout\", \"maxout\", \"maxout\", \"maxout\", \"maxout\", \"maxout\", \"maxout\", \"maxout\", \"maxout\", \"mdps\", \"mdps\", \"mdps\", \"mdps\", \"mdps\", \"mdps\", \"mdps\", \"mdps\", \"mdps\", \"mdps\", \"membership\", \"membership\", \"membership\", \"membership\", \"membership\", \"membership\", \"membership\", \"membership\", \"membership\", \"membership\", \"mesh\", \"mesh\", \"mesh\", \"mesh\", \"mesh\", \"mesh\", \"mesh\", \"mesh\", \"mesh\", \"mesh\", \"metabol\", \"metabol\", \"metabol\", \"metabol\", \"metabol\", \"metabol\", \"metabol\", \"metabol\", \"metabol\", \"metabol\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"minibatch\", \"minibatch\", \"minibatch\", \"minibatch\", \"minibatch\", \"minibatch\", \"minibatch\", \"minibatch\", \"minibatch\", \"minibatch\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"mixtur\", \"mixtur\", \"mixtur\", \"mixtur\", \"mixtur\", \"mixtur\", \"mixtur\", \"mixtur\", \"mixtur\", \"mixtur\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"mnist\", \"mnist\", \"mnist\", \"mnist\", \"mnist\", \"mnist\", \"mnist\", \"mnist\", \"mnist\", \"mnist\", \"modular\", \"modular\", \"modular\", \"modular\", \"modular\", \"modular\", \"modular\", \"modular\", \"modular\", \"modular\", \"modulus\", \"modulus\", \"modulus\", \"modulus\", \"modulus\", \"modulus\", \"modulus\", \"modulus\", \"modulus\", \"modulus\", \"mohan\", \"mohan\", \"mohan\", \"mohan\", \"mohan\", \"mohan\", \"mohan\", \"mohan\", \"mohan\", \"mohan\", \"mont\", \"mont\", \"mont\", \"mont\", \"mont\", \"mont\", \"mont\", \"mont\", \"mont\", \"mont\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilinear\", \"multilinear\", \"multilinear\", \"multilinear\", \"multilinear\", \"multilinear\", \"multilinear\", \"multilinear\", \"multilinear\", \"multilinear\", \"muno\", \"muno\", \"muno\", \"muno\", \"muno\", \"muno\", \"muno\", \"muno\", \"muno\", \"muno\", \"musco\", \"musco\", \"musco\", \"musco\", \"musco\", \"musco\", \"musco\", \"musco\", \"musco\", \"musco\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"nade\", \"nade\", \"nade\", \"nade\", \"nade\", \"nade\", \"nade\", \"nade\", \"nade\", \"nade\", \"navig\", \"navig\", \"navig\", \"navig\", \"navig\", \"navig\", \"navig\", \"navig\", \"navig\", \"navig\", \"ndcg\", \"ndcg\", \"ndcg\", \"ndcg\", \"ndcg\", \"ndcg\", \"ndcg\", \"ndcg\", \"ndcg\", \"ndcg\", \"nesterov\", \"nesterov\", \"nesterov\", \"nesterov\", \"nesterov\", \"nesterov\", \"nesterov\", \"nesterov\", \"nesterov\", \"nesterov\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"newton\", \"newton\", \"newton\", \"newton\", \"newton\", \"newton\", \"newton\", \"newton\", \"newton\", \"newton\", \"neyshabur\", \"neyshabur\", \"neyshabur\", \"neyshabur\", \"neyshabur\", \"neyshabur\", \"neyshabur\", \"neyshabur\", \"neyshabur\", \"neyshabur\", \"nod\", \"nod\", \"nod\", \"nod\", \"nod\", \"nod\", \"nod\", \"nod\", \"nod\", \"nod\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"nois\", \"nois\", \"nois\", \"nois\", \"nois\", \"nois\", \"nois\", \"nois\", \"nois\", \"nois\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"normaliz\", \"normaliz\", \"normaliz\", \"normaliz\", \"normaliz\", \"normaliz\", \"normaliz\", \"normaliz\", \"normaliz\", \"normaliz\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nystr\", \"nystr\", \"nystr\", \"nystr\", \"nystr\", \"nystr\", \"nystr\", \"nystr\", \"nystr\", \"nystr\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"oppon\", \"oppon\", \"oppon\", \"oppon\", \"oppon\", \"oppon\", \"oppon\", \"oppon\", \"oppon\", \"oppon\", \"optimist\", \"optimist\", \"optimist\", \"optimist\", \"optimist\", \"optimist\", \"optimist\", \"optimist\", \"optimist\", \"optimist\", \"oracl\", \"oracl\", \"oracl\", \"oracl\", \"oracl\", \"oracl\", \"oracl\", \"oracl\", \"oracl\", \"oracl\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"ordin\", \"ordin\", \"ordin\", \"ordin\", \"ordin\", \"ordin\", \"ordin\", \"ordin\", \"ordin\", \"ordin\", \"orthonorm\", \"orthonorm\", \"orthonorm\", \"orthonorm\", \"orthonorm\", \"orthonorm\", \"orthonorm\", \"orthonorm\", \"orthonorm\", \"orthonorm\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"overlap\", \"overlap\", \"overlap\", \"overlap\", \"overlap\", \"overlap\", \"overlap\", \"overlap\", \"overlap\", \"overlap\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack\", \"pack\", \"pagerank\", \"pagerank\", \"pagerank\", \"pagerank\", \"pagerank\", \"pagerank\", \"pagerank\", \"pagerank\", \"pagerank\", \"pagerank\", \"pairwis\", \"pairwis\", \"pairwis\", \"pairwis\", \"pairwis\", \"pairwis\", \"pairwis\", \"pairwis\", \"pairwis\", \"pairwis\", \"pareto\", \"pareto\", \"pareto\", \"pareto\", \"pareto\", \"pareto\", \"pareto\", \"pareto\", \"pareto\", \"pareto\", \"particl\", \"particl\", \"particl\", \"particl\", \"particl\", \"particl\", \"particl\", \"particl\", \"particl\", \"particl\", \"partit\", \"partit\", \"partit\", \"partit\", \"partit\", \"partit\", \"partit\", \"partit\", \"partit\", \"partit\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"payoff\", \"payoff\", \"payoff\", \"payoff\", \"payoff\", \"payoff\", \"payoff\", \"payoff\", \"payoff\", \"payoff\", \"peer\", \"peer\", \"peer\", \"peer\", \"peer\", \"peer\", \"peer\", \"peer\", \"peer\", \"peer\", \"permut\", \"permut\", \"permut\", \"permut\", \"permut\", \"permut\", \"permut\", \"permut\", \"permut\", \"permut\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"pitman\", \"pitman\", \"pitman\", \"pitman\", \"pitman\", \"pitman\", \"pitman\", \"pitman\", \"pitman\", \"pitman\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"pixelcnn\", \"pixelcnn\", \"pixelcnn\", \"pixelcnn\", \"pixelcnn\", \"pixelcnn\", \"pixelcnn\", \"pixelcnn\", \"pixelcnn\", \"pixelcnn\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plateau\", \"plateau\", \"plateau\", \"plateau\", \"plateau\", \"plateau\", \"plateau\", \"plateau\", \"plateau\", \"plateau\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"poincar\", \"poincar\", \"poincar\", \"poincar\", \"poincar\", \"poincar\", \"poincar\", \"poincar\", \"poincar\", \"poincar\", \"poisson\", \"poisson\", \"poisson\", \"poisson\", \"poisson\", \"poisson\", \"poisson\", \"poisson\", \"poisson\", \"poisson\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polyhedra\", \"polyhedra\", \"polyhedra\", \"polyhedra\", \"polyhedra\", \"polyhedra\", \"polyhedra\", \"polyhedra\", \"polyhedra\", \"polyhedra\", \"polynomi\", \"polynomi\", \"polynomi\", \"polynomi\", \"polynomi\", \"polynomi\", \"polynomi\", \"polynomi\", \"polynomi\", \"polynomi\", \"polytop\", \"polytop\", \"polytop\", \"polytop\", \"polytop\", \"polytop\", \"polytop\", \"polytop\", \"polytop\", \"polytop\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"postsynapt\", \"postsynapt\", \"postsynapt\", \"postsynapt\", \"postsynapt\", \"postsynapt\", \"postsynapt\", \"postsynapt\", \"postsynapt\", \"postsynapt\", \"precondit\", \"precondit\", \"precondit\", \"precondit\", \"precondit\", \"precondit\", \"precondit\", \"precondit\", \"precondit\", \"precondit\", \"precondition\", \"precondition\", \"precondition\", \"precondition\", \"precondition\", \"precondition\", \"precondition\", \"precondition\", \"precondition\", \"precondition\", \"presynapt\", \"presynapt\", \"presynapt\", \"presynapt\", \"presynapt\", \"presynapt\", \"presynapt\", \"presynapt\", \"presynapt\", \"presynapt\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"privaci\", \"privaci\", \"privaci\", \"privaci\", \"privaci\", \"privaci\", \"privaci\", \"privaci\", \"privaci\", \"privaci\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privileg\", \"privileg\", \"privileg\", \"privileg\", \"privileg\", \"privileg\", \"privileg\", \"privileg\", \"privileg\", \"privileg\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"prox\", \"prox\", \"prox\", \"prox\", \"prox\", \"prox\", \"prox\", \"prox\", \"prox\", \"prox\", \"proxim\", \"proxim\", \"proxim\", \"proxim\", \"proxim\", \"proxim\", \"proxim\", \"proxim\", \"proxim\", \"proxim\", \"puriti\", \"puriti\", \"puriti\", \"puriti\", \"puriti\", \"puriti\", \"puriti\", \"puriti\", \"puriti\", \"puriti\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pyramid\", \"pyramid\", \"pyramid\", \"pyramid\", \"pyramid\", \"pyramid\", \"pyramid\", \"pyramid\", \"pyramid\", \"pyramid\", \"quadratur\", \"quadratur\", \"quadratur\", \"quadratur\", \"quadratur\", \"quadratur\", \"quadratur\", \"quadratur\", \"quadratur\", \"quadratur\", \"quantiz\", \"quantiz\", \"quantiz\", \"quantiz\", \"quantiz\", \"quantiz\", \"quantiz\", \"quantiz\", \"quantiz\", \"quantiz\", \"quantize\", \"quantize\", \"quantize\", \"quantize\", \"quantize\", \"quantize\", \"quantize\", \"quantize\", \"quantize\", \"quantize\", \"queri\", \"queri\", \"queri\", \"queri\", \"queri\", \"queri\", \"queri\", \"queri\", \"queri\", \"queri\", \"queue\", \"queue\", \"queue\", \"queue\", \"queue\", \"queue\", \"queue\", \"queue\", \"queue\", \"queue\", \"radon\", \"radon\", \"radon\", \"radon\", \"radon\", \"radon\", \"radon\", \"radon\", \"radon\", \"radon\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rcnn\", \"rcnn\", \"rcnn\", \"rcnn\", \"rcnn\", \"rcnn\", \"rcnn\", \"rcnn\", \"rcnn\", \"rcnn\", \"reaction\", \"reaction\", \"reaction\", \"reaction\", \"reaction\", \"reaction\", \"reaction\", \"reaction\", \"reaction\", \"reaction\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recoveri\", \"recoveri\", \"recoveri\", \"recoveri\", \"recoveri\", \"recoveri\", \"recoveri\", \"recoveri\", \"recoveri\", \"recoveri\", \"recurr\", \"recurr\", \"recurr\", \"recurr\", \"recurr\", \"recurr\", \"recurr\", \"recurr\", \"recurr\", \"recurr\", \"regress\", \"regress\", \"regress\", \"regress\", \"regress\", \"regress\", \"regress\", \"regress\", \"regress\", \"regress\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"reinforc\", \"reinforc\", \"reinforc\", \"reinforc\", \"reinforc\", \"reinforc\", \"reinforc\", \"reinforc\", \"reinforc\", \"reinforc\", \"reject\", \"reject\", \"reject\", \"reject\", \"reject\", \"reject\", \"reject\", \"reject\", \"reject\", \"reject\", \"renam\", \"renam\", \"renam\", \"renam\", \"renam\", \"renam\", \"renam\", \"renam\", \"renam\", \"renam\", \"renorm\", \"renorm\", \"renorm\", \"renorm\", \"renorm\", \"renorm\", \"renorm\", \"renorm\", \"renorm\", \"renorm\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reservoir\", \"reservoir\", \"reservoir\", \"reservoir\", \"reservoir\", \"reservoir\", \"reservoir\", \"reservoir\", \"reservoir\", \"reservoir\", \"residu\", \"residu\", \"residu\", \"residu\", \"residu\", \"residu\", \"residu\", \"residu\", \"residu\", \"residu\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"respons\", \"respons\", \"respons\", \"respons\", \"respons\", \"respons\", \"respons\", \"respons\", \"respons\", \"respons\", \"restart\", \"restart\", \"restart\", \"restart\", \"restart\", \"restart\", \"restart\", \"restart\", \"restart\", \"restart\", \"revenu\", \"revenu\", \"revenu\", \"revenu\", \"revenu\", \"revenu\", \"revenu\", \"revenu\", \"revenu\", \"revenu\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"rollout\", \"rollout\", \"rollout\", \"rollout\", \"rollout\", \"rollout\", \"rollout\", \"rollout\", \"rollout\", \"rollout\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"rpca\", \"rpca\", \"rpca\", \"rpca\", \"rpca\", \"rpca\", \"rpca\", \"rpca\", \"rpca\", \"rpca\", \"saddl\", \"saddl\", \"saddl\", \"saddl\", \"saddl\", \"saddl\", \"saddl\", \"saddl\", \"saddl\", \"saddl\", \"safe\", \"safe\", \"safe\", \"safe\", \"safe\", \"safe\", \"safe\", \"safe\", \"safe\", \"safe\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"saga\", \"saga\", \"saga\", \"saga\", \"saga\", \"saga\", \"saga\", \"saga\", \"saga\", \"saga\", \"salienc\", \"salienc\", \"salienc\", \"salienc\", \"salienc\", \"salienc\", \"salienc\", \"salienc\", \"salienc\", \"salienc\", \"sandwich\", \"sandwich\", \"sandwich\", \"sandwich\", \"sandwich\", \"sandwich\", \"sandwich\", \"sandwich\", \"sandwich\", \"sandwich\", \"satellit\", \"satellit\", \"satellit\", \"satellit\", \"satellit\", \"satellit\", \"satellit\", \"satellit\", \"satellit\", \"satellit\", \"scan\", \"scan\", \"scan\", \"scan\", \"scan\", \"scan\", \"scan\", \"scan\", \"scan\", \"scan\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"schatten\", \"schatten\", \"schatten\", \"schatten\", \"schatten\", \"schatten\", \"schatten\", \"schatten\", \"schatten\", \"schatten\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"sdca\", \"sdca\", \"sdca\", \"sdca\", \"sdca\", \"sdca\", \"sdca\", \"sdca\", \"sdca\", \"sdca\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"seller\", \"seller\", \"seller\", \"seller\", \"seller\", \"seller\", \"seller\", \"seller\", \"seller\", \"seller\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"serial\", \"serial\", \"serial\", \"serial\", \"serial\", \"serial\", \"serial\", \"serial\", \"serial\", \"serial\", \"seth\", \"seth\", \"seth\", \"seth\", \"seth\", \"seth\", \"seth\", \"seth\", \"seth\", \"seth\", \"sgld\", \"sgld\", \"sgld\", \"sgld\", \"sgld\", \"sgld\", \"sgld\", \"sgld\", \"sgld\", \"sgld\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shapley\", \"shapley\", \"shapley\", \"shapley\", \"shapley\", \"shapley\", \"shapley\", \"shapley\", \"shapley\", \"shapley\", \"shrinkag\", \"shrinkag\", \"shrinkag\", \"shrinkag\", \"shrinkag\", \"shrinkag\", \"shrinkag\", \"shrinkag\", \"shrinkag\", \"shrinkag\", \"sift\", \"sift\", \"sift\", \"sift\", \"sift\", \"sift\", \"sift\", \"sift\", \"sift\", \"sift\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular\", \"sinkhorn\", \"sinkhorn\", \"sinkhorn\", \"sinkhorn\", \"sinkhorn\", \"sinkhorn\", \"sinkhorn\", \"sinkhorn\", \"sinkhorn\", \"sinkhorn\", \"skene\", \"skene\", \"skene\", \"skene\", \"skene\", \"skene\", \"skene\", \"skene\", \"skene\", \"skene\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"slab\", \"slab\", \"slab\", \"slab\", \"slab\", \"slab\", \"slab\", \"slab\", \"slab\", \"slab\", \"slack\", \"slack\", \"slack\", \"slack\", \"slack\", \"slack\", \"slack\", \"slack\", \"slack\", \"slack\", \"slot\", \"slot\", \"slot\", \"slot\", \"slot\", \"slot\", \"slot\", \"slot\", \"slot\", \"slot\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"sobolev\", \"sobolev\", \"sobolev\", \"sobolev\", \"sobolev\", \"sobolev\", \"sobolev\", \"sobolev\", \"sobolev\", \"sobolev\", \"spam\", \"spam\", \"spam\", \"spam\", \"spam\", \"spam\", \"spam\", \"spam\", \"spam\", \"spam\", \"spars\", \"spars\", \"spars\", \"spars\", \"spars\", \"spars\", \"spars\", \"spars\", \"spars\", \"spars\", \"sparsiti\", \"sparsiti\", \"sparsiti\", \"sparsiti\", \"sparsiti\", \"sparsiti\", \"sparsiti\", \"sparsiti\", \"sparsiti\", \"sparsiti\", \"spatiotempor\", \"spatiotempor\", \"spatiotempor\", \"spatiotempor\", \"spatiotempor\", \"spatiotempor\", \"spatiotempor\", \"spatiotempor\", \"spatiotempor\", \"spatiotempor\", \"spec\", \"spec\", \"spec\", \"spec\", \"spec\", \"spec\", \"spec\", \"spec\", \"spec\", \"spec\", \"spectra\", \"spectra\", \"spectra\", \"spectra\", \"spectra\", \"spectra\", \"spectra\", \"spectra\", \"spectra\", \"spectra\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"sriperumbudur\", \"sriperumbudur\", \"sriperumbudur\", \"sriperumbudur\", \"sriperumbudur\", \"sriperumbudur\", \"sriperumbudur\", \"sriperumbudur\", \"sriperumbudur\", \"sriperumbudur\", \"stan\", \"stan\", \"stan\", \"stan\", \"stan\", \"stan\", \"stan\", \"stan\", \"stan\", \"stan\", \"stein\", \"stein\", \"stein\", \"stein\", \"stein\", \"stein\", \"stein\", \"stein\", \"stein\", \"stein\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stitch\", \"stitch\", \"stitch\", \"stitch\", \"stitch\", \"stitch\", \"stitch\", \"stitch\", \"stitch\", \"stitch\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"subspac\", \"subspac\", \"subspac\", \"subspac\", \"subspac\", \"subspac\", \"subspac\", \"subspac\", \"subspac\", \"subspac\", \"successor\", \"successor\", \"successor\", \"successor\", \"successor\", \"successor\", \"successor\", \"successor\", \"successor\", \"successor\", \"suffix\", \"suffix\", \"suffix\", \"suffix\", \"suffix\", \"suffix\", \"suffix\", \"suffix\", \"suffix\", \"suffix\", \"summand\", \"summand\", \"summand\", \"summand\", \"summand\", \"summand\", \"summand\", \"summand\", \"summand\", \"summand\", \"supermodular\", \"supermodular\", \"supermodular\", \"supermodular\", \"supermodular\", \"supermodular\", \"supermodular\", \"supermodular\", \"supermodular\", \"supermodular\", \"supervis\", \"supervis\", \"supervis\", \"supervis\", \"supervis\", \"supervis\", \"supervis\", \"supervis\", \"supervis\", \"supervis\", \"svhn\", \"svhn\", \"svhn\", \"svhn\", \"svhn\", \"svhn\", \"svhn\", \"svhn\", \"svhn\", \"svhn\", \"svrg\", \"svrg\", \"svrg\", \"svrg\", \"svrg\", \"svrg\", \"svrg\", \"svrg\", \"svrg\", \"svrg\", \"tabul\", \"tabul\", \"tabul\", \"tabul\", \"tabul\", \"tabul\", \"tabul\", \"tabul\", \"tabul\", \"tabul\", \"tabular\", \"tabular\", \"tabular\", \"tabular\", \"tabular\", \"tabular\", \"tabular\", \"tabular\", \"tabular\", \"tabular\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"tall\", \"tall\", \"tall\", \"tall\", \"tall\", \"tall\", \"tall\", \"tall\", \"tall\", \"tall\", \"taxonomi\", \"taxonomi\", \"taxonomi\", \"taxonomi\", \"taxonomi\", \"taxonomi\", \"taxonomi\", \"taxonomi\", \"taxonomi\", \"taxonomi\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"templat\", \"templat\", \"templat\", \"templat\", \"templat\", \"templat\", \"templat\", \"templat\", \"templat\", \"templat\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"theta\", \"theta\", \"theta\", \"theta\", \"theta\", \"theta\", \"theta\", \"theta\", \"theta\", \"theta\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"tikhonov\", \"tikhonov\", \"tikhonov\", \"tikhonov\", \"tikhonov\", \"tikhonov\", \"tikhonov\", \"tikhonov\", \"tikhonov\", \"tikhonov\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"tracker\", \"tracker\", \"tracker\", \"tracker\", \"tracker\", \"tracker\", \"tracker\", \"tracker\", \"tracker\", \"tracker\", \"traffic\", \"traffic\", \"traffic\", \"traffic\", \"traffic\", \"traffic\", \"traffic\", \"traffic\", \"traffic\", \"traffic\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trajectori\", \"trajectori\", \"trajectori\", \"trajectori\", \"trajectori\", \"trajectori\", \"trajectori\", \"trajectori\", \"trajectori\", \"trajectori\", \"transduc\", \"transduc\", \"transduc\", \"transduc\", \"transduc\", \"transduc\", \"transduc\", \"transduc\", \"transduc\", \"transduc\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transit\", \"transit\", \"transit\", \"transit\", \"transit\", \"transit\", \"transit\", \"transit\", \"transit\", \"transit\", \"transmiss\", \"transmiss\", \"transmiss\", \"transmiss\", \"transmiss\", \"transmiss\", \"transmiss\", \"transmiss\", \"transmiss\", \"transmiss\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"trim\", \"trim\", \"trim\", \"trim\", \"trim\", \"trim\", \"trim\", \"trim\", \"trim\", \"trim\", \"unspecifi\", \"unspecifi\", \"unspecifi\", \"unspecifi\", \"unspecifi\", \"unspecifi\", \"unspecifi\", \"unspecifi\", \"unspecifi\", \"unspecifi\", \"unsupervis\", \"unsupervis\", \"unsupervis\", \"unsupervis\", \"unsupervis\", \"unsupervis\", \"unsupervis\", \"unsupervis\", \"unsupervis\", \"unsupervis\", \"untrain\", \"untrain\", \"untrain\", \"untrain\", \"untrain\", \"untrain\", \"untrain\", \"untrain\", \"untrain\", \"untrain\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"utter\", \"utter\", \"utter\", \"utter\", \"utter\", \"utter\", \"utter\", \"utter\", \"utter\", \"utter\", \"valuat\", \"valuat\", \"valuat\", \"valuat\", \"valuat\", \"valuat\", \"valuat\", \"valuat\", \"valuat\", \"valuat\", \"varianc\", \"varianc\", \"varianc\", \"varianc\", \"varianc\", \"varianc\", \"varianc\", \"varianc\", \"varianc\", \"varianc\", \"variat\", \"variat\", \"variat\", \"variat\", \"variat\", \"variat\", \"variat\", \"variat\", \"variat\", \"variat\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"volatil\", \"volatil\", \"volatil\", \"volatil\", \"volatil\", \"volatil\", \"volatil\", \"volatil\", \"volatil\", \"volatil\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"vote\", \"wake\", \"wake\", \"wake\", \"wake\", \"wake\", \"wake\", \"wake\", \"wake\", \"wake\", \"wake\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"watkin\", \"watkin\", \"watkin\", \"watkin\", \"watkin\", \"watkin\", \"watkin\", \"watkin\", \"watkin\", \"watkin\", \"wave\", \"wave\", \"wave\", \"wave\", \"wave\", \"wave\", \"wave\", \"wave\", \"wave\", \"wave\", \"wavelet\", \"wavelet\", \"wavelet\", \"wavelet\", \"wavelet\", \"wavelet\", \"wavelet\", \"wavelet\", \"wavelet\", \"wavelet\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wiki\", \"wiki\", \"wiki\", \"wiki\", \"wiki\", \"wiki\", \"wiki\", \"wiki\", \"wiki\", \"wiki\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"wirting\", \"wirting\", \"wirting\", \"wirting\", \"wirting\", \"wirting\", \"wirting\", \"wirting\", \"wirting\", \"wirting\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [10, 4, 7, 8, 5, 3, 6, 1, 2, 9]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el661404447422444321929867586\", ldavis_el661404447422444321929867586_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el661404447422444321929867586\", ldavis_el661404447422444321929867586_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el661404447422444321929867586\", ldavis_el661404447422444321929867586_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "9      0.026567 -0.014387       1        1  47.503545\n",
              "3     -0.000284  0.016984       2        1  16.249539\n",
              "6     -0.047809 -0.004648       3        1  10.398159\n",
              "7      0.007202  0.026594       4        1   6.852095\n",
              "4      0.024308 -0.001851       5        1   5.884843\n",
              "2      0.006960  0.004121       6        1   4.976879\n",
              "5      0.003611  0.004261       7        1   4.459483\n",
              "0     -0.008002 -0.009322       8        1   2.159992\n",
              "1      0.002506 -0.024361       9        1   1.083512\n",
              "8     -0.015058  0.002610      10        1   0.431952, topic_info=         Term         Freq        Total Category  logprob  loglift\n",
              "3092   regret  4144.000000  4144.000000  Default  30.0000  30.0000\n",
              "3345   polici  5091.000000  5091.000000  Default  29.0000  29.0000\n",
              "1920    layer  7031.000000  7031.000000  Default  28.0000  28.0000\n",
              "172    kernel  5532.000000  5532.000000  Default  27.0000  27.0000\n",
              "3093   reward  3355.000000  3355.000000  Default  26.0000  26.0000\n",
              "...       ...          ...          ...      ...      ...      ...\n",
              "588      risk    12.719363  2298.795345  Topic10  -6.7700   0.2476\n",
              "431   cluster    14.925436  7122.738797  Topic10  -6.6101  -0.7234\n",
              "3345   polici    13.188774  5091.471878  Topic10  -6.7338  -0.5113\n",
              "1181  classif    12.367269  2896.653949  Topic10  -6.7981  -0.0116\n",
              "3417     game    11.754340  2184.460824  Topic10  -6.8489   0.2197\n",
              "\n",
              "[701 rows x 6 columns], token_table=      Topic      Freq    Term\n",
              "term                         \n",
              "4856      1  0.221889    abel\n",
              "4856      2  0.118341    abel\n",
              "4856      3  0.073963    abel\n",
              "4856      4  0.066567    abel\n",
              "4856      5  0.110944    abel\n",
              "...     ...       ...     ...\n",
              "3365      6  0.081873  worker\n",
              "3365      7  0.098118  worker\n",
              "3365      8  0.013645  worker\n",
              "3365      9  0.003249  worker\n",
              "3365     10  0.003899  worker\n",
              "\n",
              "[4810 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[10, 4, 7, 8, 5, 3, 6, 1, 2, 9])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = gensimvis.prepare(lda_model_tfidf, bow_corpus, dictionary)\n",
        "vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRfOtslomRUU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "J076_NLP_Assignment_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}